{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oWbj4HgqHBg"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "mqfBOKz-qJYF"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# Suppress Warnings\n",
        "# ===========================\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ===========================\n",
        "# Standard Libraries\n",
        "# ===========================\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')  \n",
        "\n",
        "# ===========================\n",
        "# Enable Inline Plotting (Jupyter)\n",
        "# ===========================\n",
        "%matplotlib inline\n",
        "\n",
        "# ===========================\n",
        "# FinRL Imports\n",
        "# ===========================\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "\n",
        "# ===========================\n",
        "# Custom Imports (model.py)\n",
        "# ===========================\n",
        "sys.path.append(os.path.abspath(\".\"))  \n",
        "from models import DRLEnsembleAgent\n",
        "\n",
        "sys.path.append(\"../FinRL-Library\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUF2P4hmqVjh"
      },
      "source": [
        "## `process_csv_to_features(csv_path)`\n",
        "\n",
        "Processes financial data from a CSV by adding technical indicators and turbulence features.\n",
        "\n",
        "### **Parameters**\n",
        "- `csv_path` *(str)*: Path to the raw financial data CSV.\n",
        "\n",
        "### **Workflow**\n",
        "1. Load data.\n",
        "2. Identify 5-day and 7-day tickers.\n",
        "3. Apply technical indicators.\n",
        "4. Combine datasets.\n",
        "5. Add turbulence feature.\n",
        "6. Clean `NaN` and infinite values.\n",
        "\n",
        "### **Returns**\n",
        "- `processed` *(DataFrame)*: Feature-enhanced, cleaned DataFrame for modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_csv_to_features(csv_path):\n",
        "    # Step 1: Load Data\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Step 2: Identify 5-day and 7-day tickers\n",
        "    day_values_per_tic = df.groupby('tic')['day'].apply(lambda x: sorted(x.unique())).reset_index()\n",
        "    day_values_per_tic.columns = ['tic', 'unique_days']\n",
        "\n",
        "    tics_5day = day_values_per_tic[day_values_per_tic['unique_days'].apply(lambda x: x == list(range(5)))]['tic']\n",
        "    tics_7day = day_values_per_tic[day_values_per_tic['unique_days'].apply(lambda x: x == list(range(7)))]['tic']\n",
        "\n",
        "    df_5day_full = df[df['tic'].isin(tics_5day)]\n",
        "    df_7day_full = df[df['tic'].isin(tics_7day)]\n",
        "\n",
        "    # Step 3: Apply Technical Indicators\n",
        "    fe_ti = FeatureEngineer(\n",
        "        use_technical_indicator=True,\n",
        "        use_turbulence=False,\n",
        "        user_defined_feature=False\n",
        "    )\n",
        "    df_5day_full = fe_ti.preprocess_data(df_5day_full)\n",
        "    if not df_7day_full.empty:\n",
        "        df_7day_full = fe_ti.preprocess_data(df_7day_full)\n",
        "    else:\n",
        "        print(\"[Info] df_7day_full is empty. Skipping technical indicators.\")\n",
        "\n",
        "    # Step 4: Combine and Clean Index\n",
        "    combined_df = pd.concat([df_5day_full, df_7day_full], ignore_index=False)\n",
        "    combined_df.index = range(len(combined_df))\n",
        "\n",
        "    # Step 5: Remove dates with only one ticker\n",
        "    combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
        "    combined_df = combined_df[combined_df.groupby('date')['date'].transform('count') > 1]\n",
        "    combined_df = combined_df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
        "\n",
        "    # Step 6: Apply Turbulence Feature\n",
        "    fe_turb = FeatureEngineer(\n",
        "        use_technical_indicator=False,\n",
        "        use_turbulence=True,\n",
        "        user_defined_feature=False\n",
        "    )\n",
        "    processed = fe_turb.preprocess_data(combined_df)\n",
        "\n",
        "    # Step 7: Final Cleaning\n",
        "    processed = processed.copy()\n",
        "    processed = processed.fillna(0)\n",
        "    processed = processed.replace(np.inf, 0)\n",
        "\n",
        "    return processed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Processing\n",
        "\n",
        "Apply `process_csv_to_features` to prepare datasets with technical indicators, returns, and covariance matrices.\n",
        "\n",
        "### **Datasets Processed**\n",
        "- `processed_0` : `2007-2025_no_crypto.csv`\n",
        "- `processed_1` : `2015-2025_crypto.csv`\n",
        "- `processed_2` : `2015-2025_no_crypto.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "[Info] df_7day_full is empty. Skipping technical indicators.\n",
            "Successfully added turbulence index\n",
            "Successfully added technical indicators\n",
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n",
            "Successfully added technical indicators\n",
            "[Info] df_7day_full is empty. Skipping technical indicators.\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "processed_0 = process_csv_to_features('2007-2025_no_crypto.csv')\n",
        "processed_1 = process_csv_to_features('2015-2025_crypto.csv')\n",
        "processed_2 = process_csv_to_features('2015-2025_no_crypto.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17TUs71EWj09"
      },
      "source": [
        "## `process_df_for_mvo(df)`\n",
        "\n",
        "Prepares price data for Mean-Variance Optimization (MVO) by converting a DataFrame into a structured format with dates as index and tickers as columns.\n",
        "\n",
        "### **Features**\n",
        "- Sorts data by `date` and `tic`.\n",
        "- Generates a price matrix (`DataFrame`) for MVO.\n",
        "- Includes only dates where all tickers have available prices.\n",
        "\n",
        "### **Returns**\n",
        "- `mvo` *(DataFrame)*: Cleaned price matrix for MVO, with tickers as columns and dates as index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "wungSNOwPwKR"
      },
      "outputs": [],
      "source": [
        "def process_df_for_mvo(df):\n",
        "    df = df.sort_values(['date', 'tic'], ignore_index=True)[['date', 'tic', 'close']]\n",
        "    all_tickers = sorted(df['tic'].unique())\n",
        "    ticker_index = {tic: idx for idx, tic in enumerate(all_tickers)}\n",
        "    stock_dimension = len(all_tickers)\n",
        "\n",
        "    mvo = pd.DataFrame(columns=all_tickers)\n",
        "\n",
        "    grouped = df.groupby('date')\n",
        "    for date, group in grouped:\n",
        "        row = [np.nan] * stock_dimension\n",
        "        for _, row_data in group.iterrows():\n",
        "            row[ticker_index[row_data['tic']]] = row_data['close']\n",
        "        if not any(pd.isna(row)):  # only include dates with all tickers\n",
        "            mvo.loc[date] = row\n",
        "\n",
        "    return mvo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwEwkHJ1d_6u"
      },
      "source": [
        "## `StockReturnsComputing(StockPrice, Rows, Columns)`\n",
        "\n",
        "Calculates daily percentage returns from a stock price matrix.\n",
        "\n",
        "### **Features**\n",
        "- Computes daily returns for each asset using price differences.\n",
        "- Returns percentage values.\n",
        "\n",
        "### **Parameters**\n",
        "- `StockPrice`: 2D array of stock prices.\n",
        "- `Rows`: Number of rows (days).\n",
        "- `Columns`: Number of assets.\n",
        "\n",
        "### **Returns**\n",
        "- `StockReturn` *(ndarray)*: Daily percentage return matrix.\n",
        "\n",
        "> *Note: Inspired by Dr. G A Vijayalakshmi Pai's MVO implementation.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "6KvXkpyE8MFq"
      },
      "outputs": [],
      "source": [
        "# Codes in this section partially refer to Dr G A Vijayalakshmi Pai\n",
        "\n",
        "# https://www.kaggle.com/code/vijipai/lesson-5-mean-variance-optimization-of-portfolios/notebook\n",
        "\n",
        "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
        "  import numpy as np\n",
        "  StockReturn = np.zeros([Rows-1, Columns])\n",
        "  for j in range(Columns):        # j: Assets\n",
        "    for i in range(Rows-1):     # i: Daily Prices\n",
        "      StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100\n",
        "\n",
        "  return StockReturn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `run_naive_portfolio_pipeline(...)`\n",
        "\n",
        "Executes a naive equal-weighted portfolio strategy, holding fixed shares throughout the period.\n",
        "\n",
        "### **Features**\n",
        "- Allocates initial capital equally across all assets.\n",
        "- Calculates portfolio value and daily returns over time.\n",
        "- Saves both daily returns and fixed positions to CSV.\n",
        "- Outputs organized in: `<dataset>/naive/`\n",
        "\n",
        "### **Parameters**\n",
        "- `df`: Processed DataFrame.\n",
        "- `start_date`, `end_date`: Trading period.\n",
        "- `initial_fund`: Starting capital.\n",
        "- `buy_cost_pct`: Transaction cost percentage.\n",
        "- `original_csv_path`: For folder structuring.\n",
        "\n",
        "### **Outputs**\n",
        "- `df_daily_return`: Daily return CSV.\n",
        "- `df_positions`: Fixed shares held (positions) CSV.\n",
        "\n",
        "### **Returns**\n",
        "- Tuple: `(df_daily_return, df_positions)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def run_naive_portfolio_pipeline(df, \n",
        "                                  start_date, \n",
        "                                  end_date, \n",
        "                                  initial_fund=1_000_000, \n",
        "                                  buy_cost_pct=0.0, \n",
        "                                  output_return_csv='df_daily_return_naive.csv',\n",
        "                                  output_position_csv='df_positions_naive.csv',\n",
        "                                  original_csv_path='data.csv',\n",
        "                                  model_name='naive'):\n",
        "    \"\"\"\n",
        "    Compute naive equal-weighted portfolio returns and save both daily returns and positions.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 0: Setup Folder Structure ===\n",
        "    base_name = os.path.splitext(os.path.basename(original_csv_path))[0]\n",
        "    target_folder = os.path.join(base_name, model_name)\n",
        "    if not os.path.exists(target_folder):\n",
        "        os.makedirs(target_folder)\n",
        "        print(f\"[INFO] Created folder: {target_folder}\")\n",
        "\n",
        "    # === Step 1: Filter trade data ===\n",
        "    trade_df = data_split(df, start_date, end_date).reset_index(drop=True)\n",
        "    trade_df = trade_df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
        "\n",
        "    # === Step 2: Convert to MVO-like structure ===\n",
        "    trade_mvo = process_df_for_mvo(trade_df)\n",
        "\n",
        "    if trade_mvo.empty or len(trade_mvo) < 1:\n",
        "        raise ValueError(\"Insufficient data for naive portfolio.\")\n",
        "\n",
        "    stock_dimension = len(trade_mvo.columns)\n",
        "    first_prices = trade_mvo.iloc[0].to_numpy()\n",
        "\n",
        "    if np.any(first_prices == 0):\n",
        "        raise ValueError(\"Zero price detected in first trading day.\")\n",
        "\n",
        "    # === Step 3: Equal Weight Allocation in Shares ===\n",
        "    equal_weight = 1.0 / stock_dimension\n",
        "    allocation_per_asset = initial_fund * (1 - buy_cost_pct) * equal_weight\n",
        "    shares = allocation_per_asset / first_prices\n",
        "\n",
        "    # === Step 4: Calculate Portfolio Value Over Time ===\n",
        "    portfolio_values = trade_mvo @ shares\n",
        "    result_df = pd.DataFrame({\n",
        "        \"date\": trade_mvo.index,\n",
        "        \"account_value\": portfolio_values\n",
        "    })\n",
        "\n",
        "    # === Step 5: Compute Daily Returns ===\n",
        "    result_df[\"date\"] = pd.to_datetime(result_df[\"date\"])\n",
        "    result_df.set_index(\"date\", inplace=True)\n",
        "\n",
        "    df_daily_return = result_df.copy()\n",
        "    df_daily_return[\"daily_return\"] = df_daily_return[\"account_value\"].pct_change()\n",
        "    df_daily_return = df_daily_return.reset_index()\n",
        "\n",
        "    df_daily_return.loc[0, \"daily_return\"] = 0.0\n",
        "    df_daily_return = df_daily_return[[\"date\", \"daily_return\"]]\n",
        "\n",
        "    # === Step 6: Save Daily Returns ===\n",
        "    csv_return_path = os.path.join(target_folder, output_return_csv)\n",
        "    df_daily_return.to_csv(csv_return_path, index=False)\n",
        "    print(f\"[INFO] Naive portfolio daily returns saved to {csv_return_path}\")\n",
        "\n",
        "    # === Step 7: Generate Positions as Percentages for All Dates ===\n",
        "    total_value = np.sum(shares * first_prices)\n",
        "    percentage_allocations = (shares * first_prices) / total_value  # Fixed percentages\n",
        "\n",
        "    # Repeat the same allocation for every trading date\n",
        "    dates = pd.to_datetime(trade_mvo.index)\n",
        "    df_positions = pd.DataFrame([percentage_allocations] * len(dates), columns=range(stock_dimension))\n",
        "    df_positions.insert(0, 'date', dates)\n",
        "\n",
        "    # === Step 8: Save Positions ===\n",
        "    csv_position_path = os.path.join(target_folder, output_position_csv)\n",
        "    df_positions.to_csv(csv_position_path, index=False)\n",
        "    print(f\"[INFO] Naive portfolio positions saved to {csv_position_path}\")\n",
        "\n",
        "    return df_daily_return, df_positions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Naive Portfolio Execution\n",
        "\n",
        "Runs the `run_naive_portfolio_pipeline` across three datasets using an equal-weighted buy-and-hold strategy.\n",
        "\n",
        "### **Workflow**\n",
        "- Allocates \\$1,000,000 equally across assets.\n",
        "- Applies a **0.1% buy transaction cost**.\n",
        "- Holds fixed shares throughout the trading period (2023-04-05 to 2025-04-10).\n",
        "- Saves daily returns and initial positions in `/naive/` folder for each dataset.\n",
        "\n",
        "### **Datasets Processed**\n",
        "1. `2007-2025_no_crypto.csv`\n",
        "2. `2015-2025_crypto.csv`\n",
        "3. `2015-2025_no_crypto.csv`\n",
        "\n",
        "### **Outputs**\n",
        "- `df_daily_return_naive.csv` : Daily returns  \n",
        "- `df_positions_naive.csv` : Fixed positions (shares held)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Naive portfolio daily returns saved to 2007-2025_no_crypto/naive/df_daily_return_naive.csv\n",
            "[INFO] Naive portfolio positions saved to 2007-2025_no_crypto/naive/df_positions_naive.csv\n",
            "[INFO] Naive portfolio daily returns saved to 2015-2025_crypto/naive/df_daily_return_naive.csv\n",
            "[INFO] Naive portfolio positions saved to 2015-2025_crypto/naive/df_positions_naive.csv\n",
            "[INFO] Naive portfolio daily returns saved to 2015-2025_no_crypto/naive/df_daily_return_naive.csv\n",
            "[INFO] Naive portfolio positions saved to 2015-2025_no_crypto/naive/df_positions_naive.csv\n"
          ]
        }
      ],
      "source": [
        "TRADE_START_DATE = '2023-04-05'\n",
        "TRADE_END_DATE = '2025-04-10'\n",
        "\n",
        "df_daily_return_naive = run_naive_portfolio_pipeline(\n",
        "    df=processed_0,\n",
        "    start_date=TRADE_START_DATE,\n",
        "    end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    buy_cost_pct=0.001,  \n",
        "    output_return_csv='df_daily_return_naive.csv',\n",
        "    output_position_csv='df_positions_naive.csv',\n",
        "    original_csv_path='2007-2025_no_crypto.csv',   \n",
        "    model_name='naive'             \n",
        ")\n",
        "df_daily_return_naive = run_naive_portfolio_pipeline(\n",
        "    df=processed_1,\n",
        "    start_date=TRADE_START_DATE,\n",
        "    end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    buy_cost_pct=0.001,  \n",
        "    output_return_csv='df_daily_return_naive.csv',\n",
        "    output_position_csv='df_positions_naive.csv',\n",
        "    original_csv_path='2015-2025_crypto.csv',   \n",
        "    model_name='naive'             \n",
        ")\n",
        "df_daily_return_naive = run_naive_portfolio_pipeline(\n",
        "    df=processed_2,\n",
        "    start_date=TRADE_START_DATE,\n",
        "    end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    buy_cost_pct=0.001,  \n",
        "    output_return_csv='df_daily_return_naive.csv',\n",
        "    output_position_csv='df_positions_naive.csv',\n",
        "    original_csv_path='2015-2025_no_crypto.csv',   \n",
        "    model_name='naive'             \n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeVVbuwveJ_5"
      },
      "source": [
        "## `run_mvo_portfolio_pipeline(...)`\n",
        "\n",
        "Executes a Mean-Variance Optimization (MVO) strategy to compute optimal portfolio weights, track returns, and save outputs.\n",
        "\n",
        "### **Features**\n",
        "- Optimizes portfolio using **Max Sharpe Ratio** with `PyPortfolioOpt`.\n",
        "- Static allocation based on training data.\n",
        "- Calculates portfolio value and daily returns over trading period.\n",
        "- Saves outputs in `<dataset>/mvo/` folder.\n",
        "\n",
        "### **Parameters**\n",
        "- `train_start_date`, `train_end_date`: Training period for optimization.\n",
        "- `trade_start_date`, `trade_end_date`: Trading period for applying weights.\n",
        "- `initial_fund`: Starting capital.\n",
        "- `weight_bounds`: Constraints for asset weights.\n",
        "- `original_csv_path`: For folder structuring.\n",
        "\n",
        "### **Outputs**\n",
        "- `df_daily_return_mvo.csv`: Daily returns.\n",
        "- `df_positions_mvo.csv`: Static portfolio weights.\n",
        "\n",
        "### **Returns**\n",
        "- Tuple: `(df_daily_return, df_positions)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "\n",
        "def run_mvo_portfolio_pipeline(df, \n",
        "                                train_start_date, \n",
        "                                train_end_date, \n",
        "                                trade_start_date, \n",
        "                                trade_end_date, \n",
        "                                initial_fund=1_000_000, \n",
        "                                weight_bounds=(0.01, 0.25), \n",
        "                                output_return_csv='df_daily_return_mvo.csv',\n",
        "                                output_position_csv='df_positions_mvo.csv',\n",
        "                                original_csv_path='data.csv'):\n",
        "    \"\"\"\n",
        "    Compute MVO portfolio returns and positions. Save outputs in structured folders.\n",
        "\n",
        "    Outputs:\n",
        "    - Daily return CSV\n",
        "    - Static position (weights) CSV\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 0: Setup Folder Structure ===\n",
        "    base_name = os.path.splitext(os.path.basename(original_csv_path))[0]\n",
        "    model_name = \"mvo\"\n",
        "    target_folder = os.path.join(base_name, model_name)\n",
        "\n",
        "    if not os.path.exists(target_folder):\n",
        "        os.makedirs(target_folder)\n",
        "        print(f\"[INFO] Created folder: {target_folder}\")\n",
        "\n",
        "    output_csv_full_path = os.path.join(target_folder, output_return_csv)\n",
        "    output_position_csv_full_path = os.path.join(target_folder, output_position_csv)\n",
        "\n",
        "    # === Step 1: Split Data ===\n",
        "    train = data_split(df, train_start_date, train_end_date).reset_index(drop=True)\n",
        "    trade = data_split(df, trade_start_date, trade_end_date).reset_index(drop=True)\n",
        "\n",
        "    # === Step 2: Process Data for MVO ===\n",
        "    StockData = process_df_for_mvo(train)\n",
        "    TradeData = process_df_for_mvo(trade)\n",
        "\n",
        "    # === Step 3: Compute Returns, Mean, Covariance ===\n",
        "    arStockPrices = np.asarray(StockData)\n",
        "    Rows, Cols = arStockPrices.shape\n",
        "    arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
        "\n",
        "    meanReturns = np.mean(arReturns, axis=0)\n",
        "    covReturns = np.cov(arReturns, rowvar=False)\n",
        "\n",
        "    # === Step 4: Perform Mean-Variance Optimization ===\n",
        "    ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=weight_bounds)\n",
        "    ef_mean.max_sharpe()\n",
        "    cleaned_weights_mean = ef_mean.clean_weights()\n",
        "\n",
        "    # Save weights JSON (optional)\n",
        "    # weights_path = os.path.join(target_folder, \"optimized_weights.json\")\n",
        "    # pd.Series(cleaned_weights_mean).to_json(weights_path)\n",
        "    # print(f\"[INFO] Optimized weights saved to {weights_path}\")\n",
        "\n",
        "    # === Step 5: Allocate Capital ===\n",
        "    allocation = np.array([initial_fund * cleaned_weights_mean[tic] for tic in cleaned_weights_mean.keys()])\n",
        "    first_prices = TradeData.iloc[0].to_numpy()\n",
        "    shares = allocation / first_prices\n",
        "\n",
        "    # === Step 6: Compute Portfolio Value Over Time ===\n",
        "    portfolio_values = TradeData @ shares\n",
        "    MVO_result = pd.DataFrame({\n",
        "        \"date\": TradeData.index,\n",
        "        \"account_value\": portfolio_values\n",
        "    })\n",
        "\n",
        "    # === Step 7: Calculate Daily Returns ===\n",
        "    MVO_result[\"date\"] = pd.to_datetime(MVO_result[\"date\"])\n",
        "    MVO_result.set_index(\"date\", inplace=True)\n",
        "\n",
        "    df_daily_return = MVO_result.copy()\n",
        "    df_daily_return[\"daily_return\"] = df_daily_return[\"account_value\"].pct_change()\n",
        "\n",
        "    df_daily_return = df_daily_return.reset_index()\n",
        "    df_daily_return.loc[0, \"daily_return\"] = 0.0\n",
        "    df_daily_return = df_daily_return[[\"date\", \"daily_return\"]]\n",
        "\n",
        "    # === Step 8: Save Daily Return CSV ===\n",
        "    df_daily_return.to_csv(output_csv_full_path, index=False)\n",
        "    print(f\"[INFO] MVO daily returns saved to {output_csv_full_path}\")\n",
        "\n",
        "    # === Step 9: Save Positions CSV ===\n",
        "    # Since MVO is static allocation, repeat weights for each trade date\n",
        "    df_positions = pd.DataFrame([cleaned_weights_mean] * len(df_daily_return))\n",
        "    df_positions.insert(0, 'date', df_daily_return['date'])\n",
        "\n",
        "    df_positions.to_csv(output_position_csv_full_path, index=False)\n",
        "    print(f\"[INFO] MVO portfolio positions saved to {output_position_csv_full_path}\")\n",
        "\n",
        "    return df_daily_return, df_positions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean-Variance Optimization (MVO) Execution\n",
        "\n",
        "Applies the `run_mvo_portfolio_pipeline` across three datasets using a static Max Sharpe portfolio strategy.\n",
        "\n",
        "### **Workflow**\n",
        "- Trains on historical data to compute optimal weights (bounded between **1%** and **25%** per asset).\n",
        "- Applies static allocation over the trading period (**2023-04-05** to **2025-04-10**).\n",
        "- Initial fund: **\\$1,000,000**.\n",
        "- Outputs saved in `/mvo/` folder within each dataset directory.\n",
        "\n",
        "### **Datasets Processed**\n",
        "1. `2007-2025_no_crypto.csv`  \n",
        "   - **Train**: 2007-06-01 to 2023-04-04\n",
        "2. `2015-2025_crypto.csv`  \n",
        "   - **Train**: 2015-02-02 to 2023-04-04\n",
        "3. `2015-2025_no_crypto.csv`  \n",
        "   - **Train**: 2015-02-02 to 2023-04-04\n",
        "\n",
        "### **Outputs**\n",
        "- `df_daily_return_mvo.csv` : Daily portfolio returns  \n",
        "- `df_positions_mvo.csv` : Static optimized weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] MVO daily returns saved to 2007-2025_no_crypto/mvo/df_daily_return_mvo.csv\n",
            "[INFO] MVO portfolio positions saved to 2007-2025_no_crypto/mvo/df_positions_mvo.csv\n",
            "[INFO] MVO daily returns saved to 2015-2025_crypto/mvo/df_daily_return_mvo.csv\n",
            "[INFO] MVO portfolio positions saved to 2015-2025_crypto/mvo/df_positions_mvo.csv\n",
            "[INFO] MVO daily returns saved to 2015-2025_no_crypto/mvo/df_daily_return_mvo.csv\n",
            "[INFO] MVO portfolio positions saved to 2015-2025_no_crypto/mvo/df_positions_mvo.csv\n"
          ]
        }
      ],
      "source": [
        "TRAIN_START_DATE = '2015-02-02'\n",
        "TRAIN_END_DATE = '2023-04-04'\n",
        "TRADE_START_DATE = '2023-04-05'\n",
        "TRADE_END_DATE = '2025-04-10'\n",
        "\n",
        "df_daily_return_mvo = run_mvo_portfolio_pipeline(\n",
        "    df=processed_0,\n",
        "    train_start_date='2007-06-01',\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.01, 0.25),\n",
        "    output_return_csv='df_daily_return_mvo.csv',\n",
        "    output_position_csv='df_positions_mvo.csv',\n",
        "    original_csv_path='2007-2025_no_crypto.csv'\n",
        ")\n",
        "\n",
        "df_daily_return_mvo = run_mvo_portfolio_pipeline(\n",
        "    df=processed_1,\n",
        "    train_start_date=TRAIN_START_DATE,\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.01, 0.25),\n",
        "    output_return_csv='df_daily_return_mvo.csv',\n",
        "    output_position_csv='df_positions_mvo.csv',\n",
        "    original_csv_path='2015-2025_crypto.csv'\n",
        ")\n",
        "\n",
        "df_daily_return_mvo = run_mvo_portfolio_pipeline(\n",
        "    df=processed_2,\n",
        "    train_start_date=TRAIN_START_DATE,\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.01, 0.25),\n",
        "    output_return_csv='df_daily_return_mvo.csv',\n",
        "    output_position_csv='df_positions_mvo.csv',\n",
        "    original_csv_path='2015-2025_no_crypto.csv'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `run_rolling_mvo_pipeline(...)`\n",
        "\n",
        "Implements a **Rolling Mean-Variance Optimization (MVO)** strategy with periodic rebalancing based on a sliding window.\n",
        "\n",
        "### **Features**\n",
        "- Dynamically recalculates optimal portfolio weights every `window_size` days.\n",
        "- Uses **Max Sharpe Ratio** or falls back to **Min Volatility** if needed.\n",
        "- Supports cumulative training data extension (`train_window_extend`).\n",
        "- Tracks daily portfolio returns and expands positions across rebalancing periods.\n",
        "- Saves outputs in `<dataset>/adaptive_mvo/` folder.\n",
        "\n",
        "### **Parameters**\n",
        "- `train_start_date`, `train_end_date`: Initial training period.\n",
        "- `trade_start_date`, `trade_end_date`: Trading & rebalancing period.\n",
        "- `window_size`: Days per rebalance window.\n",
        "- `weight_bounds`: Allocation constraints per asset.\n",
        "- `initial_fund`: Starting capital.\n",
        "- `buy_cost_pct`, `sell_cost_pct`: Transaction costs.\n",
        "\n",
        "### **Outputs**\n",
        "- `df_daily_return_adaptive_mvo.csv`: Daily returns.\n",
        "- `df_positions_adaptive_mvo.csv`: Expanded daily positions (weights).\n",
        "\n",
        "### **Returns**\n",
        "- Tuple: `(df_daily_return, df_positions)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "\n",
        "def run_rolling_mvo_pipeline(df,\n",
        "                              train_start_date,\n",
        "                              train_end_date,\n",
        "                              trade_start_date,\n",
        "                              trade_end_date,\n",
        "                              window_size=63,\n",
        "                              train_window_extend=True,\n",
        "                              initial_fund=1_000_000,\n",
        "                              weight_bounds=(0.0, 0.5),\n",
        "                              buy_cost_pct=0.0,\n",
        "                              sell_cost_pct=0.0,\n",
        "                              original_csv_path='data.csv',\n",
        "                              model_name='adaptive_mvo',\n",
        "                              output_return_csv='df_daily_return_adaptive_mvo.csv',\n",
        "                              output_position_csv='df_positions_adaptive_mvo.csv'):\n",
        "    \"\"\"\n",
        "    Run Rolling Mean-Variance Optimization (MVO) with rebalancing.\n",
        "    Outputs:\n",
        "      - Daily returns CSV\n",
        "      - Expanded daily positions CSV (weights repeated until next rebalance)\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 1: Setup Folder Structure ===\n",
        "    base_csv_name = os.path.splitext(os.path.basename(original_csv_path))[0]\n",
        "    target_folder = os.path.join(base_csv_name, model_name)\n",
        "    if not os.path.exists(target_folder):\n",
        "        os.makedirs(target_folder)\n",
        "        print(f\"[INFO] Created folder: {target_folder}\")\n",
        "\n",
        "    output_return_csv_path = os.path.join(target_folder, output_return_csv)\n",
        "    output_position_csv_path = os.path.join(target_folder, output_position_csv)\n",
        "\n",
        "    # === Step 2: Data Preparation ===\n",
        "    train_df = data_split(df, train_start_date, train_end_date).reset_index(drop=True)\n",
        "    trade_df = data_split(df, trade_start_date, trade_end_date).reset_index(drop=True)\n",
        "\n",
        "    unique_dates = trade_df.date.unique()\n",
        "    total_windows = len(unique_dates) // window_size\n",
        "\n",
        "    portfolio_values = pd.DataFrame(columns=[\"account_value\"], dtype=float)\n",
        "    portfolio_dates = []\n",
        "    weights_log = []\n",
        "    rebalance_dates = []\n",
        "\n",
        "    train_df_window = train_df.copy()\n",
        "\n",
        "    for w in range(total_windows):\n",
        "        print(f\"\\n[Rebalancing] Window {w+1}/{total_windows}\")\n",
        "\n",
        "        start_idx = w * window_size\n",
        "        end_idx = (w + 1) * window_size\n",
        "        window_dates = unique_dates[start_idx:end_idx]\n",
        "        trade_df_window = trade_df[trade_df['date'].isin(window_dates)].copy()\n",
        "\n",
        "        train_mvo = process_df_for_mvo(train_df_window)\n",
        "        trade_mvo = process_df_for_mvo(trade_df_window)\n",
        "\n",
        "        if train_mvo.empty or len(train_mvo) < 2 or train_mvo.shape[1] < 3:\n",
        "            print(f\"[Window {w}] Skipped due to insufficient data.\")\n",
        "            continue\n",
        "\n",
        "        arReturns = StockReturnsComputing(np.asarray(train_mvo), *train_mvo.shape)\n",
        "        meanReturns = pd.Series(np.mean(arReturns, axis=0), index=train_mvo.columns)\n",
        "        covReturns = pd.DataFrame(np.cov(arReturns, rowvar=False), index=train_mvo.columns, columns=train_mvo.columns)\n",
        "\n",
        "        if meanReturns.std() < 1e-4:\n",
        "            print(f\"[Window {w}] Skipped: flat mean returns.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=weight_bounds)\n",
        "            ef_mean.max_sharpe()\n",
        "            cleaned_weights_mean = ef_mean.clean_weights()\n",
        "        except:\n",
        "            print(f\"[Window {w}] Fallback to min_volatility.\")\n",
        "            ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=weight_bounds)\n",
        "            ef_mean.min_volatility()\n",
        "            cleaned_weights_mean = ef_mean.clean_weights()\n",
        "\n",
        "        weights_log.append(cleaned_weights_mean)\n",
        "        rebalance_dates.append(window_dates[0])  # First date of each window\n",
        "\n",
        "        mvo_weights = np.array([\n",
        "            initial_fund * (1 - buy_cost_pct) * cleaned_weights_mean[key]\n",
        "            for key in cleaned_weights_mean.keys()\n",
        "        ])\n",
        "\n",
        "        first_prices = trade_mvo.head(1).to_numpy()[0]\n",
        "        if np.any(first_prices == 0):\n",
        "            print(f\"[Window {w}] Skipped: zero prices detected.\")\n",
        "            continue\n",
        "\n",
        "        shares = mvo_weights / first_prices\n",
        "        portfolio_series = trade_mvo @ shares\n",
        "        MVO_result = pd.DataFrame(portfolio_series, columns=[\"account_value\"])\n",
        "\n",
        "        dates_in_window = trade_df_window['date'].drop_duplicates().sort_values().tolist()\n",
        "        portfolio_dates.extend(dates_in_window)\n",
        "        portfolio_values = pd.concat([portfolio_values, MVO_result], ignore_index=True)\n",
        "\n",
        "        if train_window_extend:\n",
        "            train_df_window = pd.concat([train_df_window, trade_df_window], ignore_index=True)\n",
        "\n",
        "        initial_fund = MVO_result[\"account_value\"].iloc[-1] * (1 - sell_cost_pct)\n",
        "\n",
        "    # === Step 3: Finalize Portfolio Values ===\n",
        "    portfolio_values.index = pd.to_datetime(portfolio_dates)\n",
        "    df_daily_return = portfolio_values.copy()\n",
        "    df_daily_return[\"daily_return\"] = df_daily_return[\"account_value\"].pct_change()\n",
        "    df_daily_return = df_daily_return.reset_index().rename(columns={\"index\": \"date\"})\n",
        "    df_daily_return.loc[0, \"daily_return\"] = 0.0\n",
        "    df_daily_return = df_daily_return[[\"date\", \"daily_return\"]]\n",
        "\n",
        "    df_daily_return.to_csv(output_return_csv_path, index=False)\n",
        "    print(f\"[INFO] Rolling MVO daily returns saved to {output_return_csv_path}\")\n",
        "\n",
        "    # === Step 4: Expand Positions for Each Date ===\n",
        "    expanded_positions = []\n",
        "    all_dates = pd.to_datetime(portfolio_dates)\n",
        "\n",
        "    for idx, weights in enumerate(weights_log):\n",
        "        start_date = pd.to_datetime(rebalance_dates[idx])\n",
        "        if idx + 1 < len(rebalance_dates):\n",
        "            end_date = pd.to_datetime(rebalance_dates[idx + 1])\n",
        "            mask = (all_dates >= start_date) & (all_dates < end_date)\n",
        "        else:\n",
        "            mask = (all_dates >= start_date)\n",
        "\n",
        "        dates_in_window = all_dates[mask]\n",
        "\n",
        "        weight_values = list(weights.values())\n",
        "        for d in dates_in_window:\n",
        "            expanded_positions.append([d] + weight_values)\n",
        "\n",
        "    df_positions = pd.DataFrame(expanded_positions)\n",
        "    df_positions.columns = ['date'] + [str(i) for i in range(len(weights_log[0]))]\n",
        "\n",
        "    df_positions.to_csv(output_position_csv_path, index=False)\n",
        "    print(f\"[INFO] Rolling MVO expanded positions saved to {output_position_csv_path}\")\n",
        "\n",
        "    return df_daily_return, df_positions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rolling MVO Strategy Execution\n",
        "\n",
        "Applies the `run_rolling_mvo_pipeline` across three datasets with annual (252-day) rebalancing using adaptive Mean-Variance Optimization.\n",
        "\n",
        "### **Workflow**\n",
        "- Recalculates optimal portfolio weights every **252 days**.\n",
        "- Training starts with historical data and extends over time.\n",
        "- Initial capital: **\\$1,000,000** with weight bounds between **1%** and **25%**.\n",
        "- Trading period: **2023-04-05** to **2025-04-10**.\n",
        "- Outputs stored in `/adaptive_mvo/` folders for each dataset.\n",
        "\n",
        "### **Datasets Processed**\n",
        "1. `2007-2025_no_crypto.csv`  \n",
        "   - **Train**: 2007-06-01 to 2023-04-04\n",
        "2. `2015-2025_crypto.csv`  \n",
        "   - **Train**: 2015-02-02 to 2023-04-04\n",
        "3. `2015-2025_no_crypto.csv`  \n",
        "   - **Train**: 2015-02-02 to 2023-04-04\n",
        "\n",
        "### **Outputs**\n",
        "- `df_daily_return_adaptive_mvo.csv` : Daily returns  \n",
        "- `df_positions_adaptive_mvo.csv` : Expanded adaptive portfolio weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Rebalancing] Window 1/2\n",
            "\n",
            "[Rebalancing] Window 2/2\n",
            "[INFO] Rolling MVO daily returns saved to 2007-2025_no_crypto/adaptive_mvo/df_daily_return_adaptive_mvo.csv\n",
            "[INFO] Rolling MVO expanded positions saved to 2007-2025_no_crypto/adaptive_mvo/df_positions_adaptive_mvo.csv\n",
            "\n",
            "[Rebalancing] Window 1/2\n",
            "\n",
            "[Rebalancing] Window 2/2\n",
            "[INFO] Rolling MVO daily returns saved to 2015-2025_crypto/adaptive_mvo/df_daily_return_adaptive_mvo.csv\n",
            "[INFO] Rolling MVO expanded positions saved to 2015-2025_crypto/adaptive_mvo/df_positions_adaptive_mvo.csv\n",
            "\n",
            "[Rebalancing] Window 1/2\n",
            "\n",
            "[Rebalancing] Window 2/2\n",
            "[INFO] Rolling MVO daily returns saved to 2015-2025_no_crypto/adaptive_mvo/df_daily_return_adaptive_mvo.csv\n",
            "[INFO] Rolling MVO expanded positions saved to 2015-2025_no_crypto/adaptive_mvo/df_positions_adaptive_mvo.csv\n"
          ]
        }
      ],
      "source": [
        "TRAIN_START_DATE = '2015-02-02'\n",
        "TRAIN_END_DATE = '2023-04-04'\n",
        "TRADE_START_DATE = '2023-04-05'\n",
        "TRADE_END_DATE = '2025-04-10'\n",
        "\n",
        "df_daily_return, weights_log = run_rolling_mvo_pipeline(\n",
        "    df=processed_0,\n",
        "    train_start_date='2007-06-01',\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    window_size=252,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.01, 0.25),\n",
        "    original_csv_path='2007-2025_no_crypto.csv',  \n",
        "    model_name='adaptive_mvo',\n",
        "    output_return_csv='df_daily_return_adaptive_mvo.csv',\n",
        "    output_position_csv='df_positions_adaptive_mvo.csv'\n",
        ")\n",
        "\n",
        "df_daily_return, weights_log = run_rolling_mvo_pipeline(\n",
        "    df=processed_1,\n",
        "    train_start_date=TRAIN_START_DATE,\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    window_size=252,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.01, 0.25),\n",
        "    original_csv_path='2015-2025_crypto.csv',   \n",
        "    model_name='adaptive_mvo',\n",
        "    output_return_csv='df_daily_return_adaptive_mvo.csv',\n",
        "    output_position_csv='df_positions_adaptive_mvo.csv'\n",
        ")\n",
        "\n",
        "df_daily_return, weights_log = run_rolling_mvo_pipeline(\n",
        "    df=processed_2,\n",
        "    train_start_date=TRAIN_START_DATE,\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    window_size=252,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.01, 0.25),\n",
        "    original_csv_path='2015-2025_no_crypto.csv',   \n",
        "    model_name='adaptive_mvo',\n",
        "    output_return_csv='df_daily_return_adaptive_mvo.csv',\n",
        "    output_position_csv='df_positions_adaptive_mvo.csv'\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
