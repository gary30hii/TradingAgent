{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7Cycmf3Zbok"
      },
      "source": [
        "# Stock NeurIPS2018 Part 3. Backtest\n",
        "This series is a reproduction of paper *the process in the paper Practical Deep Reinforcement Learning Approach for Stock Trading*.\n",
        "\n",
        "This is the third and last part of the NeurIPS2018 series, introducing how to use use the agents we trained to do backtest, and compare with baselines such as Mean Variance Optimization and DJIA index.\n",
        "\n",
        "Other demos can be found at the repo of [FinRL-Tutorials]((https://github.com/AI4Finance-Foundation/FinRL-Tutorials))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oWbj4HgqHBg"
      },
      "source": [
        "# Part 1. Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqfBOKz-qJYF"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# Suppress Warnings\n",
        "# ===========================\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ===========================\n",
        "# Standard Libraries\n",
        "# ===========================\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')  \n",
        "\n",
        "# ===========================\n",
        "# Enable Inline Plotting (Jupyter)\n",
        "# ===========================\n",
        "%matplotlib inline\n",
        "\n",
        "# ===========================\n",
        "# FinRL Imports\n",
        "# ===========================\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "\n",
        "# ===========================\n",
        "# Custom Imports (model.py)\n",
        "# ===========================\n",
        "sys.path.append(os.path.abspath(\".\"))  \n",
        "from models import DRLEnsembleAgent\n",
        "\n",
        "sys.path.append(\"../FinRL-Library\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUF2P4hmqVjh"
      },
      "source": [
        "# Part 2. Backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_csv_to_features(csv_path):\n",
        "    # Step 1: Load Data\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Step 2: Identify 5-day and 7-day tickers\n",
        "    day_values_per_tic = df.groupby('tic')['day'].apply(lambda x: sorted(x.unique())).reset_index()\n",
        "    day_values_per_tic.columns = ['tic', 'unique_days']\n",
        "\n",
        "    tics_5day = day_values_per_tic[day_values_per_tic['unique_days'].apply(lambda x: x == list(range(5)))]['tic']\n",
        "    tics_7day = day_values_per_tic[day_values_per_tic['unique_days'].apply(lambda x: x == list(range(7)))]['tic']\n",
        "\n",
        "    df_5day_full = df[df['tic'].isin(tics_5day)]\n",
        "    df_7day_full = df[df['tic'].isin(tics_7day)]\n",
        "\n",
        "    # Step 3: Apply Technical Indicators\n",
        "    fe_ti = FeatureEngineer(\n",
        "        use_technical_indicator=True,\n",
        "        use_turbulence=False,\n",
        "        user_defined_feature=False\n",
        "    )\n",
        "    df_5day_full = fe_ti.preprocess_data(df_5day_full)\n",
        "    if not df_7day_full.empty:\n",
        "        df_7day_full = fe_ti.preprocess_data(df_7day_full)\n",
        "    else:\n",
        "        print(\"[Info] df_7day_full is empty. Skipping technical indicators.\")\n",
        "\n",
        "    # Step 4: Combine and Clean Index\n",
        "    combined_df = pd.concat([df_5day_full, df_7day_full], ignore_index=False)\n",
        "    combined_df.index = range(len(combined_df))\n",
        "\n",
        "    # Step 5: Remove dates with only one ticker\n",
        "    combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
        "    combined_df = combined_df[combined_df.groupby('date')['date'].transform('count') > 1]\n",
        "    combined_df = combined_df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
        "\n",
        "    # Step 6: Apply Turbulence Feature\n",
        "    fe_turb = FeatureEngineer(\n",
        "        use_technical_indicator=False,\n",
        "        use_turbulence=True,\n",
        "        user_defined_feature=False\n",
        "    )\n",
        "    processed = fe_turb.preprocess_data(combined_df)\n",
        "\n",
        "    # Step 7: Final Cleaning\n",
        "    processed = processed.copy()\n",
        "    processed = processed.fillna(0)\n",
        "    processed = processed.replace(np.inf, 0)\n",
        "\n",
        "    return processed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "[Info] df_7day_full is empty. Skipping technical indicators.\n",
            "Successfully added turbulence index\n",
            "Successfully added technical indicators\n",
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n",
            "Successfully added technical indicators\n",
            "[Info] df_7day_full is empty. Skipping technical indicators.\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "processed_0 = process_csv_to_features('2007-2025_no_crypto.csv')\n",
        "processed_1 = process_csv_to_features('2015-2025_crypto.csv')\n",
        "processed_2 = process_csv_to_features('2015-2025_no_crypto.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcE-t08w6DaW"
      },
      "source": [
        "# Part 3: Mean Variance Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17TUs71EWj09"
      },
      "source": [
        "Mean Variance optimization is a very classic strategy in portfolio management. Here, we go through the whole process to do the mean variance optimization and add it as a baseline to compare.\n",
        "\n",
        "First, process dataframe to the form for MVO weight calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "wungSNOwPwKR"
      },
      "outputs": [],
      "source": [
        "def process_df_for_mvo(df):\n",
        "    df = df.sort_values(['date', 'tic'], ignore_index=True)[['date', 'tic', 'close']]\n",
        "    all_tickers = sorted(df['tic'].unique())\n",
        "    ticker_index = {tic: idx for idx, tic in enumerate(all_tickers)}\n",
        "    stock_dimension = len(all_tickers)\n",
        "\n",
        "    mvo = pd.DataFrame(columns=all_tickers)\n",
        "\n",
        "    grouped = df.groupby('date')\n",
        "    for date, group in grouped:\n",
        "        row = [np.nan] * stock_dimension\n",
        "        for _, row_data in group.iterrows():\n",
        "            row[ticker_index[row_data['tic']]] = row_data['close']\n",
        "        if not any(pd.isna(row)):  # only include dates with all tickers\n",
        "            mvo.loc[date] = row\n",
        "\n",
        "    return mvo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwEwkHJ1d_6u"
      },
      "source": [
        "### Helper functions for mean returns and variance-covariance matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "6KvXkpyE8MFq"
      },
      "outputs": [],
      "source": [
        "# Codes in this section partially refer to Dr G A Vijayalakshmi Pai\n",
        "\n",
        "# https://www.kaggle.com/code/vijipai/lesson-5-mean-variance-optimization-of-portfolios/notebook\n",
        "\n",
        "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
        "  import numpy as np\n",
        "  StockReturn = np.zeros([Rows-1, Columns])\n",
        "  for j in range(Columns):        # j: Assets\n",
        "    for i in range(Rows-1):     # i: Daily Prices\n",
        "      StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100\n",
        "\n",
        "  return StockReturn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def run_naive_portfolio_pipeline(df, \n",
        "                                  start_date, \n",
        "                                  end_date, \n",
        "                                  initial_fund=1_000_000, \n",
        "                                  buy_cost_pct=0.0, \n",
        "                                  output_return_csv='df_daily_return_naive.csv',\n",
        "                                  original_csv_path='data.csv',\n",
        "                                  model_name='naive'):\n",
        "    \"\"\"\n",
        "    Compute naive equal-weighted portfolio returns and save outputs in structured folders.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Processed dataframe containing 'date', 'tic', and 'close'.\n",
        "    start_date : str\n",
        "        Start date in 'YYYY-MM-DD' format.\n",
        "    end_date : str\n",
        "        End date in 'YYYY-MM-DD' format.\n",
        "    initial_fund : float\n",
        "        Starting capital.\n",
        "    buy_cost_pct : float\n",
        "        Transaction cost percentage on initial buy.\n",
        "    output_return_csv : str\n",
        "        Filename for saving daily returns CSV.\n",
        "    original_csv_path : str\n",
        "        The path of the original CSV to derive folder name.\n",
        "    model_name : str\n",
        "        Name of the model to create subfolder (e.g., 'naive').\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 0: Setup Folder Structure ===\n",
        "    base_name = os.path.splitext(os.path.basename(original_csv_path))[0]\n",
        "    target_folder = os.path.join(base_name, model_name)\n",
        "    if not os.path.exists(target_folder):\n",
        "        os.makedirs(target_folder)\n",
        "        print(f\"[INFO] Created folder: {target_folder}\")\n",
        "\n",
        "    # Step 1: Filter trade data\n",
        "    trade_df = data_split(df, start_date, end_date).reset_index(drop=True)\n",
        "    trade_df = trade_df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
        "\n",
        "    # Step 2: Process for MVO-like structure\n",
        "    trade_mvo = process_df_for_mvo(trade_df)\n",
        "\n",
        "    if trade_mvo.empty or len(trade_mvo) < 1:\n",
        "        raise ValueError(\"Insufficient data for naive portfolio.\")\n",
        "\n",
        "    tickers = trade_mvo.columns.tolist()\n",
        "    stock_dimension = len(tickers)\n",
        "\n",
        "    # Step 3: Equal weight allocation\n",
        "    first_prices = trade_mvo.iloc[0].to_numpy()\n",
        "    if np.any(first_prices == 0):\n",
        "        raise ValueError(\"Zero price detected in first trading day.\")\n",
        "\n",
        "    equal_weight = 1.0 / stock_dimension\n",
        "    allocation_per_asset = initial_fund * (1 - buy_cost_pct) * equal_weight\n",
        "    shares = allocation_per_asset / first_prices\n",
        "\n",
        "    # Step 4: Calculate portfolio value\n",
        "    portfolio_values = trade_mvo @ shares\n",
        "    result_df = pd.DataFrame({\n",
        "        \"date\": trade_mvo.index,\n",
        "        \"account_value\": portfolio_values\n",
        "    })\n",
        "\n",
        "    # Step 5: Compute daily returns\n",
        "    result_df[\"date\"] = pd.to_datetime(result_df[\"date\"])\n",
        "    result_df.set_index(\"date\", inplace=True)\n",
        "\n",
        "    df_daily_return = result_df.copy()\n",
        "    df_daily_return[\"daily_return\"] = df_daily_return[\"account_value\"].pct_change()\n",
        "    df_daily_return = df_daily_return.reset_index()\n",
        "\n",
        "    df_daily_return.loc[0, \"daily_return\"] = 0.0\n",
        "    df_daily_return = df_daily_return[[\"date\", \"daily_return\"]]\n",
        "\n",
        "    # Step 6: Export to /data/naive/\n",
        "    csv_full_path = os.path.join(target_folder, output_return_csv)\n",
        "    df_daily_return.to_csv(csv_full_path, index=False)\n",
        "    print(f\"[INFO] Naive portfolio daily returns saved to {csv_full_path}\")\n",
        "\n",
        "    return df_daily_return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Created folder: 2007-2025_no_crypto/naive\n",
            "[INFO] Naive portfolio daily returns saved to 2007-2025_no_crypto/naive/df_daily_return_naive.csv\n",
            "[INFO] Created folder: 2015-2025_crypto/naive\n",
            "[INFO] Naive portfolio daily returns saved to 2015-2025_crypto/naive/df_daily_return_naive.csv\n",
            "[INFO] Created folder: 2015-2025_no_crypto/naive\n",
            "[INFO] Naive portfolio daily returns saved to 2015-2025_no_crypto/naive/df_daily_return_naive.csv\n"
          ]
        }
      ],
      "source": [
        "TRADE_START_DATE = '2023-04-05'\n",
        "TRADE_END_DATE = '2025-04-10'\n",
        "\n",
        "df_daily_return_naive = run_naive_portfolio_pipeline(\n",
        "    df=processed_0,\n",
        "    start_date=TRADE_START_DATE,\n",
        "    end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    buy_cost_pct=0.001,  \n",
        "    output_return_csv='df_daily_return_naive.csv',\n",
        "    original_csv_path='2007-2025_no_crypto.csv',   \n",
        "    model_name='naive'             \n",
        ")\n",
        "df_daily_return_naive = run_naive_portfolio_pipeline(\n",
        "    df=processed_1,\n",
        "    start_date=TRADE_START_DATE,\n",
        "    end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    buy_cost_pct=0.001,  \n",
        "    output_return_csv='df_daily_return_naive.csv',\n",
        "    original_csv_path='2015-2025_crypto.csv',   \n",
        "    model_name='naive'             \n",
        ")\n",
        "df_daily_return_naive = run_naive_portfolio_pipeline(\n",
        "    df=processed_2,\n",
        "    start_date=TRADE_START_DATE,\n",
        "    end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    buy_cost_pct=0.001,  \n",
        "    output_return_csv='df_daily_return_naive.csv',\n",
        "    original_csv_path='2015-2025_no_crypto.csv',   \n",
        "    model_name='naive'             \n",
        ")\n",
        "\n",
        "# processed_0 = process_csv_to_features('2007-2025_no_crypto.csv')\n",
        "# processed_1 = process_csv_to_features('2015-2025_crypto.csv')\n",
        "# processed_2 = process_csv_to_features('2015-2025_no_crypto.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeVVbuwveJ_5"
      },
      "source": [
        "### Calculate the weights for mean-variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "b1btTONEdCU4"
      },
      "outputs": [],
      "source": [
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "\n",
        "def run_mvo_portfolio_pipeline(df, \n",
        "                                train_start_date, \n",
        "                                train_end_date, \n",
        "                                trade_start_date, \n",
        "                                trade_end_date, \n",
        "                                initial_fund=1_000_000, \n",
        "                                weight_bounds=(0.01, 0.25), \n",
        "                                output_return_csv='df_daily_return_mvo.csv',\n",
        "                                original_csv_path='data.csv'):\n",
        "    \"\"\"\n",
        "    Compute MVO portfolio returns, save outputs in structured folders.\n",
        "\n",
        "    Folder Structure: \n",
        "    - <csv_name>/<model_name>/ (e.g., data/mvo/)\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 0: Setup Folder Structure ===\n",
        "    base_name = os.path.splitext(os.path.basename(original_csv_path))[0]\n",
        "    model_name = \"mvo\"\n",
        "    target_folder = os.path.join(base_name, model_name)\n",
        "\n",
        "    if not os.path.exists(target_folder):\n",
        "        os.makedirs(target_folder)\n",
        "        print(f\"[INFO] Created folder: {target_folder}\")\n",
        "\n",
        "    # Adjust output CSV path to be within the folder\n",
        "    output_csv_full_path = os.path.join(target_folder, output_return_csv)\n",
        "\n",
        "    # === Step 1: Split Data ===\n",
        "    train = data_split(df, train_start_date, train_end_date).reset_index(drop=True)\n",
        "    trade = data_split(df, trade_start_date, trade_end_date).reset_index(drop=True)\n",
        "\n",
        "    # === Step 2: Process Data for MVO ===\n",
        "    StockData = process_df_for_mvo(train)\n",
        "    TradeData = process_df_for_mvo(trade)\n",
        "\n",
        "    # === Step 3: Compute Returns, Mean, Covariance ===\n",
        "    arStockPrices = np.asarray(StockData)\n",
        "    Rows, Cols = arStockPrices.shape\n",
        "    arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
        "\n",
        "    meanReturns = np.mean(arReturns, axis=0)\n",
        "    covReturns = np.cov(arReturns, rowvar=False)\n",
        "\n",
        "    # === Step 4: Perform Mean-Variance Optimization ===\n",
        "    ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=weight_bounds)\n",
        "    ef_mean.max_sharpe()\n",
        "    cleaned_weights_mean = ef_mean.clean_weights()\n",
        "\n",
        "    # Optional: Save weights to file\n",
        "    weights_path = os.path.join(target_folder, \"optimized_weights.json\")\n",
        "    pd.Series(cleaned_weights_mean).to_json(weights_path)\n",
        "    print(f\"[INFO] Optimized weights saved to {weights_path}\")\n",
        "\n",
        "    # === Step 5: Allocate Capital ===\n",
        "    allocation = np.array([initial_fund * cleaned_weights_mean[tic] for tic in cleaned_weights_mean.keys()])\n",
        "    first_prices = TradeData.iloc[0].to_numpy()\n",
        "    shares = allocation / first_prices\n",
        "\n",
        "    # === Step 6: Compute Portfolio Value Over Time ===\n",
        "    portfolio_values = TradeData @ shares\n",
        "    MVO_result = pd.DataFrame({\n",
        "        \"date\": TradeData.index,\n",
        "        \"account_value\": portfolio_values\n",
        "    })\n",
        "\n",
        "    # === Step 7: Calculate Daily Returns ===\n",
        "    MVO_result[\"date\"] = pd.to_datetime(MVO_result[\"date\"])\n",
        "    MVO_result.set_index(\"date\", inplace=True)\n",
        "\n",
        "    df_daily_return = MVO_result.copy()\n",
        "    df_daily_return[\"daily_return\"] = df_daily_return[\"account_value\"].pct_change()\n",
        "\n",
        "    df_daily_return = df_daily_return.reset_index()\n",
        "    df_daily_return.loc[0, \"daily_return\"] = 0.0\n",
        "    df_daily_return = df_daily_return[[\"date\", \"daily_return\"]]\n",
        "\n",
        "    # === Step 8: Save Daily Return CSV ===\n",
        "    df_daily_return.to_csv(output_csv_full_path, index=False)\n",
        "    print(f\"[INFO] MVO daily returns saved to {output_csv_full_path}\")\n",
        "\n",
        "    return df_daily_return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Created folder: 2007-2025_no_crypto/mvo\n",
            "[INFO] Optimized weights saved to 2007-2025_no_crypto/mvo/optimized_weights.json\n",
            "[INFO] MVO daily returns saved to 2007-2025_no_crypto/mvo/df_daily_return_mvo.csv\n",
            "[INFO] Created folder: 2015-2025_crypto/mvo\n",
            "[INFO] Optimized weights saved to 2015-2025_crypto/mvo/optimized_weights.json\n",
            "[INFO] MVO daily returns saved to 2015-2025_crypto/mvo/df_daily_return_mvo.csv\n",
            "[INFO] Created folder: 2015-2025_no_crypto/mvo\n",
            "[INFO] Optimized weights saved to 2015-2025_no_crypto/mvo/optimized_weights.json\n",
            "[INFO] MVO daily returns saved to 2015-2025_no_crypto/mvo/df_daily_return_mvo.csv\n"
          ]
        }
      ],
      "source": [
        "TRAIN_START_DATE = '2015-02-02'\n",
        "TRAIN_END_DATE = '2023-04-04'\n",
        "TRADE_START_DATE = '2023-04-05'\n",
        "TRADE_END_DATE = '2025-04-10'\n",
        "\n",
        "df_daily_return_mvo = run_mvo_portfolio_pipeline(\n",
        "    df=processed_0,\n",
        "    train_start_date='2007-06-01',\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.01, 0.25),\n",
        "    output_return_csv='df_daily_return_mvo.csv',\n",
        "    original_csv_path='2007-2025_no_crypto.csv'\n",
        ")\n",
        "\n",
        "df_daily_return_mvo = run_mvo_portfolio_pipeline(\n",
        "    df=processed_1,\n",
        "    train_start_date=TRAIN_START_DATE,\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.01, 0.25),\n",
        "    output_return_csv='df_daily_return_mvo.csv',\n",
        "    original_csv_path='2015-2025_crypto.csv'\n",
        ")\n",
        "\n",
        "df_daily_return_mvo = run_mvo_portfolio_pipeline(\n",
        "    df=processed_2,\n",
        "    train_start_date=TRAIN_START_DATE,\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.01, 0.25),\n",
        "    output_return_csv='df_daily_return_mvo.csv',\n",
        "    original_csv_path='2015-2025_no_crypto.csv'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# processed_0 = process_csv_to_features('2007-2025_no_crypto.csv')\n",
        "# processed_1 = process_csv_to_features('2015-2025_crypto.csv')\n",
        "# processed_2 = process_csv_to_features('2015-2025_no_crypto.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def run_rolling_mvo_pipeline(df,\n",
        "                              train_start_date,\n",
        "                              train_end_date,\n",
        "                              trade_start_date,\n",
        "                              trade_end_date,\n",
        "                              window_size=63,\n",
        "                              train_window_extend=True,\n",
        "                              initial_fund=1_000_000,\n",
        "                              weight_bounds=(0.0, 0.5),\n",
        "                              buy_cost_pct=0.0,\n",
        "                              sell_cost_pct=0.0,\n",
        "                              original_csv_path='data.csv',\n",
        "                              model_name='adaptive_mvo',\n",
        "                              output_return_csv='df_daily_return_adaptive_mvo.csv'):\n",
        "    \"\"\"\n",
        "    Run Rolling Mean-Variance Optimization (MVO) with rebalancing and export daily returns.\n",
        "    All outputs are saved in /<csv_name>/<model_name>/.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 1: Setup Folder Structure ===\n",
        "    base_csv_name = os.path.splitext(os.path.basename(original_csv_path))[0]\n",
        "    target_folder = os.path.join(base_csv_name, model_name)\n",
        "    if not os.path.exists(target_folder):\n",
        "        os.makedirs(target_folder)\n",
        "        print(f\"[INFO] Created folder: {target_folder}\")\n",
        "\n",
        "    # Adjust output CSV path\n",
        "    output_return_csv = os.path.join(target_folder, output_return_csv)\n",
        "\n",
        "    # === Step 2: Data Preparation ===\n",
        "    train_df = data_split(df, train_start_date, train_end_date).reset_index(drop=True)\n",
        "    trade_df = data_split(df, trade_start_date, trade_end_date).reset_index(drop=True)\n",
        "\n",
        "    stock_dimension = len(trade_df.tic.unique())\n",
        "    unique_dates = trade_df.date.unique()\n",
        "    total_windows = len(unique_dates) // window_size\n",
        "\n",
        "    portfolio_values = pd.DataFrame(columns=[\"account_value\"], dtype=float)\n",
        "    portfolio_dates = []\n",
        "    weights_log = []\n",
        "\n",
        "    train_df_window = train_df.copy()\n",
        "\n",
        "    for w in range(total_windows):\n",
        "        print(f\"\\n[Rebalancing] Window {w+1}/{total_windows}\")\n",
        "\n",
        "        start_idx = w * window_size\n",
        "        end_idx = (w + 1) * window_size\n",
        "        window_dates = unique_dates[start_idx:end_idx]\n",
        "        trade_df_window = trade_df[trade_df['date'].isin(window_dates)].copy()\n",
        "\n",
        "        train_mvo = process_df_for_mvo(train_df_window)\n",
        "        trade_mvo = process_df_for_mvo(trade_df_window)\n",
        "\n",
        "        if train_mvo.empty or len(train_mvo) < 2 or train_mvo.shape[1] < 3:\n",
        "            print(f\"[Window {w}] Skipped due to insufficient data.\")\n",
        "            continue\n",
        "\n",
        "        arReturns = StockReturnsComputing(np.asarray(train_mvo), *train_mvo.shape)\n",
        "        meanReturns = pd.Series(np.mean(arReturns, axis=0), index=train_mvo.columns)\n",
        "        covReturns = pd.DataFrame(np.cov(arReturns, rowvar=False), index=train_mvo.columns, columns=train_mvo.columns)\n",
        "\n",
        "        if meanReturns.std() < 1e-4:\n",
        "            print(f\"[Window {w}] Skipped: flat mean returns.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=weight_bounds)\n",
        "            ef_mean.max_sharpe()\n",
        "            cleaned_weights_mean = ef_mean.clean_weights()\n",
        "        except:\n",
        "            print(f\"[Window {w}] Fallback to min_volatility.\")\n",
        "            ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=weight_bounds)\n",
        "            ef_mean.min_volatility()\n",
        "            cleaned_weights_mean = ef_mean.clean_weights()\n",
        "\n",
        "        weights_log.append(cleaned_weights_mean)\n",
        "\n",
        "        mvo_weights = np.array([\n",
        "            initial_fund * (1 - buy_cost_pct) * cleaned_weights_mean[key]\n",
        "            for key in cleaned_weights_mean.keys()\n",
        "        ])\n",
        "\n",
        "        first_prices = trade_mvo.head(1).to_numpy()[0]\n",
        "        if np.any(first_prices == 0):\n",
        "            print(f\"[Window {w}] Skipped: zero prices detected.\")\n",
        "            continue\n",
        "\n",
        "        shares = mvo_weights / first_prices\n",
        "        portfolio_series = trade_mvo @ shares\n",
        "        MVO_result = pd.DataFrame(portfolio_series, columns=[\"account_value\"])\n",
        "\n",
        "        dates_in_window = trade_df_window['date'].drop_duplicates().sort_values().tolist()\n",
        "        portfolio_dates.extend(dates_in_window)\n",
        "        portfolio_values = pd.concat([portfolio_values, MVO_result], ignore_index=True)\n",
        "\n",
        "        if train_window_extend:\n",
        "            train_df_window = pd.concat([train_df_window, trade_df_window], ignore_index=True)\n",
        "\n",
        "        initial_fund = MVO_result[\"account_value\"].iloc[-1] * (1 - sell_cost_pct)\n",
        "\n",
        "    # === Step 3: Finalize Portfolio Values ===\n",
        "    portfolio_values.index = pd.to_datetime(portfolio_dates)\n",
        "\n",
        "    # Calculate daily returns\n",
        "    df_daily_return = portfolio_values.copy()\n",
        "    df_daily_return[\"daily_return\"] = df_daily_return[\"account_value\"].pct_change()\n",
        "    df_daily_return = df_daily_return.reset_index().rename(columns={\"index\": \"date\"})\n",
        "    df_daily_return.loc[0, \"daily_return\"] = 0.0\n",
        "    df_daily_return = df_daily_return[[\"date\", \"daily_return\"]]\n",
        "\n",
        "    # Save daily return CSV\n",
        "    df_daily_return.to_csv(output_return_csv, index=False)\n",
        "    print(f\"[INFO] Rolling MVO daily returns saved to {output_return_csv}\")\n",
        "\n",
        "    # === Optional: Save Weights Log ===\n",
        "    weights_log_path = os.path.join(target_folder, \"weights_log.txt\")\n",
        "    with open(weights_log_path, 'w') as f:\n",
        "        for idx, weights in enumerate(weights_log):\n",
        "            f.write(f\"Window {idx+1} Weights:\\n{weights}\\n\\n\")\n",
        "    print(f\"[INFO] Weights log saved to {weights_log_path}\")\n",
        "\n",
        "    return df_daily_return, weights_log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Created folder: 2007-2025_no_crypto/adaptive_mvo\n",
            "\n",
            "[Rebalancing] Window 1/8\n",
            "\n",
            "[Rebalancing] Window 2/8\n",
            "\n",
            "[Rebalancing] Window 3/8\n",
            "\n",
            "[Rebalancing] Window 4/8\n",
            "\n",
            "[Rebalancing] Window 5/8\n",
            "\n",
            "[Rebalancing] Window 6/8\n",
            "\n",
            "[Rebalancing] Window 7/8\n",
            "\n",
            "[Rebalancing] Window 8/8\n",
            "[INFO] Rolling MVO daily returns saved to 2007-2025_no_crypto/adaptive_mvo/df_daily_return_adaptive_mvo.csv\n",
            "[INFO] Weights log saved to 2007-2025_no_crypto/adaptive_mvo/weights_log.txt\n",
            "[INFO] Created folder: 2015-2025_crypto/adaptive_mvo\n",
            "\n",
            "[Rebalancing] Window 1/8\n",
            "\n",
            "[Rebalancing] Window 2/8\n",
            "\n",
            "[Rebalancing] Window 3/8\n",
            "\n",
            "[Rebalancing] Window 4/8\n",
            "\n",
            "[Rebalancing] Window 5/8\n",
            "\n",
            "[Rebalancing] Window 6/8\n",
            "\n",
            "[Rebalancing] Window 7/8\n",
            "\n",
            "[Rebalancing] Window 8/8\n",
            "[INFO] Rolling MVO daily returns saved to 2015-2025_crypto/adaptive_mvo/df_daily_return_adaptive_mvo.csv\n",
            "[INFO] Weights log saved to 2015-2025_crypto/adaptive_mvo/weights_log.txt\n",
            "[INFO] Created folder: 2015-2025_no_crypto/adaptive_mvo\n",
            "\n",
            "[Rebalancing] Window 1/8\n",
            "\n",
            "[Rebalancing] Window 2/8\n",
            "\n",
            "[Rebalancing] Window 3/8\n",
            "\n",
            "[Rebalancing] Window 4/8\n",
            "\n",
            "[Rebalancing] Window 5/8\n",
            "\n",
            "[Rebalancing] Window 6/8\n",
            "\n",
            "[Rebalancing] Window 7/8\n",
            "\n",
            "[Rebalancing] Window 8/8\n",
            "[INFO] Rolling MVO daily returns saved to 2015-2025_no_crypto/adaptive_mvo/df_daily_return_adaptive_mvo.csv\n",
            "[INFO] Weights log saved to 2015-2025_no_crypto/adaptive_mvo/weights_log.txt\n"
          ]
        }
      ],
      "source": [
        "TRAIN_START_DATE = '2015-02-02'\n",
        "TRAIN_END_DATE = '2023-04-04'\n",
        "TRADE_START_DATE = '2023-04-05'\n",
        "TRADE_END_DATE = '2025-04-10'\n",
        "\n",
        "df_daily_return, weights_log = run_rolling_mvo_pipeline(\n",
        "    df=processed_0,\n",
        "    train_start_date='2007-06-01',\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    window_size=63,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.0, 0.5),\n",
        "    original_csv_path='2007-2025_no_crypto.csv',  \n",
        "    model_name='adaptive_mvo',\n",
        "    output_return_csv='df_daily_return_adaptive_mvo.csv'\n",
        ")\n",
        "\n",
        "df_daily_return, weights_log = run_rolling_mvo_pipeline(\n",
        "    df=processed_1,\n",
        "    train_start_date=TRAIN_START_DATE,\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    window_size=63,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.0, 0.5),\n",
        "    original_csv_path='2015-2025_crypto.csv',   \n",
        "    model_name='adaptive_mvo',\n",
        "    output_return_csv='df_daily_return_adaptive_mvo.csv'\n",
        ")\n",
        "\n",
        "df_daily_return, weights_log = run_rolling_mvo_pipeline(\n",
        "    df=processed_2,\n",
        "    train_start_date=TRAIN_START_DATE,\n",
        "    train_end_date=TRAIN_END_DATE,\n",
        "    trade_start_date=TRADE_START_DATE,\n",
        "    trade_end_date=TRADE_END_DATE,\n",
        "    window_size=63,\n",
        "    initial_fund=1_000_000,\n",
        "    weight_bounds=(0.0, 0.5),\n",
        "    original_csv_path='2015-2025_no_crypto.csv',   \n",
        "    model_name='adaptive_mvo',\n",
        "    output_return_csv='df_daily_return_adaptive_mvo.csv'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# processed_0 = process_csv_to_features('2007-2025_no_crypto.csv')\n",
        "# processed_1 = process_csv_to_features('2015-2025_crypto.csv')\n",
        "# processed_2 = process_csv_to_features('2015-2025_no_crypto.csv')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
