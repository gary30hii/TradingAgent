{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb9q2_QZgdNk"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
        "\n",
        "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
        "\n",
        "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
        "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
        "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mPT0ipYE28wL",
        "outputId": "912ac487-d3c8-467f-ef2a-968fa655b206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wrds in /opt/anaconda3/lib/python3.12/site-packages (3.3.0)\n",
            "Requirement already satisfied: packaging<=24.2 in /opt/anaconda3/lib/python3.12/site-packages (from wrds) (24.1)\n",
            "Requirement already satisfied: pandas<2.3,>=2.2 in /opt/anaconda3/lib/python3.12/site-packages (from wrds) (2.2.3)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from wrds) (2.9.10)\n",
            "Requirement already satisfied: sqlalchemy<2.1,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from wrds) (2.0.34)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<2.3,>=2.2->wrds) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<2.3,>=2.2->wrds) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<2.3,>=2.2->wrds) (2023.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from sqlalchemy<2.1,>=2->wrds) (4.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.16.0)\n",
            "Requirement already satisfied: swig in /opt/anaconda3/lib/python3.12/site-packages (4.3.0)\n",
            "zsh:1: command not found: apt-get\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /private/var/folders/ks/bjl76g8d4zxgw0m5p8z2pd9r0000gn/T/pip-req-build-h29_kopq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /private/var/folders/ks/bjl76g8d4zxgw0m5p8z2pd9r0000gn/T/pip-req-build-h29_kopq\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit d25d902a6de54931a329adc38a2663e8f576adc4\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git (from finrl==0.3.8)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /private/var/folders/ks/bjl76g8d4zxgw0m5p8z2pd9r0000gn/T/pip-install-85ygn7pl/elegantrl_2cb7f0126a7244d7a1aae98c00b1934b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /private/var/folders/ks/bjl76g8d4zxgw0m5p8z2pd9r0000gn/T/pip-install-85ygn7pl/elegantrl_2cb7f0126a7244d7a1aae98c00b1934b\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 5e828af1503098f4da046c0f12432dbd4ef8bd97\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: alpaca-py<0.38,>=0.37 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (0.37.0)\n",
            "Requirement already satisfied: alpaca-trade-api<4,>=3 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (3.2.0)\n",
            "Requirement already satisfied: ccxt<4,>=3 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (3.1.60)\n",
            "Requirement already satisfied: jqdatasdk<2,>=1 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (1.9.7)\n",
            "Requirement already satisfied: pyfolio-reloaded<0.10,>=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (0.9.8)\n",
            "Requirement already satisfied: pyportfolioopt<2,>=1 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (1.5.6)\n",
            "Requirement already satisfied: ray<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2.44.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (1.6.1)\n",
            "Requirement already satisfied: selenium<5,>=4 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (4.31.0)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0a5 in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.5.0)\n",
            "Requirement already satisfied: stockstats<0.6,>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (0.5.4)\n",
            "Requirement already satisfied: webdriver-manager<5,>=4 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (4.0.2)\n",
            "Requirement already satisfied: wrds<4,>=3 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (3.3.0)\n",
            "Requirement already satisfied: yfinance<0.3,>=0.2 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (0.2.55)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (1.0.3)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.2.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.32.3)\n",
            "Requirement already satisfied: sseclient-py<2.0.0,>=1.7.2 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (1.8.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (10.4)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (1.26.4)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (1.26.20)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (1.8.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (3.10.5)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (6.0.1)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (2.1.0)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.8) (24.1)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from ccxt<4,>=3->finrl==0.3.8) (75.1.0)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from ccxt<4,>=3->finrl==0.3.8) (2025.1.31)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from ccxt<4,>=3->finrl==0.3.8) (43.0.0)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from ccxt<4,>=3->finrl==0.3.8) (3.2.0)\n",
            "Requirement already satisfied: yarl>=1.7.2 in /opt/anaconda3/lib/python3.12/site-packages (from ccxt<4,>=3->finrl==0.3.8) (1.11.0)\n",
            "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (1.16.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /opt/anaconda3/lib/python3.12/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (2.0.34)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /opt/anaconda3/lib/python3.12/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (1.1.1)\n",
            "Requirement already satisfied: thriftpy2!=0.5.1,>=0.3.9 in /opt/anaconda3/lib/python3.12/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (0.5.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (8.27.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.9.2)\n",
            "Requirement already satisfied: pytz>=2014.10 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2024.1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.13.1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.13.2)\n",
            "Requirement already satisfied: empyrical-reloaded>=0.5.9 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.5.11)\n",
            "Requirement already satisfied: cvxpy>=1.1.19 in /opt/anaconda3/lib/python3.12/site-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (1.6.4)\n",
            "Requirement already satisfied: ecos<3.0.0,>=2.0.14 in /opt/anaconda3/lib/python3.12/site-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (2.0.14)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (5.24.1)\n",
            "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (8.1.7)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (4.23.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (4.25.3)\n",
            "Requirement already satisfied: aiosignal in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (1.2.0)\n",
            "Requirement already satisfied: frozenlist in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (1.4.0)\n",
            "Requirement already satisfied: aiohttp-cors in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.8.1)\n",
            "Requirement already satisfied: colorful in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.5.6)\n",
            "Requirement already satisfied: opencensus in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.11.4)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.14.1)\n",
            "Requirement already satisfied: smart-open in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (5.2.1)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (20.30.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (1.71.0)\n",
            "Requirement already satisfied: py-spy>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.4.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (19.0.1)\n",
            "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2024.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn<2,>=1->finrl==0.3.8) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn<2,>=1->finrl==0.3.8) (3.5.0)\n",
            "Requirement already satisfied: trio~=0.17 in /opt/anaconda3/lib/python3.12/site-packages (from selenium<5,>=4->finrl==0.3.8) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium<5,>=4->finrl==0.3.8) (0.12.2)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium<5,>=4->finrl==0.3.8) (4.11.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.0.0)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.6.0)\n",
            "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.0.0)\n",
            "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.19.0)\n",
            "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (5.9.0)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (4.66.5)\n",
            "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (13.7.1)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.10.2)\n",
            "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (10.4.0)\n",
            "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager<5,>=4->finrl==0.3.8) (0.21.0)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from wrds<4,>=3->finrl==0.3.8) (2.9.10)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (3.10.0)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (2.4.2)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (3.17.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (4.12.3)\n",
            "Requirement already satisfied: th in /opt/anaconda3/lib/python3.12/site-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.8) (0.4.1)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.8) (4.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (2.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (25.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (6.0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.8) (2.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.8) (1.17.1)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (1.0.3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (0.10.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /opt/anaconda3/lib/python3.12/site-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (3.2.7.post2)\n",
            "Requirement already satisfied: bottleneck>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from empyrical-reloaded>=0.5.9->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.3.7)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.0.4)\n",
            "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.15.1)\n",
            "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (5.14.3)\n",
            "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (4.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (2023.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from plotly<6.0.0,>=5.0.0->pyportfolioopt<2,>=1->finrl==0.3.8) (8.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.8) (3.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.0.3)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /opt/anaconda3/lib/python3.12/site-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.8) (3.0.12)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /opt/anaconda3/lib/python3.12/site-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.8) (3.11)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (2.4.0)\n",
            "Requirement already satisfied: outcome in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (1.3.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /opt/anaconda3/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.8) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium<5,>=4->finrl==0.3.8) (1.7.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/anaconda3/lib/python3.12/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.8) (0.3.9)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (0.10.6)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (2.24.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.2.0)\n",
            "Requirement already satisfied: niltype<2.0,>=0.3 in /opt/anaconda3/lib/python3.12/site-packages (from th->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.8) (1.0.2)\n",
            "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.8) (2.21)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (1.69.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (2.38.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.8.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.1.3)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.8) (0.14.0)\n",
            "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.8.3)\n",
            "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.0.5)\n",
            "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.4.8)\n",
            "Requirement already satisfied: pandas_market_calendars in /opt/anaconda3/lib/python3.12/site-packages (5.0.0)\n",
            "Requirement already satisfied: pandas>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas_market_calendars) (2.2.3)\n",
            "Requirement already satisfied: tzdata in /opt/anaconda3/lib/python3.12/site-packages (from pandas_market_calendars) (2023.3)\n",
            "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.12/site-packages (from pandas_market_calendars) (2.9.0.post0)\n",
            "Requirement already satisfied: exchange-calendars>=3.3 in /opt/anaconda3/lib/python3.12/site-packages (from pandas_market_calendars) (4.10)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (1.26.4)\n",
            "Requirement already satisfied: pyluach in /opt/anaconda3/lib/python3.12/site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (2.2.0)\n",
            "Requirement already satisfied: toolz in /opt/anaconda3/lib/python3.12/site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (0.12.0)\n",
            "Requirement already satisfied: korean_lunar_calendar in /opt/anaconda3/lib/python3.12/site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (0.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.1->pandas_market_calendars) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil->pandas_market_calendars) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# ## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
        "!pip install pandas_market_calendars\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them.\n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "EeMK7Uentj1V"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# Suppress Warnings\n",
        "# ===========================\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ===========================\n",
        "# Standard Libraries\n",
        "# ===========================\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')  \n",
        "\n",
        "# ===========================\n",
        "# Enable Inline Plotting (Jupyter)\n",
        "# ===========================\n",
        "%matplotlib inline\n",
        "\n",
        "# ===========================\n",
        "# FinRL Imports\n",
        "# ===========================\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        ")\n",
        "\n",
        "# ===========================\n",
        "# Create Necessary Directories\n",
        "# ===========================\n",
        "check_and_make_directories([\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR\n",
        "])\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# Custom Imports (model.py)\n",
        "# ===========================\n",
        "sys.path.append(os.path.abspath(\".\"))  \n",
        "from models import DRLEnsembleAgent\n",
        "\n",
        "sys.path.append(\"../FinRL-Library\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_csv_to_features(csv_path):\n",
        "    # Step 1: Load Data\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Step 2: Identify 5-day and 7-day tickers\n",
        "    day_values_per_tic = df.groupby('tic')['day'].apply(lambda x: sorted(x.unique())).reset_index()\n",
        "    day_values_per_tic.columns = ['tic', 'unique_days']\n",
        "\n",
        "    tics_5day = day_values_per_tic[day_values_per_tic['unique_days'].apply(lambda x: x == list(range(5)))]['tic']\n",
        "    tics_7day = day_values_per_tic[day_values_per_tic['unique_days'].apply(lambda x: x == list(range(7)))]['tic']\n",
        "\n",
        "    df_5day_full = df[df['tic'].isin(tics_5day)]\n",
        "    df_7day_full = df[df['tic'].isin(tics_7day)]\n",
        "\n",
        "    # Step 3: Apply Technical Indicators\n",
        "    fe_ti = FeatureEngineer(\n",
        "        use_technical_indicator=True,\n",
        "        use_turbulence=False,\n",
        "        user_defined_feature=False\n",
        "    )\n",
        "    df_5day_full = fe_ti.preprocess_data(df_5day_full)\n",
        "    df_7day_full = fe_ti.preprocess_data(df_7day_full)\n",
        "\n",
        "    # Step 4: Combine and Clean Index\n",
        "    combined_df = pd.concat([df_5day_full, df_7day_full], ignore_index=False)\n",
        "    combined_df.index = range(len(combined_df))\n",
        "\n",
        "    # Step 5: Remove dates with only one ticker\n",
        "    combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
        "    combined_df = combined_df[combined_df.groupby('date')['date'].transform('count') > 1]\n",
        "    combined_df = combined_df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
        "\n",
        "    # Step 6: Apply Turbulence Feature\n",
        "    fe_turb = FeatureEngineer(\n",
        "        use_technical_indicator=False,\n",
        "        use_turbulence=True,\n",
        "        user_defined_feature=False\n",
        "    )\n",
        "    processed = fe_turb.preprocess_data(combined_df)\n",
        "\n",
        "    # Step 7: Final Cleaning\n",
        "    processed = processed.copy()\n",
        "    processed = processed.fillna(0)\n",
        "    processed = processed.replace(np.inf, 0)\n",
        "\n",
        "    return processed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n",
            "        date   close     high     low    open       volume     tic  day  \\\n",
            "0 2015-02-02  112.20  112.230  112.00  112.06    2792120.0     agg    0   \n",
            "1 2015-02-02   91.46   91.480   91.46   91.48    3557487.0     bil    0   \n",
            "2 2015-02-02  237.83  240.100  220.89  228.39       7421.0  btcusd    0   \n",
            "3 2015-02-02  122.42  123.155  121.82  121.84    8885189.0     gld    0   \n",
            "4 2015-02-02  201.92  202.030  197.86  200.05  163106969.0     spy    0   \n",
            "\n",
            "       macd     boll_ub     boll_lb  rsi_30     cci_30  dx_30  close_30_sma  \\\n",
            "0  0.000000  112.593112  111.376888     0.0 -66.666667  100.0        112.20   \n",
            "1  0.000000  112.593112  111.376888     0.0 -66.666667  100.0         91.46   \n",
            "2  0.198333  245.911648  220.908352   100.0  66.666667  100.0        233.41   \n",
            "3  0.000000  112.593112  111.376888     0.0 -66.666667  100.0        122.42   \n",
            "4  0.000000  112.593112  111.376888     0.0 -66.666667  100.0        201.92   \n",
            "\n",
            "   close_60_sma  turbulence  \n",
            "0        112.20         0.0  \n",
            "1         91.46         0.0  \n",
            "2        233.41         0.0  \n",
            "3        122.42         0.0  \n",
            "4        201.92         0.0  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "processed = process_csv_to_features('data.csv')\n",
        "print(processed.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed.tail(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_drl_ensemble_agent(processed_df, \n",
        "                              indicators, \n",
        "                              train_start_date, \n",
        "                              train_end_date, \n",
        "                              trade_start_date, \n",
        "                              trade_end_date, \n",
        "                              rebalance_window=63, \n",
        "                              validation_window=63, \n",
        "                              initial_amount=1_000_000,\n",
        "                              transaction_cost=0.001,\n",
        "                              hmax=100,\n",
        "                              reward_scaling=1e-4,\n",
        "                              print_verbosity=5):\n",
        "    \"\"\"\n",
        "    Setup DRLEnsembleAgent with flexible date and parameter configuration.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Calculate dynamic parameters\n",
        "    stock_dimension = len(processed_df.tic.unique())\n",
        "    state_space = 1 + 2 * stock_dimension + len(indicators) * stock_dimension\n",
        "\n",
        "    # 2. Environment configuration\n",
        "    env_kwargs = {\n",
        "        \"hmax\": hmax,\n",
        "        \"initial_amount\": initial_amount,\n",
        "        \"buy_cost_pct\": transaction_cost,\n",
        "        \"sell_cost_pct\": transaction_cost,\n",
        "        \"state_space\": state_space,\n",
        "        \"stock_dim\": stock_dimension,\n",
        "        \"tech_indicator_list\": indicators,\n",
        "        \"action_space\": stock_dimension,\n",
        "        \"reward_scaling\": reward_scaling,\n",
        "        \"print_verbosity\": print_verbosity\n",
        "    }\n",
        "\n",
        "    # 3. Initialize DRLEnsembleAgent\n",
        "    agent = DRLEnsembleAgent(\n",
        "        df=processed_df,\n",
        "        train_period=(train_start_date, train_end_date),\n",
        "        val_test_period=(trade_start_date, trade_end_date),\n",
        "        rebalance_window=rebalance_window,\n",
        "        validation_window=validation_window,\n",
        "        **env_kwargs\n",
        "    )\n",
        "\n",
        "    return agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INIT] Unique trade dates from 2023-01-04 to 2025-04-11\n",
            "[INIT] Total trading days: 570\n",
            "[INIT] First 5 dates: <DatetimeArray>\n",
            "['2023-01-04 00:00:00', '2023-01-05 00:00:00', '2023-01-06 00:00:00',\n",
            " '2023-01-09 00:00:00', '2023-01-10 00:00:00']\n",
            "Length: 5, dtype: datetime64[ns]\n",
            "[INIT] Last 5 dates: <DatetimeArray>\n",
            "['2025-04-07 00:00:00', '2025-04-08 00:00:00', '2025-04-09 00:00:00',\n",
            " '2025-04-10 00:00:00', '2025-04-11 00:00:00']\n",
            "Length: 5, dtype: datetime64[ns]\n",
            "\n",
            "[INIT PREVIEW] ===== Rebalancing Schedule Summary =====\n",
            "Iter     Train End    Val Start    Val End      Trade Start  Trade End   \n",
            "126      2023-01-04 00:00:00 2023-01-04 00:00:00 2023-04-05 00:00:00 2023-04-05 00:00:00 2023-07-07 00:00:00\n",
            "189      2023-04-05 00:00:00 2023-04-05 00:00:00 2023-07-07 00:00:00 2023-07-07 00:00:00 2023-10-05 00:00:00\n",
            "252      2023-07-07 00:00:00 2023-07-07 00:00:00 2023-10-05 00:00:00 2023-10-05 00:00:00 2024-01-05 00:00:00\n",
            "315      2023-10-05 00:00:00 2023-10-05 00:00:00 2024-01-05 00:00:00 2024-01-05 00:00:00 2024-04-08 00:00:00\n",
            "378      2024-01-05 00:00:00 2024-01-05 00:00:00 2024-04-08 00:00:00 2024-04-08 00:00:00 2024-07-09 00:00:00\n",
            "441      2024-04-08 00:00:00 2024-04-08 00:00:00 2024-07-09 00:00:00 2024-07-09 00:00:00 2024-10-07 00:00:00\n",
            "504      2024-07-09 00:00:00 2024-07-09 00:00:00 2024-10-07 00:00:00 2024-10-07 00:00:00 2025-01-07 00:00:00\n",
            "567      2024-10-07 00:00:00 2024-10-07 00:00:00 2025-01-07 00:00:00 2025-01-07 00:00:00 2025-04-09 00:00:00\n"
          ]
        }
      ],
      "source": [
        "ensemble_agent = setup_drl_ensemble_agent(\n",
        "    processed_df = processed,\n",
        "    indicators = INDICATORS,\n",
        "    train_start_date = '2016-02-02',\n",
        "    train_end_date = '2023-01-03',\n",
        "    trade_start_date = '2023-01-04',\n",
        "    trade_end_date = '2025-04-11',\n",
        "    rebalance_window = 63,\n",
        "    validation_window = 63\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms.\n",
        "\n",
        "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007\n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128\n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 10_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64\n",
        "                    }\n",
        "\n",
        "SAC_model_kwargs = {\n",
        "                      \"batch_size\": 128,\n",
        "                      \"buffer_size\": 100000,\n",
        "                      \"learning_rate\": 0.0003,\n",
        "                      \"learning_starts\": 100,\n",
        "                      \"ent_coef\": \"auto_0.1\",\n",
        "                    }\n",
        "\n",
        "TD3_model_kwargs = {\n",
        "                      \"batch_size\": 100,\n",
        "                      \"buffer_size\": 1000000,\n",
        "                      \"learning_rate\": 0.001\n",
        "                   }\n",
        "\n",
        "\n",
        "\n",
        "timesteps_dict = {'a2c' : 10_000,\n",
        "                 'ppo' : 10_000,\n",
        "                 'ddpg' : 10_000,\n",
        "                  'sac' : 10_000,\n",
        "                 'td3' : 10_000,\n",
        "                 }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def run_ensemble_and_generate_daily_return(ensemble_agent, \n",
        "                                            A2C_kwargs, PPO_kwargs, DDPG_kwargs, SAC_kwargs, TD3_kwargs, \n",
        "                                            timesteps_dict, \n",
        "                                            processed_df, \n",
        "                                            trade_start_date, trade_end_date, \n",
        "                                            rebalance_window, validation_window, \n",
        "                                            output_csv_name=\"df_daily_return.csv\",\n",
        "                                            initial_fund=1_000_000):\n",
        "    \"\"\"\n",
        "    Runs DRL Ensemble Strategy, tracks continuous portfolio value, \n",
        "    calculates daily returns, and saves to CSV.\n",
        "    \"\"\"\n",
        "    # === Step 1: Run Ensemble Strategy ===\n",
        "    print(\"[INFO] Running Ensemble Strategy...\")\n",
        "    df_summary = ensemble_agent.run_ensemble_strategy(\n",
        "        A2C_kwargs, PPO_kwargs, DDPG_kwargs, SAC_kwargs, TD3_kwargs, timesteps_dict\n",
        "    )\n",
        "\n",
        "    # === Step 2: Prepare Trade Dates ===\n",
        "    unique_trade_date = processed_df[\n",
        "        (processed_df.date >= trade_start_date) & (processed_df.date <= trade_end_date)\n",
        "    ].date.unique()\n",
        "\n",
        "    current_value = initial_fund\n",
        "    portfolio_tracking = []\n",
        "    is_first_file = True\n",
        "\n",
        "    rebalance_points = list(range(rebalance_window + validation_window, len(unique_trade_date) + 1, rebalance_window))\n",
        "\n",
        "    # === Step 3: Track Portfolio Value Across Rebalances ===\n",
        "    for i in rebalance_points:\n",
        "        file_path = f'results/account_value_trade_ensemble_{i}.csv'\n",
        "        if os.path.exists(file_path):\n",
        "            temp = pd.read_csv(file_path)\n",
        "\n",
        "            if is_first_file:\n",
        "                first_date = temp.loc[0, 'date']\n",
        "                original_value = temp.loc[0, 'account_value']\n",
        "                portfolio_tracking.append({\n",
        "                    'date': first_date,\n",
        "                    'portfolio_value': current_value,\n",
        "                    'original_account_value': original_value\n",
        "                })\n",
        "                start_idx = 1\n",
        "                is_first_file = False\n",
        "            else:\n",
        "                start_idx = 1\n",
        "\n",
        "            for idx in range(start_idx, len(temp)):\n",
        "                daily_return = temp.loc[idx, 'daily_return']\n",
        "                date = temp.loc[idx, 'date']\n",
        "                original_value = temp.loc[idx, 'account_value']\n",
        "                if pd.notna(daily_return):\n",
        "                    current_value *= (1 + daily_return)\n",
        "                    portfolio_tracking.append({\n",
        "                        'date': date,\n",
        "                        'portfolio_value': current_value,\n",
        "                        'original_account_value': original_value\n",
        "                    })\n",
        "        else:\n",
        "            print(f\"[Warning] File does not exist: {file_path}\")\n",
        "\n",
        "    df_portfolio = pd.DataFrame(portfolio_tracking)\n",
        "\n",
        "    # === Step 4: Plot Portfolio Value ===\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.plot(pd.to_datetime(df_portfolio['date']), df_portfolio['portfolio_value'], label='Continuous Portfolio Value')\n",
        "    plt.plot(pd.to_datetime(df_portfolio['date']), df_portfolio['original_account_value'], label='Original (Resetting) Account Value', linestyle='--')\n",
        "    plt.title('Portfolio Value: Continuous vs Original')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Portfolio Value')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # === Step 5: Calculate Daily Returns ===\n",
        "    df_daily_return = df_portfolio.copy()\n",
        "    df_daily_return[\"daily_return\"] = df_daily_return[\"portfolio_value\"].pct_change()\n",
        "    df_daily_return = df_daily_return.infer_objects(copy=False)\n",
        "    df_daily_return.loc[0, \"daily_return\"] = 0.0\n",
        "    df_daily_return = df_daily_return[[\"date\", \"daily_return\"]]\n",
        "\n",
        "    # === Step 6: Save to CSV ===\n",
        "    df_daily_return.to_csv(output_csv_name, index=False)\n",
        "    print(f\"[INFO] Daily return saved to: {output_csv_name}\")\n",
        "\n",
        "    return df_daily_return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Running Ensemble Strategy...\n",
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  82.25897481973143\n",
            "======Model training from:  2016-02-02 to  2023-01-04 00:00:00\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_126_31\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 770       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 0         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | -0.335    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 21.6      |\n",
            "|    reward             | 1.1501445 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 3.28      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 771        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 16.7       |\n",
            "|    reward             | 0.05485836 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.43       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 785      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.8    |\n",
            "|    explained_variance | 0.038    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -51.7    |\n",
            "|    reward             | -0.40071 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 28.7     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 790        |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 2          |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0.102      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -10.5      |\n",
            "|    reward             | 0.17423569 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.24       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 795        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 5.74       |\n",
            "|    reward             | 0.57460594 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.965      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 798        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | -0.00962   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 11         |\n",
            "|    reward             | -3.2265093 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.5        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 800        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 0.842      |\n",
            "|    reward             | -0.2098083 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.00588    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 802       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | -0.0525   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -91.2     |\n",
            "|    reward             | 1.6863481 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 46.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 804       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 33        |\n",
            "|    reward             | 0.9421169 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 9.19      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 804      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 29.8     |\n",
            "|    reward             | 0.903234 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 8.37     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 692        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 7          |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0.0118     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 0.97       |\n",
            "|    reward             | 0.72268313 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.032      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 702        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0.278      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 16         |\n",
            "|    reward             | -0.5353809 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.82       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 711       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0.0302    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 25.6      |\n",
            "|    reward             | 2.8175483 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 6.9       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 719         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | 1.92        |\n",
            "|    reward             | -0.12795644 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.0314      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 726          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | 0.057        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | -26.5        |\n",
            "|    reward             | -0.036274187 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 5.81         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 733       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.00662  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -102      |\n",
            "|    reward             | 3.8502288 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 83.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 739       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.0714   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -32.2     |\n",
            "|    reward             | 4.2508173 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 9.2       |\n",
            "-------------------------------------\n",
            "day: 1742, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1475081.59\n",
            "total_reward: 475081.59\n",
            "total_cost: 37103.66\n",
            "total_trades: 10349\n",
            "Sharpe: 0.373\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 743        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.216      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -3.35      |\n",
            "|    reward             | -1.3565981 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.148      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 748        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.128     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -2.73      |\n",
            "|    reward             | 0.66223633 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.96       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 753       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0.0118    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -68       |\n",
            "|    reward             | 2.6070561 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 31.4      |\n",
            "-------------------------------------\n",
            "======a2c Validation from:  2023-01-04 00:00:00 to  2023-04-05 00:00:00\n",
            "a2c Sharpe Ratio:  0.3889444291387756\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_126_29\n",
            "day: 1742, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1563810.24\n",
            "total_reward: 563810.24\n",
            "total_cost: 1884.22\n",
            "total_trades: 3565\n",
            "Sharpe: 0.417\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 283      |\n",
            "|    time_elapsed    | 24       |\n",
            "|    total_timesteps | 6972     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 232      |\n",
            "|    critic_loss     | 4.18e+03 |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 6871     |\n",
            "|    reward          | -0.36908 |\n",
            "---------------------------------\n",
            "======ddpg Validation from:  2023-01-04 00:00:00 to  2023-04-05 00:00:00\n",
            "ddpg Sharpe Ratio:  -0.01297070414664087\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_126_28\n",
            "day: 1742, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1501667.66\n",
            "total_reward: 501667.66\n",
            "total_cost: 998.94\n",
            "total_trades: 10452\n",
            "Sharpe: 0.535\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 246       |\n",
            "|    time_elapsed    | 28        |\n",
            "|    total_timesteps | 6972      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 16.2      |\n",
            "|    critic_loss     | 3.59e+03  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 6871      |\n",
            "|    reward          | -0.089695 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2023-01-04 00:00:00 to  2023-04-05 00:00:00\n",
            "td3 Sharpe Ratio:  0.15054186541935827\n",
            "======sac Training========\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_126_28\n",
            "day: 1742, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 27772699.23\n",
            "total_reward: 26772699.23\n",
            "total_cost: 118940.24\n",
            "total_trades: 11405\n",
            "Sharpe: 1.040\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 186       |\n",
            "|    time_elapsed    | 37        |\n",
            "|    total_timesteps | 6972      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 1.59e+03  |\n",
            "|    critic_loss     | 4.61e+04  |\n",
            "|    ent_coef        | 0.0903    |\n",
            "|    ent_coef_loss   | -25.6     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 6871      |\n",
            "|    reward          | 6.5304117 |\n",
            "----------------------------------\n",
            "======sac Validation from:  2023-01-04 00:00:00 to  2023-04-05 00:00:00\n",
            "sac Sharpe Ratio:  0.47158969306773096\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_126_28\n",
            "day: 1742, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4197896.27\n",
            "total_reward: 3197896.27\n",
            "total_cost: 1150055.18\n",
            "total_trades: 15010\n",
            "Sharpe: 0.791\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 1020       |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 2          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.20311558 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006294959 |\n",
            "|    clip_fraction        | 0.0899      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.00296     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 318         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00663    |\n",
            "|    reward               | 1.0969007   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 669         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 960         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009421925 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | -0.00432    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 54.3        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00924    |\n",
            "|    reward               | -0.06747176 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 128         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 954         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007483811 |\n",
            "|    clip_fraction        | 0.0797      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.00448     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 338         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00801    |\n",
            "|    reward               | -2.8736959  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 573         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 955         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007772484 |\n",
            "|    clip_fraction        | 0.0763      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.00304     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 214         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00647    |\n",
            "|    reward               | -7.3292046  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 423         |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2023-01-04 00:00:00 to  2023-04-05 00:00:00\n",
            "ppo Sharpe Ratio:  0.47649965548486717\n",
            "======Best Model Retraining from:  2016-02-02 to  2023-04-05 00:00:00\n",
            "======Trading from:  2023-04-05 00:00:00 to  2023-07-07 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  82.25897481973143\n",
            "======Model training from:  2016-02-02 to  2023-04-05 00:00:00\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_189_28\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 829        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 0          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | -0.0784    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -16.6      |\n",
            "|    reward             | 0.61024153 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 11.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 825        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | -0.191     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -2.41      |\n",
            "|    reward             | 0.21129058 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 0.137      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 820         |\n",
            "|    iterations         | 300         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 1500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.7       |\n",
            "|    explained_variance | -0.108      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 299         |\n",
            "|    policy_loss        | -15.3       |\n",
            "|    reward             | -0.07421674 |\n",
            "|    std                | 0.996       |\n",
            "|    value_loss         | 1.7         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 807        |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 2          |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | 0.117      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | 34.3       |\n",
            "|    reward             | -0.3121282 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 14.4       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 808      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.8    |\n",
            "|    explained_variance | 0.187    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | -14.3    |\n",
            "|    reward             | 3.659703 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.48     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 808        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | -0.0178    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 655        |\n",
            "|    reward             | -22.079756 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.83e+03   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 812       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.8     |\n",
            "|    explained_variance | -0.212    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 108       |\n",
            "|    reward             | 1.9766483 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 92.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 813        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | -8.62      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -3.15      |\n",
            "|    reward             | 0.24124642 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.0829     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 813         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | -0.55       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 2.12        |\n",
            "|    reward             | 0.004941174 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0381      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 815         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 6           |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | -54.4       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | 0.401       |\n",
            "|    reward             | 0.014058962 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.00286     |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 815       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | -0.0091   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -20.4     |\n",
            "|    reward             | 4.6758547 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.73      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 816         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -11.7       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -4.56       |\n",
            "|    reward             | 0.016875103 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.601       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 812          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | -0.144       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | -19.9        |\n",
            "|    reward             | -0.007342701 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 9.35         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 815        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.107      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -150       |\n",
            "|    reward             | 0.37263212 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 207        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 814        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.385      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 79.3       |\n",
            "|    reward             | -10.682063 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 41.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 814       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.0112   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -47       |\n",
            "|    reward             | 4.0392246 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 14        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 813        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.0488     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 1.08e+03   |\n",
            "|    reward             | -14.499323 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 7.21e+03   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 813        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -57.3      |\n",
            "|    reward             | -7.2667575 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 83.4       |\n",
            "--------------------------------------\n",
            "day: 1805, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 9209061.33\n",
            "total_reward: 8209061.33\n",
            "total_cost: 1104891.26\n",
            "total_trades: 10528\n",
            "Sharpe: 1.006\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 813      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | 0.0251   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 215      |\n",
            "|    reward             | 5.488962 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 287      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 814        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -44.8      |\n",
            "|    reward             | -0.2636608 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 20.3       |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2023-04-05 00:00:00 to  2023-07-07 00:00:00\n",
            "a2c Sharpe Ratio:  -0.1280077918251661\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_189_28\n",
            "day: 1805, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1534096.96\n",
            "total_reward: 534096.96\n",
            "total_cost: 999.00\n",
            "total_trades: 12618\n",
            "Sharpe: 0.487\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 259       |\n",
            "|    time_elapsed    | 27        |\n",
            "|    total_timesteps | 7224      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 258       |\n",
            "|    critic_loss     | 601       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 7123      |\n",
            "|    reward          | -0.874123 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2023-04-05 00:00:00 to  2023-07-07 00:00:00\n",
            "ddpg Sharpe Ratio:  0.191688982987367\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_189_28\n",
            "day: 1805, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1601423.58\n",
            "total_reward: 601423.58\n",
            "total_cost: 998.93\n",
            "total_trades: 7220\n",
            "Sharpe: 0.545\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 235       |\n",
            "|    time_elapsed    | 30        |\n",
            "|    total_timesteps | 7224      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 204       |\n",
            "|    critic_loss     | 249       |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 7123      |\n",
            "|    reward          | -1.046744 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2023-04-05 00:00:00 to  2023-07-07 00:00:00\n",
            "td3 Sharpe Ratio:  0.21924519640957102\n",
            "======sac Training========\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_189_27\n",
            "day: 1805, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 35089458.20\n",
            "total_reward: 34089458.20\n",
            "total_cost: 998.98\n",
            "total_trades: 9025\n",
            "Sharpe: 1.078\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 189       |\n",
            "|    time_elapsed    | 38        |\n",
            "|    total_timesteps | 7224      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 1.63e+03  |\n",
            "|    critic_loss     | 5.8e+03   |\n",
            "|    ent_coef        | 0.827     |\n",
            "|    ent_coef_loss   | 24.6      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 7123      |\n",
            "|    reward          | 44.727577 |\n",
            "----------------------------------\n",
            "======sac Validation from:  2023-04-05 00:00:00 to  2023-07-07 00:00:00\n",
            "sac Sharpe Ratio:  0.09659655714008933\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_189_27\n",
            "day: 1805, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3353019.95\n",
            "total_reward: 2353019.95\n",
            "total_cost: 1021065.66\n",
            "total_trades: 15532\n",
            "Sharpe: 0.673\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 1020       |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 2          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | -0.2833888 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 990         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009734845 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.00234     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 175         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0071     |\n",
            "|    reward               | 7.5274262   |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 444         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 967         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007170151 |\n",
            "|    clip_fraction        | 0.0908      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.029       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 77          |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00741    |\n",
            "|    reward               | -0.92767125 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 171         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 963          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 8            |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070763165 |\n",
            "|    clip_fraction        | 0.0875       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.00303      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 137          |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0095      |\n",
            "|    reward               | 2.2661643    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 335          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 963         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010169259 |\n",
            "|    clip_fraction        | 0.118       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.00128     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 122         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0089     |\n",
            "|    reward               | 5.282731    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 313         |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2023-04-05 00:00:00 to  2023-07-07 00:00:00\n",
            "ppo Sharpe Ratio:  0.16431800109124461\n",
            "======Best Model Retraining from:  2016-02-02 to  2023-07-07 00:00:00\n",
            "======Trading from:  2023-07-07 00:00:00 to  2023-10-05 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  82.25897481973143\n",
            "======Model training from:  2016-02-02 to  2023-07-07 00:00:00\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_252_27\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 804        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 0          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | -0.715     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | 9.06       |\n",
            "|    reward             | 0.44069332 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.592      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 806        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | -0.0164    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 0.187      |\n",
            "|    reward             | -0.4668355 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.254      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 804      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.8    |\n",
            "|    explained_variance | -0.417   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -1.72    |\n",
            "|    reward             | 0.25074  |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 1.08     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 805        |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 2          |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | 0.848      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -9.16      |\n",
            "|    reward             | 0.34928042 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.521      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 809      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 4.13     |\n",
            "|    reward             | 0.930556 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.954    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 811        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 3.28       |\n",
            "|    reward             | -1.3106111 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.12       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 813         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | 0.101       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 28.2        |\n",
            "|    reward             | -0.87648636 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 5.64        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 812        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | -0.0153    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 8.04       |\n",
            "|    reward             | 0.47954497 |\n",
            "|    std                | 0.997      |\n",
            "|    value_loss         | 0.573      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 813         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.7       |\n",
            "|    explained_variance | -0.164      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 15.9        |\n",
            "|    reward             | 0.013471149 |\n",
            "|    std                | 0.992       |\n",
            "|    value_loss         | 2.27        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 814       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | -0.0356   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -17.8     |\n",
            "|    reward             | 0.2699353 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 2.55      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 814       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.8     |\n",
            "|    explained_variance | 0.0353    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 11.7      |\n",
            "|    reward             | 1.0840622 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.44      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 813       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0.128     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -4.49     |\n",
            "|    reward             | 0.2785358 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 0.596     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 813         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | -1.14       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | -3.44       |\n",
            "|    reward             | -0.06384117 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.967       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 814        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | -0.45      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -8.82      |\n",
            "|    reward             | 0.20761175 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.508      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 814         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 10.9        |\n",
            "|    reward             | -0.88156646 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 0.726       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 814       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 6.75      |\n",
            "|    reward             | 1.1661243 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 0.94      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 815        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | -0.0381    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | -5.05      |\n",
            "|    reward             | -2.2044556 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 0.263      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 815       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.8     |\n",
            "|    explained_variance | -0.0897   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -14       |\n",
            "|    reward             | -0.434837 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 1.68      |\n",
            "-------------------------------------\n",
            "day: 1868, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1349188.65\n",
            "total_reward: 349188.65\n",
            "total_cost: 61446.46\n",
            "total_trades: 12402\n",
            "Sharpe: 0.413\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 815        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | -0.0595    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 37.9       |\n",
            "|    reward             | -1.9975184 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 6.52       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 816         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 12          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | 0.162       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -7.73       |\n",
            "|    reward             | -0.37168735 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.14        |\n",
            "---------------------------------------\n",
            "======a2c Validation from:  2023-07-07 00:00:00 to  2023-10-05 00:00:00\n",
            "a2c Sharpe Ratio:  -0.3369468437486399\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_252_27\n",
            "day: 1868, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 28079130.96\n",
            "total_reward: 27079130.96\n",
            "total_cost: 998.98\n",
            "total_trades: 14944\n",
            "Sharpe: 1.028\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 287        |\n",
            "|    time_elapsed    | 26         |\n",
            "|    total_timesteps | 7476       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 730        |\n",
            "|    critic_loss     | 1.97e+03   |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 7375       |\n",
            "|    reward          | -54.927876 |\n",
            "-----------------------------------\n",
            "======ddpg Validation from:  2023-07-07 00:00:00 to  2023-10-05 00:00:00\n",
            "ddpg Sharpe Ratio:  -0.14529824223055535\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_252_27\n",
            "day: 1868, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1628459.55\n",
            "total_reward: 628459.55\n",
            "total_cost: 998.98\n",
            "total_trades: 7472\n",
            "Sharpe: 0.583\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 240       |\n",
            "|    time_elapsed    | 31        |\n",
            "|    total_timesteps | 7476      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 234       |\n",
            "|    critic_loss     | 185       |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 7375      |\n",
            "|    reward          | -1.185867 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2023-07-07 00:00:00 to  2023-10-05 00:00:00\n",
            "td3 Sharpe Ratio:  -0.4894974092226354\n",
            "======sac Training========\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_252_27\n",
            "day: 1868, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 29666384.88\n",
            "total_reward: 28666384.88\n",
            "total_cost: 2455.06\n",
            "total_trades: 5673\n",
            "Sharpe: 1.036\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 191        |\n",
            "|    time_elapsed    | 38         |\n",
            "|    total_timesteps | 7476       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 1.61e+03   |\n",
            "|    critic_loss     | 7.39e+03   |\n",
            "|    ent_coef        | 0.85       |\n",
            "|    ent_coef_loss   | 13.7       |\n",
            "|    learning_rate   | 0.0003     |\n",
            "|    n_updates       | 7375       |\n",
            "|    reward          | -92.934425 |\n",
            "-----------------------------------\n",
            "======sac Validation from:  2023-07-07 00:00:00 to  2023-10-05 00:00:00\n",
            "sac Sharpe Ratio:  -0.13920554369426516\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_252_27\n",
            "day: 1868, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2884931.22\n",
            "total_reward: 1884931.22\n",
            "total_cost: 1011353.13\n",
            "total_trades: 16090\n",
            "Sharpe: 0.597\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 953         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 2           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.03554704 |\n",
            "------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 949         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008276796 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | -0.000961   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 324         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00969    |\n",
            "|    reward               | 0.21599081  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 577         |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 947        |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 6          |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00810126 |\n",
            "|    clip_fraction        | 0.106      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -12.8      |\n",
            "|    explained_variance   | 0.00152    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 46.5       |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.00876   |\n",
            "|    reward               | 0.8623126  |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 71.1       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 943         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011421403 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.0063      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 63.9        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0113     |\n",
            "|    reward               | -0.5273985  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 118         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 943         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.0101876   |\n",
            "|    clip_fraction        | 0.0918      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.00714     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 178         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00994    |\n",
            "|    reward               | -0.01259245 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 471         |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2023-07-07 00:00:00 to  2023-10-05 00:00:00\n",
            "ppo Sharpe Ratio:  -0.38605764391193953\n",
            "======Best Model Retraining from:  2016-02-02 to  2023-10-05 00:00:00\n",
            "======Trading from:  2023-10-05 00:00:00 to  2024-01-05 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  82.25897481973143\n",
            "======Model training from:  2016-02-02 to  2023-10-05 00:00:00\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_315_27\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 798        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 0          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -0.355     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | 4.93       |\n",
            "|    reward             | 0.45524564 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.214      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 799        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -8.14      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 8.82       |\n",
            "|    reward             | 0.15206231 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.6        |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 796          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -12.9        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -2.18        |\n",
            "|    reward             | -0.005344477 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.0337       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 797         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 2           |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | -0.196      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | -11         |\n",
            "|    reward             | -0.29978147 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 1.28        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 800       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0.133     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 0.519     |\n",
            "|    reward             | 0.6100535 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.0647    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 802        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.104      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 1.57       |\n",
            "|    reward             | -1.2604227 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.486      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 789        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.105     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 7.61       |\n",
            "|    reward             | -1.3126925 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.66       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 790       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.154    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 34.3      |\n",
            "|    reward             | 1.5026501 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 16.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 792        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | -0.00565   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -562       |\n",
            "|    reward             | -40.995422 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 3.02e+03   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 793       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -0.0312   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 220       |\n",
            "|    reward             | 3.4114754 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 637       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 793        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.0143     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -34.5      |\n",
            "|    reward             | -8.0790825 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 32.2       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 791         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0.636       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | 3.69        |\n",
            "|    reward             | -0.08084885 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.161       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 789         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0.00329     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 24.4        |\n",
            "|    reward             | -0.24966599 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 4.42        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 788       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 52.2      |\n",
            "|    reward             | 0.5455387 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 19.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 786        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | 0.0136     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 44.5       |\n",
            "|    reward             | 0.42256695 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 17.9       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 781        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -0.0883    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 39.2       |\n",
            "|    reward             | 0.16998628 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 11.6       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 779         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 10          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | 12.6        |\n",
            "|    reward             | 0.025810253 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 1.41        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 780       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.128     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 35.3      |\n",
            "|    reward             | -2.652881 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 10.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 775       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | 0.00373   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -7.57     |\n",
            "|    reward             | 2.8423774 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.565     |\n",
            "-------------------------------------\n",
            "day: 1931, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1870104.77\n",
            "total_reward: 870104.77\n",
            "total_cost: 177124.67\n",
            "total_trades: 14899\n",
            "Sharpe: 0.614\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 770       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.1     |\n",
            "|    explained_variance | -0.00499  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 35.7      |\n",
            "|    reward             | 2.5502512 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 14        |\n",
            "-------------------------------------\n",
            "======a2c Validation from:  2023-10-05 00:00:00 to  2024-01-05 00:00:00\n",
            "a2c Sharpe Ratio:  0.6001847059831356\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_315_27\n",
            "day: 1931, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1857948.70\n",
            "total_reward: 857948.70\n",
            "total_cost: 998.97\n",
            "total_trades: 7724\n",
            "Sharpe: 0.519\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 252      |\n",
            "|    time_elapsed    | 30       |\n",
            "|    total_timesteps | 7728     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -202     |\n",
            "|    critic_loss     | 317      |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 7627     |\n",
            "|    reward          | 1.340712 |\n",
            "---------------------------------\n",
            "======ddpg Validation from:  2023-10-05 00:00:00 to  2024-01-05 00:00:00\n",
            "ddpg Sharpe Ratio:  0.34097564157454957\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_315_27\n",
            "day: 1931, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 36932542.72\n",
            "total_reward: 35932542.72\n",
            "total_cost: 998.99\n",
            "total_trades: 9655\n",
            "Sharpe: 1.044\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 214       |\n",
            "|    time_elapsed    | 35        |\n",
            "|    total_timesteps | 7728      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 1.41e+03  |\n",
            "|    critic_loss     | 7.79e+03  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 7627      |\n",
            "|    reward          | 47.007893 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2023-10-05 00:00:00 to  2024-01-05 00:00:00\n",
            "td3 Sharpe Ratio:  0.5222987728535884\n",
            "======sac Training========\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_315_27\n",
            "day: 1931, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5742320.01\n",
            "total_reward: 4742320.01\n",
            "total_cost: 152224.29\n",
            "total_trades: 16062\n",
            "Sharpe: 1.149\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 149      |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 7728     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.05e+03 |\n",
            "|    critic_loss     | 2.35e+03 |\n",
            "|    ent_coef        | 0.0506   |\n",
            "|    ent_coef_loss   | -36.7    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7627     |\n",
            "|    reward          | 8.613399 |\n",
            "---------------------------------\n",
            "======sac Validation from:  2023-10-05 00:00:00 to  2024-01-05 00:00:00\n",
            "sac Sharpe Ratio:  0.4480359305000389\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_315_27\n",
            "day: 1931, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1517920.25\n",
            "total_reward: 517920.25\n",
            "total_cost: 961959.87\n",
            "total_trades: 16605\n",
            "Sharpe: 0.337\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    fps             | 925          |\n",
            "|    iterations      | 1            |\n",
            "|    time_elapsed    | 2            |\n",
            "|    total_timesteps | 2048         |\n",
            "| train/             |              |\n",
            "|    reward          | -0.056494463 |\n",
            "-------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 875          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 4            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076277074 |\n",
            "|    clip_fraction        | 0.0748       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.00119      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 173          |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00941     |\n",
            "|    reward               | 2.955828     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 300          |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 873        |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 7          |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01164817 |\n",
            "|    clip_fraction        | 0.112      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -12.8      |\n",
            "|    explained_variance   | 0.00159    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 1.1e+03    |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.00946   |\n",
            "|    reward               | 12.371899  |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 1.21e+03   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 840          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065745553 |\n",
            "|    clip_fraction        | 0.0526       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.00659      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 566          |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00672     |\n",
            "|    reward               | -0.092650555 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 1.32e+03     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 849         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004532646 |\n",
            "|    clip_fraction        | 0.014       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.00116     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.22e+03    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00327    |\n",
            "|    reward               | -5.361678   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 1.09e+04    |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2023-10-05 00:00:00 to  2024-01-05 00:00:00\n",
            "ppo Sharpe Ratio:  0.31063763609325096\n",
            "======Best Model Retraining from:  2016-02-02 to  2024-01-05 00:00:00\n",
            "======Trading from:  2024-01-05 00:00:00 to  2024-04-08 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  82.25897481973143\n",
            "======Model training from:  2016-02-02 to  2024-01-05 00:00:00\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_378_27\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 605       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 0         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.8     |\n",
            "|    explained_variance | -0.0121   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -282      |\n",
            "|    reward             | 0.6198791 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 938       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 665         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | 0.0737      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | 41.9        |\n",
            "|    reward             | -0.22184795 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 13.8        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 680         |\n",
            "|    iterations         | 300         |\n",
            "|    time_elapsed       | 2           |\n",
            "|    total_timesteps    | 1500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | -0.0321     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 299         |\n",
            "|    policy_loss        | -66         |\n",
            "|    reward             | -0.49680525 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 44.9        |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 637          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -12.8        |\n",
            "|    explained_variance | 0.000418     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -162         |\n",
            "|    reward             | -0.020610752 |\n",
            "|    std                | 1            |\n",
            "|    value_loss         | 219          |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 644       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.8     |\n",
            "|    explained_variance | 0.149     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 9.23      |\n",
            "|    reward             | -2.459364 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.721     |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 662          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 4            |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -12.8        |\n",
            "|    explained_variance | 0.359        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | -4.73        |\n",
            "|    reward             | -0.050650302 |\n",
            "|    std                | 1            |\n",
            "|    value_loss         | 0.364        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 675       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.8     |\n",
            "|    explained_variance | 0.129     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -11       |\n",
            "|    reward             | 2.5310137 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.33      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 687        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -3.06      |\n",
            "|    reward             | 0.12780784 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.0612     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 696        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | -9.57      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -10.7      |\n",
            "|    reward             | 0.17708679 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.75       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 704       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | -44.9     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -0.972    |\n",
            "|    reward             | 0.0162591 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.0184    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 711      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.9    |\n",
            "|    explained_variance | -0.0775  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -9.39    |\n",
            "|    reward             | 0.529643 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.599    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 712        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 3.37       |\n",
            "|    reward             | 0.06394451 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0824     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 701       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0.127     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -11.7     |\n",
            "|    reward             | 0.2940561 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.04      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 706        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 15.9       |\n",
            "|    reward             | 0.05073295 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 3.45       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 711         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 10          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | -0.157      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 23.3        |\n",
            "|    reward             | 0.056719318 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 4.09        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 715        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 0.0164     |\n",
            "|    reward             | 0.14261414 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.00167    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 719        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13        |\n",
            "|    explained_variance | 0.00836    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 23.1       |\n",
            "|    reward             | 0.42362756 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 5.29       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 720         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 12          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | 0.0182      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 4.19        |\n",
            "|    reward             | -0.28189376 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.122       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 720         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 13          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -0.000928   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -13         |\n",
            "|    reward             | -0.77972555 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 1.57        |\n",
            "---------------------------------------\n",
            "day: 1994, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1005045.19\n",
            "total_reward: 5045.19\n",
            "total_cost: 43050.74\n",
            "total_trades: 8776\n",
            "Sharpe: 0.067\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 712          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 14           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -13          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | -0.354       |\n",
            "|    reward             | 0.0059708986 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.00101      |\n",
            "----------------------------------------\n",
            "======a2c Validation from:  2024-01-05 00:00:00 to  2024-04-08 00:00:00\n",
            "a2c Sharpe Ratio:  0.2270216989117858\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_378_27\n",
            "day: 1994, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1758656.63\n",
            "total_reward: 758656.63\n",
            "total_cost: 999.00\n",
            "total_trades: 13895\n",
            "Sharpe: 0.595\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 221       |\n",
            "|    time_elapsed    | 36        |\n",
            "|    total_timesteps | 7980      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 289       |\n",
            "|    critic_loss     | 130       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 7879      |\n",
            "|    reward          | -0.427789 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2024-01-05 00:00:00 to  2024-04-08 00:00:00\n",
            "ddpg Sharpe Ratio:  0.34772410880026916\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_378_27\n",
            "day: 1994, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 63902747.82\n",
            "total_reward: 62902747.82\n",
            "total_cost: 999.00\n",
            "total_trades: 5982\n",
            "Sharpe: 1.124\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 202       |\n",
            "|    time_elapsed    | 39        |\n",
            "|    total_timesteps | 7980      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 84.3      |\n",
            "|    critic_loss     | 3.16e+04  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 7879      |\n",
            "|    reward          | 189.62971 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2024-01-05 00:00:00 to  2024-04-08 00:00:00\n",
            "td3 Sharpe Ratio:  0.38984649329757115\n",
            "======sac Training========\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_378_26\n",
            "day: 1994, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 47837405.36\n",
            "total_reward: 46837405.36\n",
            "total_cost: 37030.25\n",
            "total_trades: 11901\n",
            "Sharpe: 1.094\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 182       |\n",
            "|    time_elapsed    | 43        |\n",
            "|    total_timesteps | 7980      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 2.15e+03  |\n",
            "|    critic_loss     | 9.09e+03  |\n",
            "|    ent_coef        | 0.0574    |\n",
            "|    ent_coef_loss   | -29.2     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 7879      |\n",
            "|    reward          | 253.86082 |\n",
            "----------------------------------\n",
            "======sac Validation from:  2024-01-05 00:00:00 to  2024-04-08 00:00:00\n",
            "sac Sharpe Ratio:  0.3903713811969149\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_378_26\n",
            "day: 1994, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 802146.25\n",
            "total_reward: -197853.75\n",
            "total_cost: 391371.63\n",
            "total_trades: 16703\n",
            "Sharpe: -0.027\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 880        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 2          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.40686595 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 868         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009960724 |\n",
            "|    clip_fraction        | 0.119       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | -0.0277     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 10          |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00888    |\n",
            "|    reward               | -0.28388193 |\n",
            "|    std                  | 0.998       |\n",
            "|    value_loss           | 16.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 870         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008169417 |\n",
            "|    clip_fraction        | 0.0521      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.00308     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 67.9        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00638    |\n",
            "|    reward               | 0.21382855  |\n",
            "|    std                  | 0.998       |\n",
            "|    value_loss           | 121         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 830          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009770152 |\n",
            "|    clip_fraction        | 4.88e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | -5.46e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.79e+03     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00168     |\n",
            "|    reward               | 1.0178287    |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 8.69e+03     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 841          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071455324 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | -0.000803    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 708          |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00371     |\n",
            "|    reward               | 1.6209127    |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 1.29e+03     |\n",
            "------------------------------------------\n",
            "======ppo Validation from:  2024-01-05 00:00:00 to  2024-04-08 00:00:00\n",
            "ppo Sharpe Ratio:  0.17044954129665382\n",
            "======Best Model Retraining from:  2016-02-02 to  2024-04-08 00:00:00\n",
            "======Trading from:  2024-04-08 00:00:00 to  2024-07-09 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  82.25897481973143\n",
            "======Model training from:  2016-02-02 to  2024-04-08 00:00:00\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_441_25\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 761       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 0         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -3.43     |\n",
            "|    reward             | 0.5640755 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.87      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 768         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | 0.585       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | 9.71        |\n",
            "|    reward             | -0.31640956 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.874       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 771        |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -22.8      |\n",
            "|    reward             | -0.4605865 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 7.36       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 771       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 2         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | -0.000323 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -34.9     |\n",
            "|    reward             | 2.8721638 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 11.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 770        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0.256      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -3.2       |\n",
            "|    reward             | 0.38810655 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.159      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 770         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | 0.282       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 0.404       |\n",
            "|    reward             | -0.12252241 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0588      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 770        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 20         |\n",
            "|    reward             | 0.82282734 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.92       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 769       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 12.7      |\n",
            "|    reward             | -0.875711 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.94      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 767        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -2.38e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 0.0407     |\n",
            "|    reward             | 0.41509935 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0814     |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 768      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -12.8    |\n",
            "|    reward             | 1.893514 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 1.2      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 768       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -10.9     |\n",
            "|    reward             | -0.188349 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.13      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 769      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -6.4     |\n",
            "|    reward             | 1.291392 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.951    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 766       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0.257     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 1.75      |\n",
            "|    reward             | -0.842898 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.143     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 763       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | -0.226    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 2.79      |\n",
            "|    reward             | -0.053913 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.18      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 747      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 15.3     |\n",
            "|    reward             | 0.447772 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 1.32     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 742      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -4.67    |\n",
            "|    reward             | 1.145263 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.573    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 736       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 6.79      |\n",
            "|    reward             | 0.552664  |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.345     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 732       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 2.14      |\n",
            "|    reward             | -1.036689 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.0823    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 731       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 15.6      |\n",
            "|    reward             | -1.611563 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.06      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 731       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 4.8       |\n",
            "|    reward             | -1.416935 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.15      |\n",
            "-------------------------------------\n",
            "======a2c Validation from:  2024-04-08 00:00:00 to  2024-07-09 00:00:00\n",
            "a2c Sharpe Ratio:  -0.06593869823998359\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_441_25\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 245      |\n",
            "|    time_elapsed    | 33       |\n",
            "|    total_timesteps | 8232     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 239      |\n",
            "|    critic_loss     | 689      |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 8131     |\n",
            "|    reward          | 2.118727 |\n",
            "---------------------------------\n",
            "======ddpg Validation from:  2024-04-08 00:00:00 to  2024-07-09 00:00:00\n",
            "ddpg Sharpe Ratio:  0.38188371061952325\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_441_25\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 219      |\n",
            "|    time_elapsed    | 37       |\n",
            "|    total_timesteps | 8232     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 136      |\n",
            "|    critic_loss     | 724      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8131     |\n",
            "|    reward          | 1.903222 |\n",
            "---------------------------------\n",
            "======td3 Validation from:  2024-04-08 00:00:00 to  2024-07-09 00:00:00\n",
            "td3 Sharpe Ratio:  0.2690436011986905\n",
            "======sac Training========\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_441_25\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 184        |\n",
            "|    time_elapsed    | 44         |\n",
            "|    total_timesteps | 8232       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 2.23e+03   |\n",
            "|    critic_loss     | 2.41e+04   |\n",
            "|    ent_coef        | 1.04       |\n",
            "|    ent_coef_loss   | -3.46      |\n",
            "|    learning_rate   | 0.0003     |\n",
            "|    n_updates       | 8131       |\n",
            "|    reward          | -116.99581 |\n",
            "-----------------------------------\n",
            "======sac Validation from:  2024-04-08 00:00:00 to  2024-07-09 00:00:00\n",
            "sac Sharpe Ratio:  -0.2296443508179693\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_441_25\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 838       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 2         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | -8.834203 |\n",
            "----------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 824          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 4            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0097801555 |\n",
            "|    clip_fraction        | 0.118        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 1.62e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 259          |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00984     |\n",
            "|    reward               | 0.9683751    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 578          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 817         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008068828 |\n",
            "|    clip_fraction        | 0.0926      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.00884     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 65.4        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0074     |\n",
            "|    reward               | -1.874213   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 93.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 809         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007264839 |\n",
            "|    clip_fraction        | 0.0516      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.00405     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 261         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00808    |\n",
            "|    reward               | 16.976238   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 528         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 810         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007297076 |\n",
            "|    clip_fraction        | 0.0446      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.0013      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.03e+03    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00647    |\n",
            "|    reward               | 0.898031    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 3.75e+03    |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2024-04-08 00:00:00 to  2024-07-09 00:00:00\n",
            "ppo Sharpe Ratio:  -0.15390753155208153\n",
            "======Best Model Retraining from:  2016-02-02 to  2024-07-09 00:00:00\n",
            "======Trading from:  2024-07-09 00:00:00 to  2024-10-07 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  82.25897481973143\n",
            "======Model training from:  2016-02-02 to  2024-07-09 00:00:00\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_504_25\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 721       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 0         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | -0.0275   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -483      |\n",
            "|    reward             | 0.8526556 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 2.77e+03  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 725        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | 0.0413     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 69.7       |\n",
            "|    reward             | -2.9979446 |\n",
            "|    std                | 0.992      |\n",
            "|    value_loss         | 38.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 713        |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 2          |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | 0.11       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -112       |\n",
            "|    reward             | -0.8861563 |\n",
            "|    std                | 0.989      |\n",
            "|    value_loss         | 112        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 700        |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 2          |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | 0.0997     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -74.2      |\n",
            "|    reward             | -14.808665 |\n",
            "|    std                | 0.99       |\n",
            "|    value_loss         | 77.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 697       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | -0.0104   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -4.92     |\n",
            "|    reward             | 6.7462564 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 81.6      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 698      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.7    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -40      |\n",
            "|    reward             | -1.64683 |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 14.6     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 697        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | 0.409      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -101       |\n",
            "|    reward             | -3.7942188 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 69         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 696        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | 0.0519     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 85         |\n",
            "|    reward             | 0.10887879 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 70.1       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.7    |\n",
            "|    explained_variance | -4.45    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -3.05    |\n",
            "|    reward             | 0.609102 |\n",
            "|    std                | 0.995    |\n",
            "|    value_loss         | 0.853    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 681        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 7          |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | 0.0048     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 23         |\n",
            "|    reward             | -0.9694919 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 3.49       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 682       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | -0.312    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 1.82      |\n",
            "|    reward             | 3.2018397 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 2.05      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 682       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | -0.0357   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -1.71     |\n",
            "|    reward             | 1.1204344 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 0.412     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 684        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | -0.665     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 3.71       |\n",
            "|    reward             | 0.04887542 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 0.181      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 686         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 10          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.7       |\n",
            "|    explained_variance | 0.327       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | -18.2       |\n",
            "|    reward             | -0.87363535 |\n",
            "|    std                | 0.997       |\n",
            "|    value_loss         | 1.41        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 689        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | -0.0228    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -2.94      |\n",
            "|    reward             | -1.4335816 |\n",
            "|    std                | 0.994      |\n",
            "|    value_loss         | 0.572      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 692       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0.0588    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 24        |\n",
            "|    reward             | 0.7793427 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 2.83      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 695       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 1.64      |\n",
            "|    reward             | 0.1271041 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 0.0185    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 697        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.7      |\n",
            "|    explained_variance | -0.0245    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 3.39       |\n",
            "|    reward             | -0.5394177 |\n",
            "|    std                | 0.997      |\n",
            "|    value_loss         | 1.16       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 667        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 14         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | 0.149      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 1.79       |\n",
            "|    reward             | -0.1041679 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.799      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 669      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.8    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 36.8     |\n",
            "|    reward             | 1.092288 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 11.3     |\n",
            "------------------------------------\n",
            "======a2c Validation from:  2024-07-09 00:00:00 to  2024-10-07 00:00:00\n",
            "a2c Sharpe Ratio:  -0.043136116078230334\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_504_25\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 241      |\n",
            "|    time_elapsed    | 35       |\n",
            "|    total_timesteps | 8484     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 449      |\n",
            "|    critic_loss     | 1.1e+04  |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 8383     |\n",
            "|    reward          | 9.9964   |\n",
            "---------------------------------\n",
            "======ddpg Validation from:  2024-07-09 00:00:00 to  2024-10-07 00:00:00\n",
            "ddpg Sharpe Ratio:  0.09749451449220096\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_504_25\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 212      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 8484     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 745      |\n",
            "|    critic_loss     | 2.33e+04 |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8383     |\n",
            "|    reward          | 5.82534  |\n",
            "---------------------------------\n",
            "======td3 Validation from:  2024-07-09 00:00:00 to  2024-10-07 00:00:00\n",
            "td3 Sharpe Ratio:  0.09652807681182102\n",
            "======sac Training========\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_504_25\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 184      |\n",
            "|    time_elapsed    | 45       |\n",
            "|    total_timesteps | 8484     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 2.98e+03 |\n",
            "|    critic_loss     | 4.17e+03 |\n",
            "|    ent_coef        | 1.2      |\n",
            "|    ent_coef_loss   | -19.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8383     |\n",
            "|    reward          | 0.246132 |\n",
            "---------------------------------\n",
            "======sac Validation from:  2024-07-09 00:00:00 to  2024-10-07 00:00:00\n",
            "sac Sharpe Ratio:  0.2086237095310019\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_504_25\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 937        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 2          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | -14.885291 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 906         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01010018  |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.00024     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 976         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00965    |\n",
            "|    reward               | -0.39632058 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 2.25e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 896         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011281991 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | -0.00736    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 146         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0117     |\n",
            "|    reward               | 2.94714     |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 209         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 890         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010507859 |\n",
            "|    clip_fraction        | 0.117       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.0109      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 79.5        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00923    |\n",
            "|    reward               | -0.88166946 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 117         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 887         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008831542 |\n",
            "|    clip_fraction        | 0.099       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.00671     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 425         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00825    |\n",
            "|    reward               | -0.0815732  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 886         |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2024-07-09 00:00:00 to  2024-10-07 00:00:00\n",
            "ppo Sharpe Ratio:  0.03318925621907547\n",
            "======Best Model Retraining from:  2016-02-02 to  2024-10-07 00:00:00\n",
            "======Trading from:  2024-10-07 00:00:00 to  2025-01-07 00:00:00\n",
            "============================================\n",
            "turbulence_threshold:  82.25897481973143\n",
            "======Model training from:  2016-02-02 to  2024-10-07 00:00:00\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_567_13\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 729         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 0           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | -0.701      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | 0.405       |\n",
            "|    reward             | 0.004296558 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.166       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 739         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 1           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | 0.0315      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | 15          |\n",
            "|    reward             | -0.44364765 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 1.57        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 744         |\n",
            "|    iterations         | 300         |\n",
            "|    time_elapsed       | 2           |\n",
            "|    total_timesteps    | 1500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | -0.166      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 299         |\n",
            "|    policy_loss        | -30.8       |\n",
            "|    reward             | -0.38859457 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 8.97        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 748         |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 2           |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | -0.0166     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | -20.2       |\n",
            "|    reward             | -0.07948888 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 5.38        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 743         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.8       |\n",
            "|    explained_variance | -3.09       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | -2.36       |\n",
            "|    reward             | -0.70828736 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.188       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 747        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.8      |\n",
            "|    explained_variance | -0.616     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 10.7       |\n",
            "|    reward             | -0.8179848 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.772      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 748       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.8     |\n",
            "|    explained_variance | 0.209     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -2.23     |\n",
            "|    reward             | 0.2364646 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.0606    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 747      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -12.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 1.19     |\n",
            "|    reward             | 0.102327 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.00739  |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 746        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -12.9      |\n",
            "|    explained_variance | -0.0219    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -3.74      |\n",
            "|    reward             | 0.05326208 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.2        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 747         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 6           |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -12.9       |\n",
            "|    explained_variance | 0.204       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -5.42       |\n",
            "|    reward             | 0.004992102 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.145       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 746         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13         |\n",
            "|    explained_variance | -239        |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 0.358       |\n",
            "|    reward             | 0.020407993 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.00459     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 744        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.1      |\n",
            "|    explained_variance | -3.98      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 0.228      |\n",
            "|    reward             | 0.00611733 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.000399   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 745         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 0.17        |\n",
            "|    reward             | 0.031877246 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.000449    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 746        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.2      |\n",
            "|    explained_variance | 0.0598     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 82.4       |\n",
            "|    reward             | -2.7860615 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 46.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 746       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0.0169    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 0.57      |\n",
            "|    reward             | 0.4414291 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.208     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 745        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | -0.0405    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 14.2       |\n",
            "|    reward             | 0.34921783 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.28       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 746        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -13.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | -2.24      |\n",
            "|    reward             | 0.07953556 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.17       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 745         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 12          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -13.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 14.1        |\n",
            "|    reward             | 0.033736885 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 1.34        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 746       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -13.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -6.16     |\n",
            "|    reward             | 0.6443208 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.473     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 747      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -13.3    |\n",
            "|    explained_variance | 0.0914   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -15.9    |\n",
            "|    reward             | 0.559104 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 2.07     |\n",
            "------------------------------------\n",
            "======a2c Validation from:  2024-10-07 00:00:00 to  2025-01-07 00:00:00\n",
            "a2c Sharpe Ratio:  0.41703440592554064\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_567_13\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 271       |\n",
            "|    time_elapsed    | 32        |\n",
            "|    total_timesteps | 8736      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 474       |\n",
            "|    critic_loss     | 7.86e+03  |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 8635      |\n",
            "|    reward          | 162.09842 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2024-10-07 00:00:00 to  2025-01-07 00:00:00\n",
            "ddpg Sharpe Ratio:  0.4795502154824948\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/td3/td3_567_13\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 227       |\n",
            "|    time_elapsed    | 38        |\n",
            "|    total_timesteps | 8736      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 166       |\n",
            "|    critic_loss     | 2.31e+04  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 8635      |\n",
            "|    reward          | 148.56987 |\n",
            "----------------------------------\n",
            "======td3 Validation from:  2024-10-07 00:00:00 to  2025-01-07 00:00:00\n",
            "td3 Sharpe Ratio:  0.4829035101524364\n",
            "======sac Training========\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/sac/sac_567_11\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 173       |\n",
            "|    time_elapsed    | 50        |\n",
            "|    total_timesteps | 8736      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 527       |\n",
            "|    critic_loss     | 1.58e+04  |\n",
            "|    ent_coef        | 0.0497    |\n",
            "|    ent_coef_loss   | -32.4     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 8635      |\n",
            "|    reward          | 2.6179245 |\n",
            "----------------------------------\n",
            "======sac Validation from:  2024-10-07 00:00:00 to  2025-01-07 00:00:00\n",
            "sac Sharpe Ratio:  0.5220803298851239\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo/ppo_567_11\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 874       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 2         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | -0.638528 |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 859         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007868381 |\n",
            "|    clip_fraction        | 0.0875      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | -0.000899   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 26.6        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00739    |\n",
            "|    reward               | 12.330823   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 55.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 843          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054945583 |\n",
            "|    clip_fraction        | 0.0167       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | -0.000141    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.13e+03     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00461     |\n",
            "|    reward               | -0.9312829   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 3.62e+03     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 844         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007505424 |\n",
            "|    clip_fraction        | 0.0562      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.00514     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 466         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00732    |\n",
            "|    reward               | 0.57848334  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 796         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 837         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009266179 |\n",
            "|    clip_fraction        | 0.0729      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | -0.0053     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.21e+03    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00852    |\n",
            "|    reward               | -8.261983   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 2e+03       |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2024-10-07 00:00:00 to  2025-01-07 00:00:00\n",
            "ppo Sharpe Ratio:  -0.07242782951433253\n",
            "======Best Model Retraining from:  2016-02-02 to  2025-01-07 00:00:00\n",
            "======Trading from:  2025-01-07 00:00:00 to  2025-04-09 00:00:00\n",
            "Ensemble Strategy took:  22.18157372872035  minutes\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Daily return saved to: df_daily_return_ensemble.csv\n"
          ]
        }
      ],
      "source": [
        "df_daily_return = run_ensemble_and_generate_daily_return(\n",
        "    ensemble_agent = ensemble_agent,\n",
        "    A2C_kwargs = A2C_model_kwargs,\n",
        "    PPO_kwargs = PPO_model_kwargs,\n",
        "    DDPG_kwargs = DDPG_model_kwargs,\n",
        "    SAC_kwargs = SAC_model_kwargs,\n",
        "    TD3_kwargs = TD3_model_kwargs,\n",
        "    timesteps_dict = timesteps_dict,\n",
        "    processed_df = processed,\n",
        "    trade_start_date = '2023-01-04',\n",
        "    trade_end_date = '2025-04-11',\n",
        "    rebalance_window = 63,\n",
        "    validation_window = 63,\n",
        "    output_csv_name = \"df_daily_return_ensemble.csv\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
