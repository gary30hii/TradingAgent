{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/FinRL_PortfolioAllocation_NeurIPS_2020.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv3IDvrobU37"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Portfolio Allocation\n",
        "\n",
        "Tutorials to use OpenAI DRL to perform portfolio allocation in one Jupyter Notebook | Presented at NeurIPS 2020: Deep RL Workshop\n",
        "\n",
        "* This blog is based on our paper: FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance, presented at NeurIPS 2020: Deep RL Workshop.\n",
        "* Check out medium blog for detailed explanations: https://towardsdatascience.com/finrl-for-quantitative-finance-tutorial-for-portfolio-allocation-9b417660c7cd\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-Foundation/FinRL/issues\n",
        "* **Pytorch Version**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kHCfEiTA80V"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUmLTmoQA7_w"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12v1i0jVkg48"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L63HKnWvkirx"
      },
      "source": [
        "This problem is to design an automated trading solution for portfolio alloacation. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A represents the weight of a stock in the porfolio: a ∈ (-1,1). Assume our stock pool includes N stocks, we can use a list [a<sub>1</sub>, a<sub>2</sub>, ... , a<sub>N</sub>] to determine the weight for each stock in the porfotlio, where a<sub>i</sub> ∈ (-1,1), a<sub>1</sub>+ a<sub>2</sub>+...+a<sub>N</sub>=1. For example, \"The weight of AAPL in the portfolio is 10%.\" is [0.1 , ...].\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_emqQCCklVt"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVCcCalAknGn"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "pT8a0fvhA_TW",
        "outputId": "c7abc977-bf49-4a96-e636-cbf8cbfecd87",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wrds in /opt/anaconda3/lib/python3.12/site-packages (3.3.0)\n",
            "Requirement already satisfied: packaging<=24.2 in /opt/anaconda3/lib/python3.12/site-packages (from wrds) (24.1)\n",
            "Requirement already satisfied: pandas<2.3,>=2.2 in /opt/anaconda3/lib/python3.12/site-packages (from wrds) (2.2.3)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from wrds) (2.9.10)\n",
            "Requirement already satisfied: sqlalchemy<2.1,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from wrds) (2.0.34)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<2.3,>=2.2->wrds) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<2.3,>=2.2->wrds) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<2.3,>=2.2->wrds) (2023.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from sqlalchemy<2.1,>=2->wrds) (4.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.16.0)\n",
            "Requirement already satisfied: swig in /opt/anaconda3/lib/python3.12/site-packages (4.3.0)\n",
            "Requirement already satisfied: shimmy>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from shimmy>=2.0) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /opt/anaconda3/lib/python3.12/site-packages (from shimmy>=2.0) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n",
            "Requirement already satisfied: pandas_market_calendars in /opt/anaconda3/lib/python3.12/site-packages (5.0.0)\n",
            "Requirement already satisfied: pandas>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas_market_calendars) (2.2.3)\n",
            "Requirement already satisfied: tzdata in /opt/anaconda3/lib/python3.12/site-packages (from pandas_market_calendars) (2023.3)\n",
            "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.12/site-packages (from pandas_market_calendars) (2.9.0.post0)\n",
            "Requirement already satisfied: exchange-calendars>=3.3 in /opt/anaconda3/lib/python3.12/site-packages (from pandas_market_calendars) (4.10)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (1.26.4)\n",
            "Requirement already satisfied: pyluach in /opt/anaconda3/lib/python3.12/site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (2.2.0)\n",
            "Requirement already satisfied: toolz in /opt/anaconda3/lib/python3.12/site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (0.12.0)\n",
            "Requirement already satisfied: korean_lunar_calendar in /opt/anaconda3/lib/python3.12/site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (0.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.1->pandas_market_calendars) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil->pandas_market_calendars) (1.16.0)\n",
            "zsh:1: command not found: apt-get\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /private/var/folders/ks/bjl76g8d4zxgw0m5p8z2pd9r0000gn/T/pip-req-build-3z480sdj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /private/var/folders/ks/bjl76g8d4zxgw0m5p8z2pd9r0000gn/T/pip-req-build-3z480sdj\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit d25d902a6de54931a329adc38a2663e8f576adc4\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git (from finrl==0.3.8)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /private/var/folders/ks/bjl76g8d4zxgw0m5p8z2pd9r0000gn/T/pip-install-c6oj3qxy/elegantrl_df73e353c2824c1e97d4b46aa86a937c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /private/var/folders/ks/bjl76g8d4zxgw0m5p8z2pd9r0000gn/T/pip-install-c6oj3qxy/elegantrl_df73e353c2824c1e97d4b46aa86a937c\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 5e828af1503098f4da046c0f12432dbd4ef8bd97\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: alpaca-py<0.38,>=0.37 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (0.37.0)\n",
            "Requirement already satisfied: alpaca-trade-api<4,>=3 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (3.2.0)\n",
            "Requirement already satisfied: ccxt<4,>=3 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (3.1.60)\n",
            "Requirement already satisfied: jqdatasdk<2,>=1 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (1.9.7)\n",
            "Requirement already satisfied: pyfolio-reloaded<0.10,>=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (0.9.8)\n",
            "Requirement already satisfied: pyportfolioopt<2,>=1 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (1.5.6)\n",
            "Requirement already satisfied: ray<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2.44.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (1.6.1)\n",
            "Requirement already satisfied: selenium<5,>=4 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (4.31.0)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0a5 in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.5.0)\n",
            "Requirement already satisfied: stockstats<0.6,>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (0.5.4)\n",
            "Requirement already satisfied: webdriver-manager<5,>=4 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (4.0.2)\n",
            "Requirement already satisfied: wrds<4,>=3 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (3.3.0)\n",
            "Requirement already satisfied: yfinance<0.3,>=0.2 in /opt/anaconda3/lib/python3.12/site-packages (from finrl==0.3.8) (0.2.55)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (1.0.3)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.2.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.3 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.32.3)\n",
            "Requirement already satisfied: sseclient-py<2.0.0,>=1.7.2 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (1.8.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (10.4)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (1.26.4)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (1.26.20)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (1.8.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (3.10.5)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (6.0.1)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (2.1.0)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.8) (24.1)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from ccxt<4,>=3->finrl==0.3.8) (75.1.0)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from ccxt<4,>=3->finrl==0.3.8) (2025.1.31)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from ccxt<4,>=3->finrl==0.3.8) (43.0.0)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from ccxt<4,>=3->finrl==0.3.8) (3.2.0)\n",
            "Requirement already satisfied: yarl>=1.7.2 in /opt/anaconda3/lib/python3.12/site-packages (from ccxt<4,>=3->finrl==0.3.8) (1.11.0)\n",
            "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (1.16.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /opt/anaconda3/lib/python3.12/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (2.0.34)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /opt/anaconda3/lib/python3.12/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (1.1.1)\n",
            "Requirement already satisfied: thriftpy2!=0.5.1,>=0.3.9 in /opt/anaconda3/lib/python3.12/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (0.5.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (8.27.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.9.2)\n",
            "Requirement already satisfied: pytz>=2014.10 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2024.1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.13.1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.13.2)\n",
            "Requirement already satisfied: empyrical-reloaded>=0.5.9 in /opt/anaconda3/lib/python3.12/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.5.11)\n",
            "Requirement already satisfied: cvxpy>=1.1.19 in /opt/anaconda3/lib/python3.12/site-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (1.6.4)\n",
            "Requirement already satisfied: ecos<3.0.0,>=2.0.14 in /opt/anaconda3/lib/python3.12/site-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (2.0.14)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (5.24.1)\n",
            "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (8.1.7)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (4.23.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (4.25.3)\n",
            "Requirement already satisfied: aiosignal in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (1.2.0)\n",
            "Requirement already satisfied: frozenlist in /opt/anaconda3/lib/python3.12/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (1.4.0)\n",
            "Requirement already satisfied: aiohttp-cors in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.8.1)\n",
            "Requirement already satisfied: colorful in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.5.6)\n",
            "Requirement already satisfied: opencensus in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.11.4)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.14.1)\n",
            "Requirement already satisfied: smart-open in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (5.2.1)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (20.30.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (1.71.0)\n",
            "Requirement already satisfied: py-spy>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.4.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (19.0.1)\n",
            "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2024.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn<2,>=1->finrl==0.3.8) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn<2,>=1->finrl==0.3.8) (3.5.0)\n",
            "Requirement already satisfied: trio~=0.17 in /opt/anaconda3/lib/python3.12/site-packages (from selenium<5,>=4->finrl==0.3.8) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium<5,>=4->finrl==0.3.8) (0.12.2)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium<5,>=4->finrl==0.3.8) (4.11.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.0.0)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.6.0)\n",
            "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.0.0)\n",
            "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.19.0)\n",
            "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (5.9.0)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (4.66.5)\n",
            "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (13.7.1)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.10.2)\n",
            "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (10.4.0)\n",
            "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (from webdriver-manager<5,>=4->finrl==0.3.8) (0.21.0)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from wrds<4,>=3->finrl==0.3.8) (2.9.10)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (3.10.0)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (2.4.2)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (3.17.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (4.12.3)\n",
            "Requirement already satisfied: th in /opt/anaconda3/lib/python3.12/site-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.8) (0.4.1)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.8) (4.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (2.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (25.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (6.0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.8) (2.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.8) (1.17.1)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (1.0.3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (0.10.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /opt/anaconda3/lib/python3.12/site-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (3.2.7.post2)\n",
            "Requirement already satisfied: bottleneck>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from empyrical-reloaded>=0.5.9->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.3.7)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.0.4)\n",
            "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.15.1)\n",
            "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (5.14.3)\n",
            "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (4.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (2023.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from plotly<6.0.0,>=5.0.0->pyportfolioopt<2,>=1->finrl==0.3.8) (8.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.8) (3.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.0.3)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /opt/anaconda3/lib/python3.12/site-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.8) (3.0.12)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /opt/anaconda3/lib/python3.12/site-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.8) (3.11)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.3)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (2.4.0)\n",
            "Requirement already satisfied: outcome in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (1.3.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /opt/anaconda3/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.8) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium<5,>=4->finrl==0.3.8) (1.7.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/anaconda3/lib/python3.12/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.8) (0.3.9)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (0.10.6)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (2.24.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.2.0)\n",
            "Requirement already satisfied: niltype<2.0,>=0.3 in /opt/anaconda3/lib/python3.12/site-packages (from th->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.8) (1.0.2)\n",
            "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.8) (2.21)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (1.69.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (2.38.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.8.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.1.3)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.8) (0.14.0)\n",
            "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.8.3)\n",
            "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.0.5)\n",
            "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.4.8)\n"
          ]
        }
      ],
      "source": [
        "## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "\n",
        "!pip install 'shimmy>=2.0'\n",
        "!pip install pandas_market_calendars\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2568cp5bU38"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them.\n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNmvYN9YbU4B"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ntfTb0e2bU4C",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "%matplotlib inline\n",
        "import datetime\n",
        "\n",
        "from finrl import config\n",
        "from finrl import config_tickers\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "from finrl.meta.data_processors.processor_yahoofinance import YahooFinanceProcessor\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlIS2abxkwan"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "B8bBq7nsBCfF",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slBria_QbU4F"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Dx1LMUjNqqPX"
      },
      "outputs": [],
      "source": [
        "TRAIN_START_DATE = '2016-02-02'\n",
        "TRAIN_END_DATE = '2023-04-03'\n",
        "TRADE_START_DATE = '2023-04-04'\n",
        "TRADE_END_DATE = '2025-04-08'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CPsuy6d9yRPp",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVnjL69hY9wt",
        "outputId": "687d4d1a-38d0-41a7-a888-9a6e3410764d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date      0\n",
            "close     0\n",
            "high      0\n",
            "low       0\n",
            "open      0\n",
            "volume    0\n",
            "tic       0\n",
            "day       0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esUbUY4oY0a9",
        "outputId": "b138d0bd-6dd9-4cb4-9cb2-d1298a95220f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24243, 8)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHR0DwZQXMOP",
        "outputId": "48e1e57a-735e-4a5c-ceb4-1bfb8caf0af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      tic            unique_days\n",
            "0     agg        [0, 1, 2, 3, 4]\n",
            "1     bil        [0, 1, 2, 3, 4]\n",
            "2  btcusd  [0, 1, 2, 3, 4, 5, 6]\n",
            "3     gld        [0, 1, 2, 3, 4]\n",
            "4     spy        [0, 1, 2, 3, 4]\n",
            "5      vb        [0, 1, 2, 3, 4]\n",
            "6     vnq        [0, 1, 2, 3, 4]\n",
            "7      vo        [0, 1, 2, 3, 4]\n",
            "8     vwo        [0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "day_values_per_tic = df.groupby('tic')['day'].apply(lambda x: sorted(x.unique())).reset_index()\n",
        "day_values_per_tic.columns = ['tic', 'unique_days']\n",
        "\n",
        "# Display\n",
        "print(day_values_per_tic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK2PhVx8X9N3",
        "outputId": "7fc8af15-435b-42ac-838c-6bccbf986fc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5-day tickers: ['agg', 'bil', 'gld', 'spy', 'vb', 'vnq', 'vo', 'vwo']\n",
            "7-day tickers: ['btcusd']\n",
            "5-day df shape: (20520, 8)\n",
            "7-day df shape: (3723, 8)\n"
          ]
        }
      ],
      "source": [
        "# Match 5-day and 7-day tickers using apply\n",
        "tics_5day = day_values_per_tic[day_values_per_tic['unique_days'].apply(lambda x: x == list(range(5)))]['tic']\n",
        "tics_7day = day_values_per_tic[day_values_per_tic['unique_days'].apply(lambda x: x == list(range(7)))]['tic']\n",
        "\n",
        "# Filter the original df\n",
        "df_5day_full = df[df['tic'].isin(tics_5day)]\n",
        "df_7day_full = df[df['tic'].isin(tics_7day)]\n",
        "\n",
        "# Results\n",
        "print(\"5-day tickers:\", tics_5day.tolist())\n",
        "print(\"7-day tickers:\", tics_7day.tolist())\n",
        "print(\"5-day df shape:\", df_5day_full.shape)\n",
        "print(\"7-day df shape:\", df_7day_full.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS1-nxRzbU4i",
        "outputId": "d3a725ad-5eee-40c4-e621-a1bce79a1b4b",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24243, 8)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "V1xC-LpbbU4f",
        "outputId": "70bdbcba-1704-424b-c694-b7ce6b4a8f23",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-02-01</td>\n",
              "      <td>228.99</td>\n",
              "      <td>233.790</td>\n",
              "      <td>210.00</td>\n",
              "      <td>218.67</td>\n",
              "      <td>7220.0</td>\n",
              "      <td>btcusd</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>112.20</td>\n",
              "      <td>112.230</td>\n",
              "      <td>112.00</td>\n",
              "      <td>112.06</td>\n",
              "      <td>2792120.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>91.46</td>\n",
              "      <td>91.480</td>\n",
              "      <td>91.46</td>\n",
              "      <td>91.48</td>\n",
              "      <td>3557487.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>237.83</td>\n",
              "      <td>240.100</td>\n",
              "      <td>220.89</td>\n",
              "      <td>228.39</td>\n",
              "      <td>7421.0</td>\n",
              "      <td>btcusd</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>122.42</td>\n",
              "      <td>123.155</td>\n",
              "      <td>121.82</td>\n",
              "      <td>121.84</td>\n",
              "      <td>8885189.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   close     high     low    open     volume     tic  day\n",
              "0  2015-02-01  228.99  233.790  210.00  218.67     7220.0  btcusd    6\n",
              "1  2015-02-02  112.20  112.230  112.00  112.06  2792120.0     agg    0\n",
              "2  2015-02-02   91.46   91.480   91.46   91.48  3557487.0     bil    0\n",
              "3  2015-02-02  237.83  240.100  220.89  228.39     7421.0  btcusd    0\n",
              "4  2015-02-02  122.42  123.155  121.82  121.84  8885189.0     gld    0"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9UwKwzRbU4l"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5h8RbeBHMDQ",
        "outputId": "ac089851-7100-479f-e3e9-9f3def5d357b",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added technical indicators\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    use_turbulence=False,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "df_5day_full = fe.preprocess_data(df_5day_full)\n",
        "df_7day_full = fe.preprocess_data(df_7day_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zsIW1LAiqCb",
        "outputId": "c51e4d4c-b214-47a9-f9c0-6ece0857bda7",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20520, 16)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_5day_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anBCxKtIZRvG",
        "outputId": "47bbec44-bf34-447a-b9d9-2d46272a67da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3723, 16)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_7day_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "GlzWEH8oZdLI"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df_5day_full, df_7day_full], ignore_index=False)\n",
        "df.index = range(len(df))  # Assign new sequential index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhkZptZ5aGI6",
        "outputId": "3b1ac3ee-a1f7-433a-822f-239b02cee8f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24243, 16)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lWB-RoTSbU4s",
        "outputId": "079ac2e9-6a78-4cef-bf8d-61c3cdf99583",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>112.20</td>\n",
              "      <td>112.2300</td>\n",
              "      <td>112.0000</td>\n",
              "      <td>112.06</td>\n",
              "      <td>2792120.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>112.200000</td>\n",
              "      <td>112.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>91.46</td>\n",
              "      <td>91.4800</td>\n",
              "      <td>91.4600</td>\n",
              "      <td>91.48</td>\n",
              "      <td>3557487.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>91.460000</td>\n",
              "      <td>91.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>122.42</td>\n",
              "      <td>123.1550</td>\n",
              "      <td>121.8200</td>\n",
              "      <td>121.84</td>\n",
              "      <td>8885189.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>122.420000</td>\n",
              "      <td>122.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>201.92</td>\n",
              "      <td>202.0300</td>\n",
              "      <td>197.8600</td>\n",
              "      <td>200.05</td>\n",
              "      <td>163106969.0</td>\n",
              "      <td>spy</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>201.920000</td>\n",
              "      <td>201.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>115.12</td>\n",
              "      <td>115.2100</td>\n",
              "      <td>112.8500</td>\n",
              "      <td>114.38</td>\n",
              "      <td>549866.0</td>\n",
              "      <td>vb</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>115.120000</td>\n",
              "      <td>115.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>86.32</td>\n",
              "      <td>86.6900</td>\n",
              "      <td>84.6851</td>\n",
              "      <td>86.53</td>\n",
              "      <td>7523640.0</td>\n",
              "      <td>vnq</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.320000</td>\n",
              "      <td>86.320000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>122.30</td>\n",
              "      <td>122.3899</td>\n",
              "      <td>119.9400</td>\n",
              "      <td>121.66</td>\n",
              "      <td>823489.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>122.300000</td>\n",
              "      <td>122.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>40.65</td>\n",
              "      <td>40.7600</td>\n",
              "      <td>40.2800</td>\n",
              "      <td>40.40</td>\n",
              "      <td>15944366.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>40.650000</td>\n",
              "      <td>40.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>111.77</td>\n",
              "      <td>112.1000</td>\n",
              "      <td>111.7600</td>\n",
              "      <td>112.10</td>\n",
              "      <td>1815375.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.009647</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>111.985000</td>\n",
              "      <td>111.985000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>91.48</td>\n",
              "      <td>91.4800</td>\n",
              "      <td>91.4600</td>\n",
              "      <td>91.46</td>\n",
              "      <td>266084.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>91.498284</td>\n",
              "      <td>91.441716</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>91.470000</td>\n",
              "      <td>91.470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>121.05</td>\n",
              "      <td>121.7600</td>\n",
              "      <td>120.5648</td>\n",
              "      <td>121.74</td>\n",
              "      <td>8255863.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.030737</td>\n",
              "      <td>123.672473</td>\n",
              "      <td>119.797527</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>121.735000</td>\n",
              "      <td>121.735000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>204.84</td>\n",
              "      <td>204.8500</td>\n",
              "      <td>202.5500</td>\n",
              "      <td>203.00</td>\n",
              "      <td>124212881.0</td>\n",
              "      <td>spy</td>\n",
              "      <td>1</td>\n",
              "      <td>0.065513</td>\n",
              "      <td>207.509504</td>\n",
              "      <td>199.250496</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>203.380000</td>\n",
              "      <td>203.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>117.28</td>\n",
              "      <td>117.3300</td>\n",
              "      <td>115.5000</td>\n",
              "      <td>115.50</td>\n",
              "      <td>650585.0</td>\n",
              "      <td>vb</td>\n",
              "      <td>1</td>\n",
              "      <td>0.048462</td>\n",
              "      <td>119.254701</td>\n",
              "      <td>113.145299</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>116.200000</td>\n",
              "      <td>116.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>87.07</td>\n",
              "      <td>87.1000</td>\n",
              "      <td>85.6600</td>\n",
              "      <td>86.33</td>\n",
              "      <td>4617437.0</td>\n",
              "      <td>vnq</td>\n",
              "      <td>1</td>\n",
              "      <td>0.016827</td>\n",
              "      <td>87.755660</td>\n",
              "      <td>85.634340</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.695000</td>\n",
              "      <td>86.695000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>124.26</td>\n",
              "      <td>124.2900</td>\n",
              "      <td>122.7400</td>\n",
              "      <td>123.05</td>\n",
              "      <td>386410.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>1</td>\n",
              "      <td>0.043974</td>\n",
              "      <td>126.051859</td>\n",
              "      <td>120.508141</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>123.280000</td>\n",
              "      <td>123.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>41.37</td>\n",
              "      <td>41.4100</td>\n",
              "      <td>41.0000</td>\n",
              "      <td>41.03</td>\n",
              "      <td>20858075.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>1</td>\n",
              "      <td>0.016154</td>\n",
              "      <td>42.028234</td>\n",
              "      <td>39.991766</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.010000</td>\n",
              "      <td>41.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2015-02-04</td>\n",
              "      <td>111.94</td>\n",
              "      <td>111.9500</td>\n",
              "      <td>111.5000</td>\n",
              "      <td>111.64</td>\n",
              "      <td>1953033.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.007021</td>\n",
              "      <td>112.403128</td>\n",
              "      <td>111.536872</td>\n",
              "      <td>29.026750</td>\n",
              "      <td>-69.565217</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>111.970000</td>\n",
              "      <td>111.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2015-02-04</td>\n",
              "      <td>91.46</td>\n",
              "      <td>91.4800</td>\n",
              "      <td>91.4600</td>\n",
              "      <td>91.46</td>\n",
              "      <td>214178.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.000048</td>\n",
              "      <td>91.489761</td>\n",
              "      <td>91.443573</td>\n",
              "      <td>49.152542</td>\n",
              "      <td>-50.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>91.466667</td>\n",
              "      <td>91.466667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2015-02-04</td>\n",
              "      <td>121.58</td>\n",
              "      <td>122.2200</td>\n",
              "      <td>120.9200</td>\n",
              "      <td>121.63</td>\n",
              "      <td>5386747.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.022730</td>\n",
              "      <td>123.064975</td>\n",
              "      <td>120.301692</td>\n",
              "      <td>28.581701</td>\n",
              "      <td>-19.861991</td>\n",
              "      <td>43.704008</td>\n",
              "      <td>121.683333</td>\n",
              "      <td>121.683333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2015-02-04</td>\n",
              "      <td>204.06</td>\n",
              "      <td>205.3800</td>\n",
              "      <td>203.5100</td>\n",
              "      <td>203.92</td>\n",
              "      <td>134306728.0</td>\n",
              "      <td>spy</td>\n",
              "      <td>2</td>\n",
              "      <td>0.059289</td>\n",
              "      <td>206.630395</td>\n",
              "      <td>200.582938</td>\n",
              "      <td>78.349371</td>\n",
              "      <td>54.937413</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>203.606667</td>\n",
              "      <td>203.606667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2015-02-04</td>\n",
              "      <td>116.77</td>\n",
              "      <td>117.4120</td>\n",
              "      <td>116.5600</td>\n",
              "      <td>116.85</td>\n",
              "      <td>447819.0</td>\n",
              "      <td>vb</td>\n",
              "      <td>2</td>\n",
              "      <td>0.045935</td>\n",
              "      <td>118.648052</td>\n",
              "      <td>114.131948</td>\n",
              "      <td>80.369515</td>\n",
              "      <td>56.541540</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>116.390000</td>\n",
              "      <td>116.390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2015-02-04</td>\n",
              "      <td>86.71</td>\n",
              "      <td>87.0900</td>\n",
              "      <td>86.2101</td>\n",
              "      <td>86.87</td>\n",
              "      <td>3332758.0</td>\n",
              "      <td>vnq</td>\n",
              "      <td>2</td>\n",
              "      <td>0.010277</td>\n",
              "      <td>87.450200</td>\n",
              "      <td>85.949800</td>\n",
              "      <td>66.820276</td>\n",
              "      <td>56.070923</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.700000</td>\n",
              "      <td>86.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2015-02-04</td>\n",
              "      <td>123.71</td>\n",
              "      <td>124.3900</td>\n",
              "      <td>123.3900</td>\n",
              "      <td>123.67</td>\n",
              "      <td>434403.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>2</td>\n",
              "      <td>0.038977</td>\n",
              "      <td>125.445247</td>\n",
              "      <td>121.401420</td>\n",
              "      <td>77.502045</td>\n",
              "      <td>52.218902</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>123.423333</td>\n",
              "      <td>123.423333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2015-02-04</td>\n",
              "      <td>41.09</td>\n",
              "      <td>41.5000</td>\n",
              "      <td>41.0500</td>\n",
              "      <td>41.19</td>\n",
              "      <td>8677098.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>2</td>\n",
              "      <td>0.011900</td>\n",
              "      <td>41.762568</td>\n",
              "      <td>40.310765</td>\n",
              "      <td>71.311475</td>\n",
              "      <td>44.801980</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.036667</td>\n",
              "      <td>41.036667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2015-02-05</td>\n",
              "      <td>111.71</td>\n",
              "      <td>111.8474</td>\n",
              "      <td>111.5700</td>\n",
              "      <td>111.79</td>\n",
              "      <td>2409552.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.013959</td>\n",
              "      <td>112.343938</td>\n",
              "      <td>111.466062</td>\n",
              "      <td>20.641146</td>\n",
              "      <td>-87.732027</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>111.905000</td>\n",
              "      <td>111.905000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2015-02-05</td>\n",
              "      <td>91.46</td>\n",
              "      <td>91.4800</td>\n",
              "      <td>91.4600</td>\n",
              "      <td>91.46</td>\n",
              "      <td>414793.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.000273</td>\n",
              "      <td>91.485000</td>\n",
              "      <td>91.445000</td>\n",
              "      <td>49.152542</td>\n",
              "      <td>-44.444444</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>91.465000</td>\n",
              "      <td>91.465000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2015-02-05</td>\n",
              "      <td>121.79</td>\n",
              "      <td>121.8300</td>\n",
              "      <td>120.6100</td>\n",
              "      <td>120.98</td>\n",
              "      <td>6879945.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.010949</td>\n",
              "      <td>122.843137</td>\n",
              "      <td>120.576863</td>\n",
              "      <td>36.071177</td>\n",
              "      <td>-37.859949</td>\n",
              "      <td>53.194921</td>\n",
              "      <td>121.710000</td>\n",
              "      <td>121.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2015-02-05</td>\n",
              "      <td>206.12</td>\n",
              "      <td>206.3000</td>\n",
              "      <td>204.7700</td>\n",
              "      <td>204.86</td>\n",
              "      <td>97953181.0</td>\n",
              "      <td>spy</td>\n",
              "      <td>3</td>\n",
              "      <td>0.129380</td>\n",
              "      <td>207.758086</td>\n",
              "      <td>200.711914</td>\n",
              "      <td>86.396222</td>\n",
              "      <td>88.660352</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>204.235000</td>\n",
              "      <td>204.235000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2015-02-05</td>\n",
              "      <td>118.22</td>\n",
              "      <td>118.3946</td>\n",
              "      <td>117.0400</td>\n",
              "      <td>117.13</td>\n",
              "      <td>385979.0</td>\n",
              "      <td>vb</td>\n",
              "      <td>3</td>\n",
              "      <td>0.096011</td>\n",
              "      <td>119.445211</td>\n",
              "      <td>114.249789</td>\n",
              "      <td>87.554905</td>\n",
              "      <td>90.423739</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>116.847500</td>\n",
              "      <td>116.847500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2015-02-05</td>\n",
              "      <td>87.75</td>\n",
              "      <td>87.7900</td>\n",
              "      <td>86.6700</td>\n",
              "      <td>86.92</td>\n",
              "      <td>2921645.0</td>\n",
              "      <td>vnq</td>\n",
              "      <td>3</td>\n",
              "      <td>0.044595</td>\n",
              "      <td>88.178107</td>\n",
              "      <td>85.746893</td>\n",
              "      <td>83.339982</td>\n",
              "      <td>129.141640</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>86.962500</td>\n",
              "      <td>86.962500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2015-02-05</td>\n",
              "      <td>125.23</td>\n",
              "      <td>125.2600</td>\n",
              "      <td>124.0401</td>\n",
              "      <td>124.31</td>\n",
              "      <td>327650.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>3</td>\n",
              "      <td>0.090627</td>\n",
              "      <td>126.322339</td>\n",
              "      <td>121.427661</td>\n",
              "      <td>86.308464</td>\n",
              "      <td>92.115705</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>123.875000</td>\n",
              "      <td>123.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2015-02-05</td>\n",
              "      <td>41.40</td>\n",
              "      <td>41.4300</td>\n",
              "      <td>41.0200</td>\n",
              "      <td>41.07</td>\n",
              "      <td>11220549.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>3</td>\n",
              "      <td>0.020867</td>\n",
              "      <td>41.822698</td>\n",
              "      <td>40.432302</td>\n",
              "      <td>78.406552</td>\n",
              "      <td>52.473118</td>\n",
              "      <td>91.215588</td>\n",
              "      <td>41.127500</td>\n",
              "      <td>41.127500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>111.06</td>\n",
              "      <td>111.4100</td>\n",
              "      <td>111.0300</td>\n",
              "      <td>111.41</td>\n",
              "      <td>2531315.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.043299</td>\n",
              "      <td>112.582002</td>\n",
              "      <td>110.889998</td>\n",
              "      <td>11.190113</td>\n",
              "      <td>-158.527209</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>111.736000</td>\n",
              "      <td>111.736000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>91.46</td>\n",
              "      <td>91.4800</td>\n",
              "      <td>91.4600</td>\n",
              "      <td>91.48</td>\n",
              "      <td>291738.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.000390</td>\n",
              "      <td>91.481889</td>\n",
              "      <td>91.446111</td>\n",
              "      <td>49.152542</td>\n",
              "      <td>-41.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>91.464000</td>\n",
              "      <td>91.464000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>118.64</td>\n",
              "      <td>119.5200</td>\n",
              "      <td>117.9500</td>\n",
              "      <td>119.15</td>\n",
              "      <td>13206906.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.129663</td>\n",
              "      <td>124.011977</td>\n",
              "      <td>118.180023</td>\n",
              "      <td>13.729590</td>\n",
              "      <td>-166.666667</td>\n",
              "      <td>81.618921</td>\n",
              "      <td>121.096000</td>\n",
              "      <td>121.096000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>205.55</td>\n",
              "      <td>207.2400</td>\n",
              "      <td>204.9200</td>\n",
              "      <td>206.56</td>\n",
              "      <td>125672026.0</td>\n",
              "      <td>spy</td>\n",
              "      <td>4</td>\n",
              "      <td>0.142062</td>\n",
              "      <td>207.767936</td>\n",
              "      <td>201.228064</td>\n",
              "      <td>78.088648</td>\n",
              "      <td>82.944289</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>204.498000</td>\n",
              "      <td>204.498000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>117.90</td>\n",
              "      <td>118.6700</td>\n",
              "      <td>117.5054</td>\n",
              "      <td>118.40</td>\n",
              "      <td>718075.0</td>\n",
              "      <td>vb</td>\n",
              "      <td>4</td>\n",
              "      <td>0.108467</td>\n",
              "      <td>119.496705</td>\n",
              "      <td>114.619295</td>\n",
              "      <td>80.802631</td>\n",
              "      <td>83.683983</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>117.058000</td>\n",
              "      <td>117.058000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>85.20</td>\n",
              "      <td>87.6600</td>\n",
              "      <td>84.8333</td>\n",
              "      <td>87.54</td>\n",
              "      <td>6323274.0</td>\n",
              "      <td>vnq</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.039166</td>\n",
              "      <td>88.505627</td>\n",
              "      <td>84.714373</td>\n",
              "      <td>36.829281</td>\n",
              "      <td>-83.375151</td>\n",
              "      <td>29.930975</td>\n",
              "      <td>86.610000</td>\n",
              "      <td>86.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>124.70</td>\n",
              "      <td>125.6000</td>\n",
              "      <td>124.2800</td>\n",
              "      <td>125.52</td>\n",
              "      <td>395036.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>4</td>\n",
              "      <td>0.095696</td>\n",
              "      <td>126.284237</td>\n",
              "      <td>121.795763</td>\n",
              "      <td>75.630061</td>\n",
              "      <td>81.637535</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>124.040000</td>\n",
              "      <td>124.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>40.72</td>\n",
              "      <td>41.0100</td>\n",
              "      <td>40.5901</td>\n",
              "      <td>40.77</td>\n",
              "      <td>19723986.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.001759</td>\n",
              "      <td>41.749790</td>\n",
              "      <td>40.342210</td>\n",
              "      <td>50.221907</td>\n",
              "      <td>-58.352443</td>\n",
              "      <td>14.307999</td>\n",
              "      <td>41.046000</td>\n",
              "      <td>41.046000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2015-02-09</td>\n",
              "      <td>111.04</td>\n",
              "      <td>111.3100</td>\n",
              "      <td>111.0400</td>\n",
              "      <td>111.31</td>\n",
              "      <td>1724911.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.060979</td>\n",
              "      <td>112.566319</td>\n",
              "      <td>110.673681</td>\n",
              "      <td>11.029369</td>\n",
              "      <td>-103.751108</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>111.620000</td>\n",
              "      <td>111.620000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2015-02-09</td>\n",
              "      <td>91.44</td>\n",
              "      <td>91.4600</td>\n",
              "      <td>91.4400</td>\n",
              "      <td>91.46</td>\n",
              "      <td>147068.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.001308</td>\n",
              "      <td>91.485298</td>\n",
              "      <td>91.434702</td>\n",
              "      <td>31.449374</td>\n",
              "      <td>-200.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>91.460000</td>\n",
              "      <td>91.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>2015-02-09</td>\n",
              "      <td>119.17</td>\n",
              "      <td>119.4000</td>\n",
              "      <td>118.7700</td>\n",
              "      <td>118.83</td>\n",
              "      <td>5237181.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.175926</td>\n",
              "      <td>123.820541</td>\n",
              "      <td>117.729459</td>\n",
              "      <td>22.124972</td>\n",
              "      <td>-88.756787</td>\n",
              "      <td>81.618921</td>\n",
              "      <td>120.775000</td>\n",
              "      <td>120.775000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>2015-02-09</td>\n",
              "      <td>204.63</td>\n",
              "      <td>205.6400</td>\n",
              "      <td>204.1350</td>\n",
              "      <td>204.77</td>\n",
              "      <td>87219016.0</td>\n",
              "      <td>spy</td>\n",
              "      <td>0</td>\n",
              "      <td>0.107675</td>\n",
              "      <td>207.446705</td>\n",
              "      <td>201.593295</td>\n",
              "      <td>67.285781</td>\n",
              "      <td>29.644269</td>\n",
              "      <td>68.991171</td>\n",
              "      <td>204.520000</td>\n",
              "      <td>204.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2015-02-09</td>\n",
              "      <td>117.19</td>\n",
              "      <td>118.1500</td>\n",
              "      <td>117.0000</td>\n",
              "      <td>117.60</td>\n",
              "      <td>249545.0</td>\n",
              "      <td>vb</td>\n",
              "      <td>0</td>\n",
              "      <td>0.083556</td>\n",
              "      <td>119.263905</td>\n",
              "      <td>114.896095</td>\n",
              "      <td>68.650680</td>\n",
              "      <td>41.011885</td>\n",
              "      <td>69.496091</td>\n",
              "      <td>117.080000</td>\n",
              "      <td>117.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2015-02-09</td>\n",
              "      <td>84.60</td>\n",
              "      <td>85.6100</td>\n",
              "      <td>84.5800</td>\n",
              "      <td>85.12</td>\n",
              "      <td>4235744.0</td>\n",
              "      <td>vnq</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.114438</td>\n",
              "      <td>88.634686</td>\n",
              "      <td>83.915314</td>\n",
              "      <td>32.424654</td>\n",
              "      <td>-131.901918</td>\n",
              "      <td>36.055167</td>\n",
              "      <td>86.275000</td>\n",
              "      <td>86.275000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>2015-02-09</td>\n",
              "      <td>124.10</td>\n",
              "      <td>124.6300</td>\n",
              "      <td>123.8500</td>\n",
              "      <td>124.41</td>\n",
              "      <td>326692.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.071287</td>\n",
              "      <td>126.057904</td>\n",
              "      <td>122.042096</td>\n",
              "      <td>66.058549</td>\n",
              "      <td>29.784830</td>\n",
              "      <td>71.770804</td>\n",
              "      <td>124.050000</td>\n",
              "      <td>124.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2015-02-09</td>\n",
              "      <td>40.67</td>\n",
              "      <td>40.7858</td>\n",
              "      <td>40.5600</td>\n",
              "      <td>40.59</td>\n",
              "      <td>7247112.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.017465</td>\n",
              "      <td>41.683695</td>\n",
              "      <td>40.282972</td>\n",
              "      <td>48.885243</td>\n",
              "      <td>-66.120021</td>\n",
              "      <td>10.967552</td>\n",
              "      <td>40.983333</td>\n",
              "      <td>40.983333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>2015-02-10</td>\n",
              "      <td>110.92</td>\n",
              "      <td>111.0555</td>\n",
              "      <td>110.8200</td>\n",
              "      <td>110.96</td>\n",
              "      <td>1272543.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.076702</td>\n",
              "      <td>112.533048</td>\n",
              "      <td>110.506952</td>\n",
              "      <td>10.126480</td>\n",
              "      <td>-102.173378</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>111.520000</td>\n",
              "      <td>111.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2015-02-10</td>\n",
              "      <td>91.46</td>\n",
              "      <td>91.4600</td>\n",
              "      <td>91.4400</td>\n",
              "      <td>91.46</td>\n",
              "      <td>170448.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.000968</td>\n",
              "      <td>91.483094</td>\n",
              "      <td>91.436906</td>\n",
              "      <td>50.057372</td>\n",
              "      <td>-86.419753</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>91.460000</td>\n",
              "      <td>91.460000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          date   close      high       low    open       volume  tic  day  \\\n",
              "0   2015-02-02  112.20  112.2300  112.0000  112.06    2792120.0  agg    0   \n",
              "1   2015-02-02   91.46   91.4800   91.4600   91.48    3557487.0  bil    0   \n",
              "2   2015-02-02  122.42  123.1550  121.8200  121.84    8885189.0  gld    0   \n",
              "3   2015-02-02  201.92  202.0300  197.8600  200.05  163106969.0  spy    0   \n",
              "4   2015-02-02  115.12  115.2100  112.8500  114.38     549866.0   vb    0   \n",
              "5   2015-02-02   86.32   86.6900   84.6851   86.53    7523640.0  vnq    0   \n",
              "6   2015-02-02  122.30  122.3899  119.9400  121.66     823489.0   vo    0   \n",
              "7   2015-02-02   40.65   40.7600   40.2800   40.40   15944366.0  vwo    0   \n",
              "8   2015-02-03  111.77  112.1000  111.7600  112.10    1815375.0  agg    1   \n",
              "9   2015-02-03   91.48   91.4800   91.4600   91.46     266084.0  bil    1   \n",
              "10  2015-02-03  121.05  121.7600  120.5648  121.74    8255863.0  gld    1   \n",
              "11  2015-02-03  204.84  204.8500  202.5500  203.00  124212881.0  spy    1   \n",
              "12  2015-02-03  117.28  117.3300  115.5000  115.50     650585.0   vb    1   \n",
              "13  2015-02-03   87.07   87.1000   85.6600   86.33    4617437.0  vnq    1   \n",
              "14  2015-02-03  124.26  124.2900  122.7400  123.05     386410.0   vo    1   \n",
              "15  2015-02-03   41.37   41.4100   41.0000   41.03   20858075.0  vwo    1   \n",
              "16  2015-02-04  111.94  111.9500  111.5000  111.64    1953033.0  agg    2   \n",
              "17  2015-02-04   91.46   91.4800   91.4600   91.46     214178.0  bil    2   \n",
              "18  2015-02-04  121.58  122.2200  120.9200  121.63    5386747.0  gld    2   \n",
              "19  2015-02-04  204.06  205.3800  203.5100  203.92  134306728.0  spy    2   \n",
              "20  2015-02-04  116.77  117.4120  116.5600  116.85     447819.0   vb    2   \n",
              "21  2015-02-04   86.71   87.0900   86.2101   86.87    3332758.0  vnq    2   \n",
              "22  2015-02-04  123.71  124.3900  123.3900  123.67     434403.0   vo    2   \n",
              "23  2015-02-04   41.09   41.5000   41.0500   41.19    8677098.0  vwo    2   \n",
              "24  2015-02-05  111.71  111.8474  111.5700  111.79    2409552.0  agg    3   \n",
              "25  2015-02-05   91.46   91.4800   91.4600   91.46     414793.0  bil    3   \n",
              "26  2015-02-05  121.79  121.8300  120.6100  120.98    6879945.0  gld    3   \n",
              "27  2015-02-05  206.12  206.3000  204.7700  204.86   97953181.0  spy    3   \n",
              "28  2015-02-05  118.22  118.3946  117.0400  117.13     385979.0   vb    3   \n",
              "29  2015-02-05   87.75   87.7900   86.6700   86.92    2921645.0  vnq    3   \n",
              "30  2015-02-05  125.23  125.2600  124.0401  124.31     327650.0   vo    3   \n",
              "31  2015-02-05   41.40   41.4300   41.0200   41.07   11220549.0  vwo    3   \n",
              "32  2015-02-06  111.06  111.4100  111.0300  111.41    2531315.0  agg    4   \n",
              "33  2015-02-06   91.46   91.4800   91.4600   91.48     291738.0  bil    4   \n",
              "34  2015-02-06  118.64  119.5200  117.9500  119.15   13206906.0  gld    4   \n",
              "35  2015-02-06  205.55  207.2400  204.9200  206.56  125672026.0  spy    4   \n",
              "36  2015-02-06  117.90  118.6700  117.5054  118.40     718075.0   vb    4   \n",
              "37  2015-02-06   85.20   87.6600   84.8333   87.54    6323274.0  vnq    4   \n",
              "38  2015-02-06  124.70  125.6000  124.2800  125.52     395036.0   vo    4   \n",
              "39  2015-02-06   40.72   41.0100   40.5901   40.77   19723986.0  vwo    4   \n",
              "40  2015-02-09  111.04  111.3100  111.0400  111.31    1724911.0  agg    0   \n",
              "41  2015-02-09   91.44   91.4600   91.4400   91.46     147068.0  bil    0   \n",
              "42  2015-02-09  119.17  119.4000  118.7700  118.83    5237181.0  gld    0   \n",
              "43  2015-02-09  204.63  205.6400  204.1350  204.77   87219016.0  spy    0   \n",
              "44  2015-02-09  117.19  118.1500  117.0000  117.60     249545.0   vb    0   \n",
              "45  2015-02-09   84.60   85.6100   84.5800   85.12    4235744.0  vnq    0   \n",
              "46  2015-02-09  124.10  124.6300  123.8500  124.41     326692.0   vo    0   \n",
              "47  2015-02-09   40.67   40.7858   40.5600   40.59    7247112.0  vwo    0   \n",
              "48  2015-02-10  110.92  111.0555  110.8200  110.96    1272543.0  agg    1   \n",
              "49  2015-02-10   91.46   91.4600   91.4400   91.46     170448.0  bil    1   \n",
              "\n",
              "        macd     boll_ub     boll_lb      rsi_30      cci_30       dx_30  \\\n",
              "0   0.000000  112.593112  111.376888    0.000000  -66.666667  100.000000   \n",
              "1   0.000000  112.593112  111.376888    0.000000  -66.666667  100.000000   \n",
              "2   0.000000  112.593112  111.376888    0.000000  -66.666667  100.000000   \n",
              "3   0.000000  112.593112  111.376888    0.000000  -66.666667  100.000000   \n",
              "4   0.000000  112.593112  111.376888    0.000000  -66.666667  100.000000   \n",
              "5   0.000000  112.593112  111.376888    0.000000  -66.666667  100.000000   \n",
              "6   0.000000  112.593112  111.376888    0.000000  -66.666667  100.000000   \n",
              "7   0.000000  112.593112  111.376888    0.000000  -66.666667  100.000000   \n",
              "8  -0.009647  112.593112  111.376888    0.000000  -66.666667  100.000000   \n",
              "9   0.000449   91.498284   91.441716  100.000000   66.666667  100.000000   \n",
              "10 -0.030737  123.672473  119.797527    0.000000  -66.666667  100.000000   \n",
              "11  0.065513  207.509504  199.250496  100.000000   66.666667  100.000000   \n",
              "12  0.048462  119.254701  113.145299  100.000000   66.666667  100.000000   \n",
              "13  0.016827   87.755660   85.634340  100.000000   66.666667  100.000000   \n",
              "14  0.043974  126.051859  120.508141  100.000000   66.666667  100.000000   \n",
              "15  0.016154   42.028234   39.991766  100.000000   66.666667  100.000000   \n",
              "16 -0.007021  112.403128  111.536872   29.026750  -69.565217  100.000000   \n",
              "17 -0.000048   91.489761   91.443573   49.152542  -50.000000  100.000000   \n",
              "18 -0.022730  123.064975  120.301692   28.581701  -19.861991   43.704008   \n",
              "19  0.059289  206.630395  200.582938   78.349371   54.937413  100.000000   \n",
              "20  0.045935  118.648052  114.131948   80.369515   56.541540  100.000000   \n",
              "21  0.010277   87.450200   85.949800   66.820276   56.070923  100.000000   \n",
              "22  0.038977  125.445247  121.401420   77.502045   52.218902  100.000000   \n",
              "23  0.011900   41.762568   40.310765   71.311475   44.801980  100.000000   \n",
              "24 -0.013959  112.343938  111.466062   20.641146  -87.732027  100.000000   \n",
              "25 -0.000273   91.485000   91.445000   49.152542  -44.444444  100.000000   \n",
              "26 -0.010949  122.843137  120.576863   36.071177  -37.859949   53.194921   \n",
              "27  0.129380  207.758086  200.711914   86.396222   88.660352  100.000000   \n",
              "28  0.096011  119.445211  114.249789   87.554905   90.423739  100.000000   \n",
              "29  0.044595   88.178107   85.746893   83.339982  129.141640  100.000000   \n",
              "30  0.090627  126.322339  121.427661   86.308464   92.115705  100.000000   \n",
              "31  0.020867   41.822698   40.432302   78.406552   52.473118   91.215588   \n",
              "32 -0.043299  112.582002  110.889998   11.190113 -158.527209  100.000000   \n",
              "33 -0.000390   91.481889   91.446111   49.152542  -41.666667  100.000000   \n",
              "34 -0.129663  124.011977  118.180023   13.729590 -166.666667   81.618921   \n",
              "35  0.142062  207.767936  201.228064   78.088648   82.944289  100.000000   \n",
              "36  0.108467  119.496705  114.619295   80.802631   83.683983  100.000000   \n",
              "37 -0.039166   88.505627   84.714373   36.829281  -83.375151   29.930975   \n",
              "38  0.095696  126.284237  121.795763   75.630061   81.637535  100.000000   \n",
              "39 -0.001759   41.749790   40.342210   50.221907  -58.352443   14.307999   \n",
              "40 -0.060979  112.566319  110.673681   11.029369 -103.751108  100.000000   \n",
              "41 -0.001308   91.485298   91.434702   31.449374 -200.000000  100.000000   \n",
              "42 -0.175926  123.820541  117.729459   22.124972  -88.756787   81.618921   \n",
              "43  0.107675  207.446705  201.593295   67.285781   29.644269   68.991171   \n",
              "44  0.083556  119.263905  114.896095   68.650680   41.011885   69.496091   \n",
              "45 -0.114438   88.634686   83.915314   32.424654 -131.901918   36.055167   \n",
              "46  0.071287  126.057904  122.042096   66.058549   29.784830   71.770804   \n",
              "47 -0.017465   41.683695   40.282972   48.885243  -66.120021   10.967552   \n",
              "48 -0.076702  112.533048  110.506952   10.126480 -102.173378  100.000000   \n",
              "49 -0.000968   91.483094   91.436906   50.057372  -86.419753  100.000000   \n",
              "\n",
              "    close_30_sma  close_60_sma  \n",
              "0     112.200000    112.200000  \n",
              "1      91.460000     91.460000  \n",
              "2     122.420000    122.420000  \n",
              "3     201.920000    201.920000  \n",
              "4     115.120000    115.120000  \n",
              "5      86.320000     86.320000  \n",
              "6     122.300000    122.300000  \n",
              "7      40.650000     40.650000  \n",
              "8     111.985000    111.985000  \n",
              "9      91.470000     91.470000  \n",
              "10    121.735000    121.735000  \n",
              "11    203.380000    203.380000  \n",
              "12    116.200000    116.200000  \n",
              "13     86.695000     86.695000  \n",
              "14    123.280000    123.280000  \n",
              "15     41.010000     41.010000  \n",
              "16    111.970000    111.970000  \n",
              "17     91.466667     91.466667  \n",
              "18    121.683333    121.683333  \n",
              "19    203.606667    203.606667  \n",
              "20    116.390000    116.390000  \n",
              "21     86.700000     86.700000  \n",
              "22    123.423333    123.423333  \n",
              "23     41.036667     41.036667  \n",
              "24    111.905000    111.905000  \n",
              "25     91.465000     91.465000  \n",
              "26    121.710000    121.710000  \n",
              "27    204.235000    204.235000  \n",
              "28    116.847500    116.847500  \n",
              "29     86.962500     86.962500  \n",
              "30    123.875000    123.875000  \n",
              "31     41.127500     41.127500  \n",
              "32    111.736000    111.736000  \n",
              "33     91.464000     91.464000  \n",
              "34    121.096000    121.096000  \n",
              "35    204.498000    204.498000  \n",
              "36    117.058000    117.058000  \n",
              "37     86.610000     86.610000  \n",
              "38    124.040000    124.040000  \n",
              "39     41.046000     41.046000  \n",
              "40    111.620000    111.620000  \n",
              "41     91.460000     91.460000  \n",
              "42    120.775000    120.775000  \n",
              "43    204.520000    204.520000  \n",
              "44    117.080000    117.080000  \n",
              "45     86.275000     86.275000  \n",
              "46    124.050000    124.050000  \n",
              "47     40.983333     40.983333  \n",
              "48    111.520000    111.520000  \n",
              "49     91.460000     91.460000  "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Q8Og8SxHQpKA"
      },
      "outputs": [],
      "source": [
        "# Convert date column to datetime\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Remove rows where the date appears only once\n",
        "df = df[df.groupby('date')['date'].transform('count') > 1]\n",
        "\n",
        "# Sort by date\n",
        "df = df.sort_values('date').reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBYdJcvlbx27",
        "outputId": "0444da81-e841-47ff-fb5b-c32e9fbd5ba1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23085, 16)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iRmEQqecb3zo",
        "outputId": "7cdbd6e9-0168-4365-a4d8-08794475c9f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>112.20</td>\n",
              "      <td>112.2300</td>\n",
              "      <td>112.0000</td>\n",
              "      <td>112.06</td>\n",
              "      <td>2792120.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>112.200000</td>\n",
              "      <td>112.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>40.65</td>\n",
              "      <td>40.7600</td>\n",
              "      <td>40.2800</td>\n",
              "      <td>40.40</td>\n",
              "      <td>15944366.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>40.650000</td>\n",
              "      <td>40.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>122.30</td>\n",
              "      <td>122.3899</td>\n",
              "      <td>119.9400</td>\n",
              "      <td>121.66</td>\n",
              "      <td>823489.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>122.300000</td>\n",
              "      <td>122.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>86.32</td>\n",
              "      <td>86.6900</td>\n",
              "      <td>84.6851</td>\n",
              "      <td>86.53</td>\n",
              "      <td>7523640.0</td>\n",
              "      <td>vnq</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>86.320000</td>\n",
              "      <td>86.320000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>237.83</td>\n",
              "      <td>240.1000</td>\n",
              "      <td>220.8900</td>\n",
              "      <td>228.39</td>\n",
              "      <td>7421.0</td>\n",
              "      <td>btcusd</td>\n",
              "      <td>0</td>\n",
              "      <td>0.198333</td>\n",
              "      <td>245.911648</td>\n",
              "      <td>220.908352</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>233.410000</td>\n",
              "      <td>233.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>201.92</td>\n",
              "      <td>202.0300</td>\n",
              "      <td>197.8600</td>\n",
              "      <td>200.05</td>\n",
              "      <td>163106969.0</td>\n",
              "      <td>spy</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>201.920000</td>\n",
              "      <td>201.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>122.42</td>\n",
              "      <td>123.1550</td>\n",
              "      <td>121.8200</td>\n",
              "      <td>121.84</td>\n",
              "      <td>8885189.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>122.420000</td>\n",
              "      <td>122.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>91.46</td>\n",
              "      <td>91.4800</td>\n",
              "      <td>91.4600</td>\n",
              "      <td>91.48</td>\n",
              "      <td>3557487.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>91.460000</td>\n",
              "      <td>91.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>115.12</td>\n",
              "      <td>115.2100</td>\n",
              "      <td>112.8500</td>\n",
              "      <td>114.38</td>\n",
              "      <td>549866.0</td>\n",
              "      <td>vb</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>115.120000</td>\n",
              "      <td>115.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>111.77</td>\n",
              "      <td>112.1000</td>\n",
              "      <td>111.7600</td>\n",
              "      <td>112.10</td>\n",
              "      <td>1815375.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.009647</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>111.985000</td>\n",
              "      <td>111.985000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>91.48</td>\n",
              "      <td>91.4800</td>\n",
              "      <td>91.4600</td>\n",
              "      <td>91.46</td>\n",
              "      <td>266084.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>91.498284</td>\n",
              "      <td>91.441716</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>91.470000</td>\n",
              "      <td>91.470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>121.05</td>\n",
              "      <td>121.7600</td>\n",
              "      <td>120.5648</td>\n",
              "      <td>121.74</td>\n",
              "      <td>8255863.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.030737</td>\n",
              "      <td>123.672473</td>\n",
              "      <td>119.797527</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>121.735000</td>\n",
              "      <td>121.735000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>204.84</td>\n",
              "      <td>204.8500</td>\n",
              "      <td>202.5500</td>\n",
              "      <td>203.00</td>\n",
              "      <td>124212881.0</td>\n",
              "      <td>spy</td>\n",
              "      <td>1</td>\n",
              "      <td>0.065513</td>\n",
              "      <td>207.509504</td>\n",
              "      <td>199.250496</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>203.380000</td>\n",
              "      <td>203.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>117.28</td>\n",
              "      <td>117.3300</td>\n",
              "      <td>115.5000</td>\n",
              "      <td>115.50</td>\n",
              "      <td>650585.0</td>\n",
              "      <td>vb</td>\n",
              "      <td>1</td>\n",
              "      <td>0.048462</td>\n",
              "      <td>119.254701</td>\n",
              "      <td>113.145299</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>116.200000</td>\n",
              "      <td>116.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>87.07</td>\n",
              "      <td>87.1000</td>\n",
              "      <td>85.6600</td>\n",
              "      <td>86.33</td>\n",
              "      <td>4617437.0</td>\n",
              "      <td>vnq</td>\n",
              "      <td>1</td>\n",
              "      <td>0.016827</td>\n",
              "      <td>87.755660</td>\n",
              "      <td>85.634340</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>86.695000</td>\n",
              "      <td>86.695000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>124.26</td>\n",
              "      <td>124.2900</td>\n",
              "      <td>122.7400</td>\n",
              "      <td>123.05</td>\n",
              "      <td>386410.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>1</td>\n",
              "      <td>0.043974</td>\n",
              "      <td>126.051859</td>\n",
              "      <td>120.508141</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>123.280000</td>\n",
              "      <td>123.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>41.37</td>\n",
              "      <td>41.4100</td>\n",
              "      <td>41.0000</td>\n",
              "      <td>41.03</td>\n",
              "      <td>20858075.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>1</td>\n",
              "      <td>0.016154</td>\n",
              "      <td>42.028234</td>\n",
              "      <td>39.991766</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>41.010000</td>\n",
              "      <td>41.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2015-02-03</td>\n",
              "      <td>228.58</td>\n",
              "      <td>243.9000</td>\n",
              "      <td>225.3200</td>\n",
              "      <td>237.01</td>\n",
              "      <td>8303.0</td>\n",
              "      <td>btcusd</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.034126</td>\n",
              "      <td>242.252311</td>\n",
              "      <td>221.347689</td>\n",
              "      <td>48.020080</td>\n",
              "      <td>47.003525</td>\n",
              "      <td>100.0</td>\n",
              "      <td>231.800000</td>\n",
              "      <td>231.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2015-02-04</td>\n",
              "      <td>41.09</td>\n",
              "      <td>41.5000</td>\n",
              "      <td>41.0500</td>\n",
              "      <td>41.19</td>\n",
              "      <td>8677098.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>2</td>\n",
              "      <td>0.011900</td>\n",
              "      <td>41.762568</td>\n",
              "      <td>40.310765</td>\n",
              "      <td>71.311475</td>\n",
              "      <td>44.801980</td>\n",
              "      <td>100.0</td>\n",
              "      <td>41.036667</td>\n",
              "      <td>41.036667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2015-02-04</td>\n",
              "      <td>123.71</td>\n",
              "      <td>124.3900</td>\n",
              "      <td>123.3900</td>\n",
              "      <td>123.67</td>\n",
              "      <td>434403.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>2</td>\n",
              "      <td>0.038977</td>\n",
              "      <td>125.445247</td>\n",
              "      <td>121.401420</td>\n",
              "      <td>77.502045</td>\n",
              "      <td>52.218902</td>\n",
              "      <td>100.0</td>\n",
              "      <td>123.423333</td>\n",
              "      <td>123.423333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   close      high       low    open       volume     tic  day  \\\n",
              "0  2015-02-02  112.20  112.2300  112.0000  112.06    2792120.0     agg    0   \n",
              "1  2015-02-02   40.65   40.7600   40.2800   40.40   15944366.0     vwo    0   \n",
              "2  2015-02-02  122.30  122.3899  119.9400  121.66     823489.0      vo    0   \n",
              "3  2015-02-02   86.32   86.6900   84.6851   86.53    7523640.0     vnq    0   \n",
              "4  2015-02-02  237.83  240.1000  220.8900  228.39       7421.0  btcusd    0   \n",
              "5  2015-02-02  201.92  202.0300  197.8600  200.05  163106969.0     spy    0   \n",
              "6  2015-02-02  122.42  123.1550  121.8200  121.84    8885189.0     gld    0   \n",
              "7  2015-02-02   91.46   91.4800   91.4600   91.48    3557487.0     bil    0   \n",
              "8  2015-02-02  115.12  115.2100  112.8500  114.38     549866.0      vb    0   \n",
              "9  2015-02-03  111.77  112.1000  111.7600  112.10    1815375.0     agg    1   \n",
              "10 2015-02-03   91.48   91.4800   91.4600   91.46     266084.0     bil    1   \n",
              "11 2015-02-03  121.05  121.7600  120.5648  121.74    8255863.0     gld    1   \n",
              "12 2015-02-03  204.84  204.8500  202.5500  203.00  124212881.0     spy    1   \n",
              "13 2015-02-03  117.28  117.3300  115.5000  115.50     650585.0      vb    1   \n",
              "14 2015-02-03   87.07   87.1000   85.6600   86.33    4617437.0     vnq    1   \n",
              "15 2015-02-03  124.26  124.2900  122.7400  123.05     386410.0      vo    1   \n",
              "16 2015-02-03   41.37   41.4100   41.0000   41.03   20858075.0     vwo    1   \n",
              "17 2015-02-03  228.58  243.9000  225.3200  237.01       8303.0  btcusd    1   \n",
              "18 2015-02-04   41.09   41.5000   41.0500   41.19    8677098.0     vwo    2   \n",
              "19 2015-02-04  123.71  124.3900  123.3900  123.67     434403.0      vo    2   \n",
              "\n",
              "        macd     boll_ub     boll_lb      rsi_30     cci_30  dx_30  \\\n",
              "0   0.000000  112.593112  111.376888    0.000000 -66.666667  100.0   \n",
              "1   0.000000  112.593112  111.376888    0.000000 -66.666667  100.0   \n",
              "2   0.000000  112.593112  111.376888    0.000000 -66.666667  100.0   \n",
              "3   0.000000  112.593112  111.376888    0.000000 -66.666667  100.0   \n",
              "4   0.198333  245.911648  220.908352  100.000000  66.666667  100.0   \n",
              "5   0.000000  112.593112  111.376888    0.000000 -66.666667  100.0   \n",
              "6   0.000000  112.593112  111.376888    0.000000 -66.666667  100.0   \n",
              "7   0.000000  112.593112  111.376888    0.000000 -66.666667  100.0   \n",
              "8   0.000000  112.593112  111.376888    0.000000 -66.666667  100.0   \n",
              "9  -0.009647  112.593112  111.376888    0.000000 -66.666667  100.0   \n",
              "10  0.000449   91.498284   91.441716  100.000000  66.666667  100.0   \n",
              "11 -0.030737  123.672473  119.797527    0.000000 -66.666667  100.0   \n",
              "12  0.065513  207.509504  199.250496  100.000000  66.666667  100.0   \n",
              "13  0.048462  119.254701  113.145299  100.000000  66.666667  100.0   \n",
              "14  0.016827   87.755660   85.634340  100.000000  66.666667  100.0   \n",
              "15  0.043974  126.051859  120.508141  100.000000  66.666667  100.0   \n",
              "16  0.016154   42.028234   39.991766  100.000000  66.666667  100.0   \n",
              "17 -0.034126  242.252311  221.347689   48.020080  47.003525  100.0   \n",
              "18  0.011900   41.762568   40.310765   71.311475  44.801980  100.0   \n",
              "19  0.038977  125.445247  121.401420   77.502045  52.218902  100.0   \n",
              "\n",
              "    close_30_sma  close_60_sma  \n",
              "0     112.200000    112.200000  \n",
              "1      40.650000     40.650000  \n",
              "2     122.300000    122.300000  \n",
              "3      86.320000     86.320000  \n",
              "4     233.410000    233.410000  \n",
              "5     201.920000    201.920000  \n",
              "6     122.420000    122.420000  \n",
              "7      91.460000     91.460000  \n",
              "8     115.120000    115.120000  \n",
              "9     111.985000    111.985000  \n",
              "10     91.470000     91.470000  \n",
              "11    121.735000    121.735000  \n",
              "12    203.380000    203.380000  \n",
              "13    116.200000    116.200000  \n",
              "14     86.695000     86.695000  \n",
              "15    123.280000    123.280000  \n",
              "16     41.010000     41.010000  \n",
              "17    231.800000    231.800000  \n",
              "18     41.036667     41.036667  \n",
              "19    123.423333    123.423333  "
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz9K2vul6RmK"
      },
      "source": [
        "## Add covariance matrix as states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "xrz3zcXyTYGV",
        "outputId": "5964ee80-cd02-44b6-a16f-a506e369f8ee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>112.20</td>\n",
              "      <td>112.2300</td>\n",
              "      <td>112.0000</td>\n",
              "      <td>112.06</td>\n",
              "      <td>2792120.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>112.20</td>\n",
              "      <td>112.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>40.65</td>\n",
              "      <td>40.7600</td>\n",
              "      <td>40.2800</td>\n",
              "      <td>40.40</td>\n",
              "      <td>15944366.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>40.65</td>\n",
              "      <td>40.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>122.30</td>\n",
              "      <td>122.3899</td>\n",
              "      <td>119.9400</td>\n",
              "      <td>121.66</td>\n",
              "      <td>823489.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>122.30</td>\n",
              "      <td>122.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>86.32</td>\n",
              "      <td>86.6900</td>\n",
              "      <td>84.6851</td>\n",
              "      <td>86.53</td>\n",
              "      <td>7523640.0</td>\n",
              "      <td>vnq</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112.593112</td>\n",
              "      <td>111.376888</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>86.32</td>\n",
              "      <td>86.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>237.83</td>\n",
              "      <td>240.1000</td>\n",
              "      <td>220.8900</td>\n",
              "      <td>228.39</td>\n",
              "      <td>7421.0</td>\n",
              "      <td>btcusd</td>\n",
              "      <td>0</td>\n",
              "      <td>0.198333</td>\n",
              "      <td>245.911648</td>\n",
              "      <td>220.908352</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>233.41</td>\n",
              "      <td>233.41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date   close      high       low    open      volume     tic  day  \\\n",
              "0 2015-02-02  112.20  112.2300  112.0000  112.06   2792120.0     agg    0   \n",
              "1 2015-02-02   40.65   40.7600   40.2800   40.40  15944366.0     vwo    0   \n",
              "2 2015-02-02  122.30  122.3899  119.9400  121.66    823489.0      vo    0   \n",
              "3 2015-02-02   86.32   86.6900   84.6851   86.53   7523640.0     vnq    0   \n",
              "4 2015-02-02  237.83  240.1000  220.8900  228.39      7421.0  btcusd    0   \n",
              "\n",
              "       macd     boll_ub     boll_lb  rsi_30     cci_30  dx_30  close_30_sma  \\\n",
              "0  0.000000  112.593112  111.376888     0.0 -66.666667  100.0        112.20   \n",
              "1  0.000000  112.593112  111.376888     0.0 -66.666667  100.0         40.65   \n",
              "2  0.000000  112.593112  111.376888     0.0 -66.666667  100.0        122.30   \n",
              "3  0.000000  112.593112  111.376888     0.0 -66.666667  100.0         86.32   \n",
              "4  0.198333  245.911648  220.908352   100.0  66.666667  100.0        233.41   \n",
              "\n",
              "   close_60_sma  \n",
              "0        112.20  \n",
              "1         40.65  \n",
              "2        122.30  \n",
              "3         86.32  \n",
              "4        233.41  "
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "IhizvNwcrg1n",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "# add covariance matrix as states\n",
        "df=df.sort_values(['date','tic'],ignore_index=True)\n",
        "df.index = df.date.factorize()[0]\n",
        "\n",
        "cov_list = []\n",
        "return_list = []\n",
        "\n",
        "# look back is one year\n",
        "lookback=252\n",
        "for i in range(lookback,len(df.index.unique())):\n",
        "  data_lookback = df.loc[i-lookback:i,:]\n",
        "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
        "  return_lookback = price_lookback.pct_change().dropna()\n",
        "  return_list.append(return_lookback)\n",
        "\n",
        "  covs = return_lookback.cov().values\n",
        "  cov_list.append(covs)\n",
        "\n",
        "\n",
        "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
        "df = df.merge(df_cov, on='date')\n",
        "df = df.sort_values(['date','tic']).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUPwwa13uBQ-",
        "outputId": "9e240357-354b-4af2-a925-fc769656b929",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20817, 18)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "wv3jR1zPrg4g",
        "outputId": "0ce6adfe-64bd-4897-825d-9c908a882bb2",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>cov_list</th>\n",
              "      <th>return_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>109.32</td>\n",
              "      <td>109.380</td>\n",
              "      <td>109.1301</td>\n",
              "      <td>109.23</td>\n",
              "      <td>4835115.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>1</td>\n",
              "      <td>0.207871</td>\n",
              "      <td>109.414436</td>\n",
              "      <td>108.155564</td>\n",
              "      <td>56.401620</td>\n",
              "      <td>128.048919</td>\n",
              "      <td>18.311124</td>\n",
              "      <td>108.540000</td>\n",
              "      <td>108.509083</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>91.34</td>\n",
              "      <td>91.360</td>\n",
              "      <td>91.3400</td>\n",
              "      <td>91.34</td>\n",
              "      <td>1627284.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.003626</td>\n",
              "      <td>91.386806</td>\n",
              "      <td>91.327194</td>\n",
              "      <td>46.986934</td>\n",
              "      <td>-124.094203</td>\n",
              "      <td>12.399460</td>\n",
              "      <td>91.360333</td>\n",
              "      <td>91.364333</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>372.93</td>\n",
              "      <td>374.410</td>\n",
              "      <td>371.1700</td>\n",
              "      <td>371.33</td>\n",
              "      <td>6817.0</td>\n",
              "      <td>btcusd</td>\n",
              "      <td>1</td>\n",
              "      <td>-12.397434</td>\n",
              "      <td>422.125588</td>\n",
              "      <td>352.168412</td>\n",
              "      <td>45.804685</td>\n",
              "      <td>-84.272928</td>\n",
              "      <td>40.704445</td>\n",
              "      <td>405.695000</td>\n",
              "      <td>419.803333</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>108.09</td>\n",
              "      <td>108.180</td>\n",
              "      <td>107.3500</td>\n",
              "      <td>107.92</td>\n",
              "      <td>6656018.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>1</td>\n",
              "      <td>1.135824</td>\n",
              "      <td>108.620100</td>\n",
              "      <td>102.477820</td>\n",
              "      <td>56.790972</td>\n",
              "      <td>143.671556</td>\n",
              "      <td>35.269843</td>\n",
              "      <td>104.479307</td>\n",
              "      <td>103.650320</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>190.16</td>\n",
              "      <td>191.970</td>\n",
              "      <td>189.5400</td>\n",
              "      <td>191.96</td>\n",
              "      <td>182564890.0</td>\n",
              "      <td>spy</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.744645</td>\n",
              "      <td>199.106331</td>\n",
              "      <td>183.296129</td>\n",
              "      <td>43.397377</td>\n",
              "      <td>-51.889822</td>\n",
              "      <td>20.952982</td>\n",
              "      <td>195.478153</td>\n",
              "      <td>201.393583</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>99.93</td>\n",
              "      <td>101.300</td>\n",
              "      <td>99.5600</td>\n",
              "      <td>101.23</td>\n",
              "      <td>806243.0</td>\n",
              "      <td>vb</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.286971</td>\n",
              "      <td>107.259181</td>\n",
              "      <td>95.234819</td>\n",
              "      <td>39.656457</td>\n",
              "      <td>-58.511357</td>\n",
              "      <td>32.436105</td>\n",
              "      <td>104.496667</td>\n",
              "      <td>109.190167</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>76.42</td>\n",
              "      <td>77.000</td>\n",
              "      <td>75.9900</td>\n",
              "      <td>76.75</td>\n",
              "      <td>6405965.0</td>\n",
              "      <td>vnq</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.590040</td>\n",
              "      <td>80.000387</td>\n",
              "      <td>73.562613</td>\n",
              "      <td>46.993766</td>\n",
              "      <td>-52.042083</td>\n",
              "      <td>19.794014</td>\n",
              "      <td>77.738333</td>\n",
              "      <td>78.155167</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>108.76</td>\n",
              "      <td>110.390</td>\n",
              "      <td>108.3705</td>\n",
              "      <td>110.39</td>\n",
              "      <td>1044394.0</td>\n",
              "      <td>vo</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.324530</td>\n",
              "      <td>116.708953</td>\n",
              "      <td>104.273047</td>\n",
              "      <td>39.842589</td>\n",
              "      <td>-62.826827</td>\n",
              "      <td>28.141177</td>\n",
              "      <td>113.705333</td>\n",
              "      <td>118.021333</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>29.61</td>\n",
              "      <td>30.074</td>\n",
              "      <td>29.5250</td>\n",
              "      <td>30.01</td>\n",
              "      <td>29716675.0</td>\n",
              "      <td>vwo</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.602581</td>\n",
              "      <td>31.511900</td>\n",
              "      <td>28.106100</td>\n",
              "      <td>40.930317</td>\n",
              "      <td>-50.822375</td>\n",
              "      <td>20.542572</td>\n",
              "      <td>30.827333</td>\n",
              "      <td>32.391667</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2016-02-03</td>\n",
              "      <td>109.31</td>\n",
              "      <td>109.640</td>\n",
              "      <td>109.2000</td>\n",
              "      <td>109.26</td>\n",
              "      <td>3700282.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>2</td>\n",
              "      <td>0.219987</td>\n",
              "      <td>109.409405</td>\n",
              "      <td>108.289595</td>\n",
              "      <td>56.284904</td>\n",
              "      <td>134.384090</td>\n",
              "      <td>26.433157</td>\n",
              "      <td>108.571000</td>\n",
              "      <td>108.518083</td>\n",
              "      <td>[[5.6805382532148396e-06, 1.0046908129070857e-...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date   close     high       low    open       volume     tic  day  \\\n",
              "0 2016-02-02  109.32  109.380  109.1301  109.23    4835115.0     agg    1   \n",
              "1 2016-02-02   91.34   91.360   91.3400   91.34    1627284.0     bil    1   \n",
              "2 2016-02-02  372.93  374.410  371.1700  371.33       6817.0  btcusd    1   \n",
              "3 2016-02-02  108.09  108.180  107.3500  107.92    6656018.0     gld    1   \n",
              "4 2016-02-02  190.16  191.970  189.5400  191.96  182564890.0     spy    1   \n",
              "5 2016-02-02   99.93  101.300   99.5600  101.23     806243.0      vb    1   \n",
              "6 2016-02-02   76.42   77.000   75.9900   76.75    6405965.0     vnq    1   \n",
              "7 2016-02-02  108.76  110.390  108.3705  110.39    1044394.0      vo    1   \n",
              "8 2016-02-02   29.61   30.074   29.5250   30.01   29716675.0     vwo    1   \n",
              "9 2016-02-03  109.31  109.640  109.2000  109.26    3700282.0     agg    2   \n",
              "\n",
              "        macd     boll_ub     boll_lb     rsi_30      cci_30      dx_30  \\\n",
              "0   0.207871  109.414436  108.155564  56.401620  128.048919  18.311124   \n",
              "1  -0.003626   91.386806   91.327194  46.986934 -124.094203  12.399460   \n",
              "2 -12.397434  422.125588  352.168412  45.804685  -84.272928  40.704445   \n",
              "3   1.135824  108.620100  102.477820  56.790972  143.671556  35.269843   \n",
              "4  -2.744645  199.106331  183.296129  43.397377  -51.889822  20.952982   \n",
              "5  -2.286971  107.259181   95.234819  39.656457  -58.511357  32.436105   \n",
              "6  -0.590040   80.000387   73.562613  46.993766  -52.042083  19.794014   \n",
              "7  -2.324530  116.708953  104.273047  39.842589  -62.826827  28.141177   \n",
              "8  -0.602581   31.511900   28.106100  40.930317  -50.822375  20.542572   \n",
              "9   0.219987  109.409405  108.289595  56.284904  134.384090  26.433157   \n",
              "\n",
              "   close_30_sma  close_60_sma  \\\n",
              "0    108.540000    108.509083   \n",
              "1     91.360333     91.364333   \n",
              "2    405.695000    419.803333   \n",
              "3    104.479307    103.650320   \n",
              "4    195.478153    201.393583   \n",
              "5    104.496667    109.190167   \n",
              "6     77.738333     78.155167   \n",
              "7    113.705333    118.021333   \n",
              "8     30.827333     32.391667   \n",
              "9    108.571000    108.518083   \n",
              "\n",
              "                                            cov_list  \\\n",
              "0  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "1  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "2  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "3  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "4  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "5  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "6  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "7  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "8  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "9  [[5.6805382532148396e-06, 1.0046908129070857e-...   \n",
              "\n",
              "                                         return_list  \n",
              "0  tic              agg       bil    btcusd      ...  \n",
              "1  tic              agg       bil    btcusd      ...  \n",
              "2  tic              agg       bil    btcusd      ...  \n",
              "3  tic              agg       bil    btcusd      ...  \n",
              "4  tic              agg       bil    btcusd      ...  \n",
              "5  tic              agg       bil    btcusd      ...  \n",
              "6  tic              agg       bil    btcusd      ...  \n",
              "7  tic              agg       bil    btcusd      ...  \n",
              "8  tic              agg       bil    btcusd      ...  \n",
              "9  tic              agg       bil    btcusd      ...  "
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UooHj1OgbU4v"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQnmN1qdk88I"
      },
      "source": [
        "## Training data split: 2009-01-01 to 2020-07-01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "NrPxgv4eBQ_R",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "train = data_split(df, TRAIN_START_DATE, TRAIN_END_DATE)\n",
        "# trade = data_split(df, TRADE_START_DATE, TRADE_END_DATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "vU2vXEll0hfk",
        "outputId": "a36eef56-27f9-49c3-cb75-52f5e4fb4a16",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>cov_list</th>\n",
              "      <th>return_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>109.32</td>\n",
              "      <td>109.38</td>\n",
              "      <td>109.1301</td>\n",
              "      <td>109.23</td>\n",
              "      <td>4835115.0</td>\n",
              "      <td>agg</td>\n",
              "      <td>1</td>\n",
              "      <td>0.207871</td>\n",
              "      <td>109.414436</td>\n",
              "      <td>108.155564</td>\n",
              "      <td>56.401620</td>\n",
              "      <td>128.048919</td>\n",
              "      <td>18.311124</td>\n",
              "      <td>108.540000</td>\n",
              "      <td>108.509083</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>91.34</td>\n",
              "      <td>91.36</td>\n",
              "      <td>91.3400</td>\n",
              "      <td>91.34</td>\n",
              "      <td>1627284.0</td>\n",
              "      <td>bil</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.003626</td>\n",
              "      <td>91.386806</td>\n",
              "      <td>91.327194</td>\n",
              "      <td>46.986934</td>\n",
              "      <td>-124.094203</td>\n",
              "      <td>12.399460</td>\n",
              "      <td>91.360333</td>\n",
              "      <td>91.364333</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>372.93</td>\n",
              "      <td>374.41</td>\n",
              "      <td>371.1700</td>\n",
              "      <td>371.33</td>\n",
              "      <td>6817.0</td>\n",
              "      <td>btcusd</td>\n",
              "      <td>1</td>\n",
              "      <td>-12.397434</td>\n",
              "      <td>422.125588</td>\n",
              "      <td>352.168412</td>\n",
              "      <td>45.804685</td>\n",
              "      <td>-84.272928</td>\n",
              "      <td>40.704445</td>\n",
              "      <td>405.695000</td>\n",
              "      <td>419.803333</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>108.09</td>\n",
              "      <td>108.18</td>\n",
              "      <td>107.3500</td>\n",
              "      <td>107.92</td>\n",
              "      <td>6656018.0</td>\n",
              "      <td>gld</td>\n",
              "      <td>1</td>\n",
              "      <td>1.135824</td>\n",
              "      <td>108.620100</td>\n",
              "      <td>102.477820</td>\n",
              "      <td>56.790972</td>\n",
              "      <td>143.671556</td>\n",
              "      <td>35.269843</td>\n",
              "      <td>104.479307</td>\n",
              "      <td>103.650320</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>190.16</td>\n",
              "      <td>191.97</td>\n",
              "      <td>189.5400</td>\n",
              "      <td>191.96</td>\n",
              "      <td>182564890.0</td>\n",
              "      <td>spy</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.744645</td>\n",
              "      <td>199.106331</td>\n",
              "      <td>183.296129</td>\n",
              "      <td>43.397377</td>\n",
              "      <td>-51.889822</td>\n",
              "      <td>20.952982</td>\n",
              "      <td>195.478153</td>\n",
              "      <td>201.393583</td>\n",
              "      <td>[[5.736252007431309e-06, 6.710303377777988e-09...</td>\n",
              "      <td>tic              agg       bil    btcusd      ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date   close    high       low    open       volume     tic  day  \\\n",
              "0 2016-02-02  109.32  109.38  109.1301  109.23    4835115.0     agg    1   \n",
              "0 2016-02-02   91.34   91.36   91.3400   91.34    1627284.0     bil    1   \n",
              "0 2016-02-02  372.93  374.41  371.1700  371.33       6817.0  btcusd    1   \n",
              "0 2016-02-02  108.09  108.18  107.3500  107.92    6656018.0     gld    1   \n",
              "0 2016-02-02  190.16  191.97  189.5400  191.96  182564890.0     spy    1   \n",
              "\n",
              "        macd     boll_ub     boll_lb     rsi_30      cci_30      dx_30  \\\n",
              "0   0.207871  109.414436  108.155564  56.401620  128.048919  18.311124   \n",
              "0  -0.003626   91.386806   91.327194  46.986934 -124.094203  12.399460   \n",
              "0 -12.397434  422.125588  352.168412  45.804685  -84.272928  40.704445   \n",
              "0   1.135824  108.620100  102.477820  56.790972  143.671556  35.269843   \n",
              "0  -2.744645  199.106331  183.296129  43.397377  -51.889822  20.952982   \n",
              "\n",
              "   close_30_sma  close_60_sma  \\\n",
              "0    108.540000    108.509083   \n",
              "0     91.360333     91.364333   \n",
              "0    405.695000    419.803333   \n",
              "0    104.479307    103.650320   \n",
              "0    195.478153    201.393583   \n",
              "\n",
              "                                            cov_list  \\\n",
              "0  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "0  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "0  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "0  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "0  [[5.736252007431309e-06, 6.710303377777988e-09...   \n",
              "\n",
              "                                         return_list  \n",
              "0  tic              agg       bil    btcusd      ...  \n",
              "0  tic              agg       bil    btcusd      ...  \n",
              "0  tic              agg       bil    btcusd      ...  \n",
              "0  tic              agg       bil    btcusd      ...  \n",
              "0  tic              agg       bil    btcusd      ...  "
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxQTNjpblAMN"
      },
      "source": [
        "## Environment for Portfolio Allocation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "xlfE-VERbU40",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "\n",
        "class StockPortfolioEnv(gym.Env):\n",
        "    \"\"\"A single stock trading environment for OpenAI gym\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        df: DataFrame\n",
        "            input data\n",
        "        stock_dim : int\n",
        "            number of unique stocks\n",
        "        hmax : int\n",
        "            maximum number of shares to trade\n",
        "        initial_amount : int\n",
        "            start money\n",
        "        transaction_cost_pct: float\n",
        "            transaction cost percentage per trade\n",
        "        reward_scaling: float\n",
        "            scaling factor for reward, good for training\n",
        "        state_space: int\n",
        "            the dimension of input features\n",
        "        action_space: int\n",
        "            equals stock dimension\n",
        "        tech_indicator_list: list\n",
        "            a list of technical indicator names\n",
        "        turbulence_threshold: int\n",
        "            a threshold to control risk aversion\n",
        "        day: int\n",
        "            an increment number to control date\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    _sell_stock()\n",
        "        perform sell action based on the sign of the action\n",
        "    _buy_stock()\n",
        "        perform buy action based on the sign of the action\n",
        "    step()\n",
        "        at each step the agent will return actions, then\n",
        "        we will calculate the reward, and return the next observation.\n",
        "    reset()\n",
        "        reset the environment\n",
        "    render()\n",
        "        use render to return other functions\n",
        "    save_asset_memory()\n",
        "        return account value at each time step\n",
        "    save_action_memory()\n",
        "        return actions/positions at each time step\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self,\n",
        "                df,\n",
        "                stock_dim,\n",
        "                hmax,\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                reward_scaling,\n",
        "                state_space,\n",
        "                action_space,\n",
        "                tech_indicator_list,\n",
        "                turbulence_threshold=None,\n",
        "                lookback=252,\n",
        "                day = 0):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.lookback=lookback\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct =transaction_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "\n",
        "        # action_space normalization and shape is self.stock_dim\n",
        "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,))\n",
        "        # Shape = (34, 30)\n",
        "        # covariance matrix + technical indicators\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
        "\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.terminal = False\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
        "        self.portfolio_value = self.initial_amount\n",
        "\n",
        "        # memorize portfolio value each step\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        # memorize portfolio return each step\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "\n",
        "\n",
        "    def step(self, actions):\n",
        "        # print(self.day)\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            df = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df.columns = ['daily_return']\n",
        "            plt.plot(df.daily_return.cumsum(),'r')\n",
        "            plt.savefig('results/cumulative_reward.png')\n",
        "            plt.close()\n",
        "\n",
        "            plt.plot(self.portfolio_return_memory,'r')\n",
        "            plt.savefig('results/rewards.png')\n",
        "            plt.close()\n",
        "\n",
        "            print(\"=================================\")\n",
        "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
        "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
        "\n",
        "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df_daily_return.columns = ['daily_return']\n",
        "            if df_daily_return['daily_return'].std() !=0:\n",
        "              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
        "                       df_daily_return['daily_return'].std()\n",
        "              print(\"Sharpe: \",sharpe)\n",
        "            print(\"=================================\")\n",
        "\n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            #print(\"Model actions: \",actions)\n",
        "            # actions are the portfolio weight\n",
        "            # normalize to sum of 1\n",
        "            #if (np.array(actions) - np.array(actions).min()).sum() != 0:\n",
        "            #  norm_actions = (np.array(actions) - np.array(actions).min()) / (np.array(actions) - np.array(actions).min()).sum()\n",
        "            #else:\n",
        "            #  norm_actions = actions\n",
        "            weights = self.softmax_normalization(actions)\n",
        "            #print(\"Normalized actions: \", weights)\n",
        "            self.actions_memory.append(weights)\n",
        "            last_day_memory = self.data\n",
        "\n",
        "            #load next state\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.covs = self.data['cov_list'].values[0]\n",
        "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "            #print(self.state)\n",
        "            # calcualte portfolio return\n",
        "            # individual stocks' return * weight\n",
        "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            # update portfolio value\n",
        "            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
        "            self.portfolio_value = new_portfolio_value\n",
        "\n",
        "            # save into memory\n",
        "            self.portfolio_return_memory.append(portfolio_return)\n",
        "            self.date_memory.append(self.data.date.unique()[0])\n",
        "            self.asset_memory.append(new_portfolio_value)\n",
        "\n",
        "            # the reward is the new portfolio value or end portfolo value\n",
        "            self.reward = new_portfolio_value\n",
        "            #print(\"Step reward: \", self.reward)\n",
        "            #self.reward = self.reward*self.reward_scaling\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        # load states\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        #self.cost = 0\n",
        "        #self.trades = 0\n",
        "        self.terminal = False\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "\n",
        "    def softmax_normalization(self, actions):\n",
        "        numerator = np.exp(actions)\n",
        "        denominator = np.sum(np.exp(actions))\n",
        "        softmax_output = numerator/denominator\n",
        "        return softmax_output\n",
        "\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        portfolio_return = self.portfolio_return_memory\n",
        "        #print(len(date_list))\n",
        "        #print(len(asset_list))\n",
        "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        # date and close price length must match actions length\n",
        "        date_list = self.date_memory\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = ['date']\n",
        "\n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzD06X0CbU43",
        "outputId": "b486b75a-a6f5-44d8-a75b-dcda1c64d95b",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 9, State Space: 9\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "jyg0_ZuVEVQ5",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"transaction_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": config.INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "\n",
        "}\n",
        "\n",
        "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTlOf8SJGdkl",
        "outputId": "2a2fdabd-9751-420a-dd13-dd05a1ca3fd6",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eKIu5UPlPnk"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "VDxU0iCEGdnb",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "# initialize\n",
        "agent = DRLAgent(env = env_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdPe8uzflbXe"
      },
      "source": [
        "### Model 1: **A2C**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1tORf1fIcQ2",
        "outputId": "d7857242-9e6b-4afc-8ab3-0e55b094cc93",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DazEdrMpIdyz",
        "outputId": "c3f99924-ae82-47a9-abcf-10c5bc0ca3c2",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1099      |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 0         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 7.91e+07  |\n",
            "|    reward             | 2047358.5 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 4.36e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1112      |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 0         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 7.92e+07  |\n",
            "|    reward             | 2262884.5 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 5.41e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1118      |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 1         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 1.37e+08  |\n",
            "|    reward             | 3275779.8 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 1.16e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2934277.637573717\n",
            "Sharpe:  1.0169376666191843\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 989       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 2         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 4.99e+07  |\n",
            "|    reward             | 1260256.0 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 1.68e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1007      |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 2         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 7.33e+07  |\n",
            "|    reward             | 1872491.6 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 3.6e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1022      |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 2         |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 9.3e+07   |\n",
            "|    reward             | 2465568.0 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 6.84e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1032      |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 1.04e+08  |\n",
            "|    reward             | 2874819.2 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 8.41e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3203663.708609701\n",
            "Sharpe:  1.1180505295227754\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1009      |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 6.31e+07  |\n",
            "|    reward             | 1590013.5 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 2.6e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1018      |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 8.15e+07  |\n",
            "|    reward             | 2138316.5 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 4.86e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1027      |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 1.25e+08  |\n",
            "|    reward             | 3293367.8 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 1.13e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2938992.7879951885\n",
            "Sharpe:  1.0267183910778563\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1009      |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 4.59e+07  |\n",
            "|    reward             | 1144020.4 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 1.32e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1015      |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 6.94e+07  |\n",
            "|    reward             | 1625917.0 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 2.8e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1021      |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 6.54e+07  |\n",
            "|    reward             | 1737394.8 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 3.08e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1026      |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 7.89e+07  |\n",
            "|    reward             | 2329077.0 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 5.68e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2367183.3407949377\n",
            "Sharpe:  0.8061493457826542\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1015      |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 4.81e+07  |\n",
            "|    reward             | 1313016.1 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 1.88e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1020      |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 6.3e+07   |\n",
            "|    reward             | 1650739.6 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 2.83e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1023      |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 1.07e+08  |\n",
            "|    reward             | 2745384.0 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 7.73e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1027      |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 8.75e+07  |\n",
            "|    reward             | 2560148.5 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 7.1e+13   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2589501.45249095\n",
            "Sharpe:  0.9370068075654071\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1013      |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 8.24e+07  |\n",
            "|    reward             | 1823198.1 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 3.62e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1017      |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 6.38e+07  |\n",
            "|    reward             | 1842932.8 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 3.55e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1021      |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 1.03e+08  |\n",
            "|    reward             | 2680305.8 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 7.79e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2331476.336239754\n",
            "Sharpe:  0.8366117562201332\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1015      |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | 4.25e+07  |\n",
            "|    reward             | 1184611.0 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 1.52e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1019      |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 6.32e+07  |\n",
            "|    reward             | 1761674.9 |\n",
            "|    std                | 0.98      |\n",
            "|    value_loss         | 3.41e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1023      |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 7.36e+07  |\n",
            "|    reward             | 2069554.5 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 4.37e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1026      |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | 7.53e+07  |\n",
            "|    reward             | 2237401.5 |\n",
            "|    std                | 0.978     |\n",
            "|    value_loss         | 5.7e+13   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2491027.4181795144\n",
            "Sharpe:  0.8989976056359191\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1020      |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 5.35e+07  |\n",
            "|    reward             | 1507379.1 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 2.35e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1023      |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 13500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | 7.93e+07  |\n",
            "|    reward             | 2012256.1 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 4.47e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1027      |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | 1.03e+08  |\n",
            "|    reward             | 2926860.8 |\n",
            "|    std                | 0.976     |\n",
            "|    value_loss         | 9.15e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2750191.8147914903\n",
            "Sharpe:  1.0185949029264847\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1022      |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | 3.77e+07  |\n",
            "|    reward             | 1099802.1 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 1.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1025      |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | 6.73e+07  |\n",
            "|    reward             | 1844109.1 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 3.57e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1027      |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | 8.12e+07  |\n",
            "|    reward             | 2069629.5 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 4.16e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 1.09e+08  |\n",
            "|    reward             | 3135683.5 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 1.1e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2883473.4929407863\n",
            "Sharpe:  1.064878978586161\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1025      |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 16500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 4.59e+07  |\n",
            "|    reward             | 1283699.4 |\n",
            "|    std                | 0.971     |\n",
            "|    value_loss         | 1.71e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1028      |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 6.07e+07  |\n",
            "|    reward             | 1612225.9 |\n",
            "|    std                | 0.971     |\n",
            "|    value_loss         | 2.72e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1031      |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 17500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 1.06e+08  |\n",
            "|    reward             | 2677189.0 |\n",
            "|    std                | 0.969     |\n",
            "|    value_loss         | 6.8e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1034      |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 8.77e+07  |\n",
            "|    reward             | 2672167.5 |\n",
            "|    std                | 0.968     |\n",
            "|    value_loss         | 7.45e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2679985.8945282595\n",
            "Sharpe:  0.99883527034539\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1026      |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 18500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 5.87e+07  |\n",
            "|    reward             | 1740537.4 |\n",
            "|    std                | 0.967     |\n",
            "|    value_loss         | 3e+13     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1027      |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 7.64e+07  |\n",
            "|    reward             | 1944323.0 |\n",
            "|    std                | 0.967     |\n",
            "|    value_loss         | 4.13e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 1.3e+08   |\n",
            "|    reward             | 3148255.2 |\n",
            "|    std                | 0.966     |\n",
            "|    value_loss         | 1.06e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2577190.48577263\n",
            "Sharpe:  0.9407950022038035\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1026      |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 3.97e+07  |\n",
            "|    reward             | 1153994.0 |\n",
            "|    std                | 0.965     |\n",
            "|    value_loss         | 1.49e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1019      |\n",
            "|    iterations         | 4100      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 20500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4099      |\n",
            "|    policy_loss        | 6.32e+07  |\n",
            "|    reward             | 1720696.4 |\n",
            "|    std                | 0.964     |\n",
            "|    value_loss         | 3.25e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1021      |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 7.51e+07  |\n",
            "|    reward             | 2004750.4 |\n",
            "|    std                | 0.964     |\n",
            "|    value_loss         | 4.42e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1024      |\n",
            "|    iterations         | 4300      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 21500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4299      |\n",
            "|    policy_loss        | 9.67e+07  |\n",
            "|    reward             | 2430806.8 |\n",
            "|    std                | 0.962     |\n",
            "|    value_loss         | 6.73e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2545861.6413980825\n",
            "Sharpe:  0.9392472917339507\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1021      |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | 5.43e+07  |\n",
            "|    reward             | 1450096.0 |\n",
            "|    std                | 0.962     |\n",
            "|    value_loss         | 2.26e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1023      |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 7.65e+07  |\n",
            "|    reward             | 1914260.5 |\n",
            "|    std                | 0.962     |\n",
            "|    value_loss         | 3.62e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1024      |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 8.82e+07  |\n",
            "|    reward             | 2743610.0 |\n",
            "|    std                | 0.962     |\n",
            "|    value_loss         | 7.96e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2556506.169673555\n",
            "Sharpe:  0.9676375306669522\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1021      |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 3.89e+07  |\n",
            "|    reward             | 1102230.9 |\n",
            "|    std                | 0.962     |\n",
            "|    value_loss         | 1.27e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1023      |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | 7.14e+07  |\n",
            "|    reward             | 1610422.1 |\n",
            "|    std                | 0.961     |\n",
            "|    value_loss         | 2.87e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1026      |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 24500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | 5.37e+07  |\n",
            "|    reward             | 1496137.5 |\n",
            "|    std                | 0.959     |\n",
            "|    value_loss         | 2.23e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1027      |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | 9.57e+07  |\n",
            "|    reward             | 2518697.0 |\n",
            "|    std                | 0.959     |\n",
            "|    value_loss         | 6.51e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2284936.994971075\n",
            "Sharpe:  0.8650990891835598\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1024      |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | 4.49e+07  |\n",
            "|    reward             | 1222116.2 |\n",
            "|    std                | 0.957     |\n",
            "|    value_loss         | 1.58e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1026      |\n",
            "|    iterations         | 5200      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5199      |\n",
            "|    policy_loss        | 5.38e+07  |\n",
            "|    reward             | 1530740.0 |\n",
            "|    std                | 0.957     |\n",
            "|    value_loss         | 2.45e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1027      |\n",
            "|    iterations         | 5300      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 26500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5299      |\n",
            "|    policy_loss        | 9.81e+07  |\n",
            "|    reward             | 2416938.2 |\n",
            "|    std                | 0.957     |\n",
            "|    value_loss         | 5.98e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 5400      |\n",
            "|    time_elapsed       | 26        |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5399      |\n",
            "|    policy_loss        | 8.22e+07  |\n",
            "|    reward             | 2271537.5 |\n",
            "|    std                | 0.957     |\n",
            "|    value_loss         | 5.46e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2435096.3946212325\n",
            "Sharpe:  0.934095154852763\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1026      |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 26        |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | 5.73e+07  |\n",
            "|    reward             | 1617088.4 |\n",
            "|    std                | 0.956     |\n",
            "|    value_loss         | 2.8e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1028      |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 27        |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | 8.09e+07  |\n",
            "|    reward             | 2127401.5 |\n",
            "|    std                | 0.956     |\n",
            "|    value_loss         | 4.67e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 27        |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | 1.22e+08  |\n",
            "|    reward             | 3499010.5 |\n",
            "|    std                | 0.955     |\n",
            "|    value_loss         | 1.2e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3020710.638980561\n",
            "Sharpe:  1.1355174757415387\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1026      |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 4.66e+07  |\n",
            "|    reward             | 1153668.4 |\n",
            "|    std                | 0.955     |\n",
            "|    value_loss         | 1.42e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1027      |\n",
            "|    iterations         | 5900      |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 29500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5899      |\n",
            "|    policy_loss        | 5.8e+07   |\n",
            "|    reward             | 1620213.8 |\n",
            "|    std                | 0.954     |\n",
            "|    value_loss         | 2.94e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1028      |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | 7.18e+07  |\n",
            "|    reward             | 1957822.9 |\n",
            "|    std                | 0.954     |\n",
            "|    value_loss         | 3.87e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 6100      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 30500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6099      |\n",
            "|    policy_loss        | 8.51e+07  |\n",
            "|    reward             | 2297213.0 |\n",
            "|    std                | 0.954     |\n",
            "|    value_loss         | 5.42e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2412909.3018030515\n",
            "Sharpe:  0.9166790527169671\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1027      |\n",
            "|    iterations         | 6200      |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6199      |\n",
            "|    policy_loss        | 5.36e+07  |\n",
            "|    reward             | 1376847.2 |\n",
            "|    std                | 0.954     |\n",
            "|    value_loss         | 1.93e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1028      |\n",
            "|    iterations         | 6300      |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 31500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6299      |\n",
            "|    policy_loss        | 5.92e+07  |\n",
            "|    reward             | 1725500.2 |\n",
            "|    std                | 0.952     |\n",
            "|    value_loss         | 3.19e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | 9.29e+07  |\n",
            "|    reward             | 2497099.5 |\n",
            "|    std                | 0.952     |\n",
            "|    value_loss         | 7.05e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2363254.600852507\n",
            "Sharpe:  0.9042753306211646\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1027      |\n",
            "|    iterations         | 6500      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 32500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6499      |\n",
            "|    policy_loss        | 3.96e+07  |\n",
            "|    reward             | 1063761.5 |\n",
            "|    std                | 0.951     |\n",
            "|    value_loss         | 1.2e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1028      |\n",
            "|    iterations         | 6600      |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6599      |\n",
            "|    policy_loss        | 6.42e+07  |\n",
            "|    reward             | 1629200.2 |\n",
            "|    std                | 0.951     |\n",
            "|    value_loss         | 2.84e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | 7.28e+07  |\n",
            "|    reward             | 1783632.4 |\n",
            "|    std                | 0.95      |\n",
            "|    value_loss         | 3.52e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 6800      |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6799      |\n",
            "|    policy_loss        | 8.98e+07  |\n",
            "|    reward             | 2492452.5 |\n",
            "|    std                | 0.948     |\n",
            "|    value_loss         | 6.83e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2312077.6308776126\n",
            "Sharpe:  0.8780734985761138\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1028      |\n",
            "|    iterations         | 6900      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 34500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6899      |\n",
            "|    policy_loss        | 4.11e+07  |\n",
            "|    reward             | 1157898.6 |\n",
            "|    std                | 0.948     |\n",
            "|    value_loss         | 1.44e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | 4.6e+07   |\n",
            "|    reward             | 1448084.5 |\n",
            "|    std                | 0.947     |\n",
            "|    value_loss         | 2.31e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1031      |\n",
            "|    iterations         | 7100      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 35500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7099      |\n",
            "|    policy_loss        | 7.74e+07  |\n",
            "|    reward             | 2121950.5 |\n",
            "|    std                | 0.947     |\n",
            "|    value_loss         | 4.76e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1031      |\n",
            "|    iterations         | 7200      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7199      |\n",
            "|    policy_loss        | 7.9e+07   |\n",
            "|    reward             | 2205872.8 |\n",
            "|    std                | 0.946     |\n",
            "|    value_loss         | 5.15e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2349835.683180793\n",
            "Sharpe:  0.9207112160415843\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 7300      |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 36500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7299      |\n",
            "|    policy_loss        | 5.13e+07  |\n",
            "|    reward             | 1516247.9 |\n",
            "|    std                | 0.947     |\n",
            "|    value_loss         | 2.37e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | 7.35e+07  |\n",
            "|    reward             | 1865570.9 |\n",
            "|    std                | 0.946     |\n",
            "|    value_loss         | 3.92e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1031      |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | 9.81e+07  |\n",
            "|    reward             | 2725487.2 |\n",
            "|    std                | 0.946     |\n",
            "|    value_loss         | 8.18e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2567809.6682243636\n",
            "Sharpe:  1.02768123862016\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 7600      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7599      |\n",
            "|    policy_loss        | 4.48e+07  |\n",
            "|    reward             | 1178228.9 |\n",
            "|    std                | 0.945     |\n",
            "|    value_loss         | 1.46e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 7700      |\n",
            "|    time_elapsed       | 37        |\n",
            "|    total_timesteps    | 38500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7699      |\n",
            "|    policy_loss        | 5.6e+07   |\n",
            "|    reward             | 1615287.9 |\n",
            "|    std                | 0.945     |\n",
            "|    value_loss         | 2.75e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1031      |\n",
            "|    iterations         | 7800      |\n",
            "|    time_elapsed       | 37        |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7799      |\n",
            "|    policy_loss        | 6.56e+07  |\n",
            "|    reward             | 1894205.8 |\n",
            "|    std                | 0.944     |\n",
            "|    value_loss         | 3.67e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1032      |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | 7.91e+07  |\n",
            "|    reward             | 2365866.8 |\n",
            "|    std                | 0.942     |\n",
            "|    value_loss         | 6.03e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2546447.954995342\n",
            "Sharpe:  1.0189134781953462\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1028      |\n",
            "|    iterations         | 8000      |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7999      |\n",
            "|    policy_loss        | 5.09e+07  |\n",
            "|    reward             | 1303425.9 |\n",
            "|    std                | 0.942     |\n",
            "|    value_loss         | 1.77e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | 5.63e+07  |\n",
            "|    reward             | 1619651.9 |\n",
            "|    std                | 0.942     |\n",
            "|    value_loss         | 2.8e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 8200      |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8199      |\n",
            "|    policy_loss        | 9.84e+07  |\n",
            "|    reward             | 2663176.0 |\n",
            "|    std                | 0.942     |\n",
            "|    value_loss         | 7.54e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2538532.7543905927\n",
            "Sharpe:  0.9839856797884089\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1028      |\n",
            "|    iterations         | 8300      |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 41500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8299      |\n",
            "|    policy_loss        | 3.23e+07  |\n",
            "|    reward             | 1000257.4 |\n",
            "|    std                | 0.94      |\n",
            "|    value_loss         | 9.2e+12   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 8400      |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8399      |\n",
            "|    policy_loss        | 6.14e+07  |\n",
            "|    reward             | 1668052.2 |\n",
            "|    std                | 0.94      |\n",
            "|    value_loss         | 3.33e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 41        |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | 6.37e+07  |\n",
            "|    reward             | 1879191.2 |\n",
            "|    std                | 0.939     |\n",
            "|    value_loss         | 3.72e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1031      |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 41        |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | 1.17e+08  |\n",
            "|    reward             | 2482717.0 |\n",
            "|    std                | 0.938     |\n",
            "|    value_loss         | 7.1e+13   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2401873.3272074545\n",
            "Sharpe:  0.95852181215003\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | 4.5e+07   |\n",
            "|    reward             | 1204076.1 |\n",
            "|    std                | 0.938     |\n",
            "|    value_loss         | 1.51e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 8800      |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8799      |\n",
            "|    policy_loss        | 5.44e+07  |\n",
            "|    reward             | 1576732.4 |\n",
            "|    std                | 0.937     |\n",
            "|    value_loss         | 2.76e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1031      |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 43        |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | 7.21e+07  |\n",
            "|    reward             | 2065521.6 |\n",
            "|    std                | 0.938     |\n",
            "|    value_loss         | 4.17e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1032      |\n",
            "|    iterations         | 9000      |\n",
            "|    time_elapsed       | 43        |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8999      |\n",
            "|    policy_loss        | 7.28e+07  |\n",
            "|    reward             | 2007944.9 |\n",
            "|    std                | 0.936     |\n",
            "|    value_loss         | 4.3e+13   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2156466.627396325\n",
            "Sharpe:  0.8381582405617037\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 9100      |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 45500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9099      |\n",
            "|    policy_loss        | 5.5e+07   |\n",
            "|    reward             | 1564302.4 |\n",
            "|    std                | 0.936     |\n",
            "|    value_loss         | 2.49e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 9200      |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9199      |\n",
            "|    policy_loss        | 7.42e+07  |\n",
            "|    reward             | 1891496.0 |\n",
            "|    std                | 0.937     |\n",
            "|    value_loss         | 3.81e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1031      |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 45        |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | 1.09e+08  |\n",
            "|    reward             | 3028378.5 |\n",
            "|    std                | 0.935     |\n",
            "|    value_loss         | 9.62e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2573278.8044937733\n",
            "Sharpe:  1.0443381901804991\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 45        |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | 3.98e+07  |\n",
            "|    reward             | 1137012.0 |\n",
            "|    std                | 0.935     |\n",
            "|    value_loss         | 1.36e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 9500      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9499      |\n",
            "|    policy_loss        | 4.7e+07   |\n",
            "|    reward             | 1501640.1 |\n",
            "|    std                | 0.934     |\n",
            "|    value_loss         | 2.48e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1031      |\n",
            "|    iterations         | 9600      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9599      |\n",
            "|    policy_loss        | 6.75e+07  |\n",
            "|    reward             | 1868424.2 |\n",
            "|    std                | 0.934     |\n",
            "|    value_loss         | 3.57e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1032      |\n",
            "|    iterations         | 9700      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 48500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9699      |\n",
            "|    policy_loss        | 7.55e+07  |\n",
            "|    reward             | 2374334.8 |\n",
            "|    std                | 0.933     |\n",
            "|    value_loss         | 5.74e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2295324.2600828726\n",
            "Sharpe:  0.9106916400233944\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 9800      |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9799      |\n",
            "|    policy_loss        | 4.06e+07  |\n",
            "|    reward             | 1270840.4 |\n",
            "|    std                | 0.932     |\n",
            "|    value_loss         | 1.71e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1029      |\n",
            "|    iterations         | 9900      |\n",
            "|    time_elapsed       | 48        |\n",
            "|    total_timesteps    | 49500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9899      |\n",
            "|    policy_loss        | 5.44e+07  |\n",
            "|    reward             | 1601411.4 |\n",
            "|    std                | 0.932     |\n",
            "|    value_loss         | 2.74e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1030      |\n",
            "|    iterations         | 10000     |\n",
            "|    time_elapsed       | 48        |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -12.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9999      |\n",
            "|    policy_loss        | 9.35e+07  |\n",
            "|    reward             | 2506991.8 |\n",
            "|    std                | 0.931     |\n",
            "|    value_loss         | 6.74e+13  |\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_a2c = agent.train_model(model=model_a2c,\n",
        "                                tb_log_name='a2c',\n",
        "                                total_timesteps=50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "cfhURI26P_Nr",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "trained_a2c.save('trained_models/a2c.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvrqTro3lhAh"
      },
      "source": [
        "### Model 2: **PPO**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVXta7jVKMhV",
        "outputId": "eab95391-634c-4f4f-8136-f05ec33611db",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.005,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5XlUIszKUGx",
        "outputId": "750155ee-fd20-4be5-f810-5321d1254cbb",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2910316.167630258\n",
            "Sharpe:  1.037367463094112\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 1484      |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 1         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1217751.9 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2839563.0382875516\n",
            "Sharpe:  1.013452864194386\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1367      |\n",
            "|    iterations           | 2         |\n",
            "|    time_elapsed         | 2         |\n",
            "|    total_timesteps      | 4096      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.39e+14  |\n",
            "|    n_updates            | 10        |\n",
            "|    policy_gradient_loss | -1.48e-07 |\n",
            "|    reward               | 2021899.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.41e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3319679.573993247\n",
            "Sharpe:  1.171526764322184\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1281      |\n",
            "|    iterations           | 3         |\n",
            "|    time_elapsed         | 4         |\n",
            "|    total_timesteps      | 6144      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.53e+14  |\n",
            "|    n_updates            | 20        |\n",
            "|    policy_gradient_loss | -3.8e-07  |\n",
            "|    reward               | 1653378.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.28e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2448773.168601847\n",
            "Sharpe:  0.8727534291579851\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1280      |\n",
            "|    iterations           | 4         |\n",
            "|    time_elapsed         | 6         |\n",
            "|    total_timesteps      | 8192      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.36e+14  |\n",
            "|    n_updates            | 30        |\n",
            "|    policy_gradient_loss | -1.37e-07 |\n",
            "|    reward               | 1892915.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.63e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2700059.2581125335\n",
            "Sharpe:  0.97152340190459\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1287      |\n",
            "|    iterations           | 5         |\n",
            "|    time_elapsed         | 7         |\n",
            "|    total_timesteps      | 10240     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.61e+14  |\n",
            "|    n_updates            | 40        |\n",
            "|    policy_gradient_loss | -3.35e-07 |\n",
            "|    reward               | 2570142.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.21e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2507563.106354583\n",
            "Sharpe:  0.8786011393638596\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1293      |\n",
            "|    iterations           | 6         |\n",
            "|    time_elapsed         | 9         |\n",
            "|    total_timesteps      | 12288     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.6e+14   |\n",
            "|    n_updates            | 50        |\n",
            "|    policy_gradient_loss | -2.5e-07  |\n",
            "|    reward               | 3608668.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.26e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3254167.3043411262\n",
            "Sharpe:  1.1168651456628271\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1284      |\n",
            "|    iterations           | 7         |\n",
            "|    time_elapsed         | 11        |\n",
            "|    total_timesteps      | 14336     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.81e+14  |\n",
            "|    n_updates            | 60        |\n",
            "|    policy_gradient_loss | -3.13e-07 |\n",
            "|    reward               | 2814516.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.55e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3062655.4045814793\n",
            "Sharpe:  1.0760851795023754\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2432794.695217996\n",
            "Sharpe:  0.8743951120764176\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1279      |\n",
            "|    iterations           | 8         |\n",
            "|    time_elapsed         | 12        |\n",
            "|    total_timesteps      | 16384     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.1e+14   |\n",
            "|    n_updates            | 70        |\n",
            "|    policy_gradient_loss | -1.61e-07 |\n",
            "|    reward               | 1205792.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.65e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2930494.7091521327\n",
            "Sharpe:  1.016479003467057\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1281      |\n",
            "|    iterations           | 9         |\n",
            "|    time_elapsed         | 14        |\n",
            "|    total_timesteps      | 18432     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.82e+14  |\n",
            "|    n_updates            | 80        |\n",
            "|    policy_gradient_loss | -1.65e-07 |\n",
            "|    reward               | 1605194.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.13e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2598678.653243114\n",
            "Sharpe:  0.9406365734215472\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1281      |\n",
            "|    iterations           | 10        |\n",
            "|    time_elapsed         | 15        |\n",
            "|    total_timesteps      | 20480     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.45e+14  |\n",
            "|    n_updates            | 90        |\n",
            "|    policy_gradient_loss | -1.18e-07 |\n",
            "|    reward               | 1807959.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.43e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2817503.065174606\n",
            "Sharpe:  1.0068302200372268\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1283      |\n",
            "|    iterations           | 11        |\n",
            "|    time_elapsed         | 17        |\n",
            "|    total_timesteps      | 22528     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.44e+14  |\n",
            "|    n_updates            | 100       |\n",
            "|    policy_gradient_loss | -2.99e-07 |\n",
            "|    reward               | 1997665.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.29e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2856262.52250357\n",
            "Sharpe:  1.0193948571641263\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1286      |\n",
            "|    iterations           | 12        |\n",
            "|    time_elapsed         | 19        |\n",
            "|    total_timesteps      | 24576     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.21e+14  |\n",
            "|    n_updates            | 110       |\n",
            "|    policy_gradient_loss | -1.41e-07 |\n",
            "|    reward               | 2351173.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.27e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2806547.8278789995\n",
            "Sharpe:  1.015308854998052\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1289      |\n",
            "|    iterations           | 13        |\n",
            "|    time_elapsed         | 20        |\n",
            "|    total_timesteps      | 26624     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.8e+14   |\n",
            "|    n_updates            | 120       |\n",
            "|    policy_gradient_loss | -2.86e-07 |\n",
            "|    reward               | 2947288.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.4e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2780960.476549862\n",
            "Sharpe:  0.9823135137028499\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1288      |\n",
            "|    iterations           | 14        |\n",
            "|    time_elapsed         | 22        |\n",
            "|    total_timesteps      | 28672     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.45e+14  |\n",
            "|    n_updates            | 130       |\n",
            "|    policy_gradient_loss | -1.4e-07  |\n",
            "|    reward               | 2860611.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.5e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3224838.5501540466\n",
            "Sharpe:  1.1152622339072302\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2669168.811055454\n",
            "Sharpe:  0.9236705176157787\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1284      |\n",
            "|    iterations           | 15        |\n",
            "|    time_elapsed         | 23        |\n",
            "|    total_timesteps      | 30720     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.74e+14  |\n",
            "|    n_updates            | 140       |\n",
            "|    policy_gradient_loss | -4.12e-07 |\n",
            "|    reward               | 1096916.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.61e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3241974.6150741163\n",
            "Sharpe:  1.1587197334617034\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1285      |\n",
            "|    iterations           | 16        |\n",
            "|    time_elapsed         | 25        |\n",
            "|    total_timesteps      | 32768     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | -2.38e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.63e+14  |\n",
            "|    n_updates            | 150       |\n",
            "|    policy_gradient_loss | -2.89e-07 |\n",
            "|    reward               | 1303979.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.4e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2924238.5330270506\n",
            "Sharpe:  1.048157955250185\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1286      |\n",
            "|    iterations           | 17        |\n",
            "|    time_elapsed         | 27        |\n",
            "|    total_timesteps      | 34816     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.47e+14  |\n",
            "|    n_updates            | 160       |\n",
            "|    policy_gradient_loss | -1.57e-07 |\n",
            "|    reward               | 1828247.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.5e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3007527.734725474\n",
            "Sharpe:  1.0467637292799277\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1285      |\n",
            "|    iterations           | 18        |\n",
            "|    time_elapsed         | 28        |\n",
            "|    total_timesteps      | 36864     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.81e+14  |\n",
            "|    n_updates            | 170       |\n",
            "|    policy_gradient_loss | -3.97e-07 |\n",
            "|    reward               | 1703140.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.3e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2730292.628336259\n",
            "Sharpe:  0.976393976260514\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1286      |\n",
            "|    iterations           | 19        |\n",
            "|    time_elapsed         | 30        |\n",
            "|    total_timesteps      | 38912     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.8e+14   |\n",
            "|    n_updates            | 180       |\n",
            "|    policy_gradient_loss | -3.26e-07 |\n",
            "|    reward               | 2157934.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.31e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3039664.557397935\n",
            "Sharpe:  1.053319283555695\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1279      |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 32        |\n",
            "|    total_timesteps      | 40960     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | -2.38e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.41e+14  |\n",
            "|    n_updates            | 190       |\n",
            "|    policy_gradient_loss | -1.43e-07 |\n",
            "|    reward               | 3600957.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.26e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3154382.0892486605\n",
            "Sharpe:  1.107589189386401\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1281      |\n",
            "|    iterations           | 21        |\n",
            "|    time_elapsed         | 33        |\n",
            "|    total_timesteps      | 43008     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.17e+14  |\n",
            "|    n_updates            | 200       |\n",
            "|    policy_gradient_loss | -2.62e-07 |\n",
            "|    reward               | 3428807.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.63e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3009435.8872927306\n",
            "Sharpe:  1.0535290774997714\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1282      |\n",
            "|    iterations           | 22        |\n",
            "|    time_elapsed         | 35        |\n",
            "|    total_timesteps      | 45056     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.88e+14  |\n",
            "|    n_updates            | 210       |\n",
            "|    policy_gradient_loss | -2.38e-07 |\n",
            "|    reward               | 2308302.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.7e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2408730.947098075\n",
            "Sharpe:  0.8558619111153974\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3024974.438636123\n",
            "Sharpe:  1.0651981127372523\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1280      |\n",
            "|    iterations           | 23        |\n",
            "|    time_elapsed         | 36        |\n",
            "|    total_timesteps      | 47104     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.64e+14  |\n",
            "|    n_updates            | 220       |\n",
            "|    policy_gradient_loss | -9.81e-08 |\n",
            "|    reward               | 1138263.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.23e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3051148.426755163\n",
            "Sharpe:  1.0751711303354405\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1281      |\n",
            "|    iterations           | 24        |\n",
            "|    time_elapsed         | 38        |\n",
            "|    total_timesteps      | 49152     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.49e+14  |\n",
            "|    n_updates            | 230       |\n",
            "|    policy_gradient_loss | -3.44e-07 |\n",
            "|    reward               | 1941886.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.37e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3050122.1384841027\n",
            "Sharpe:  1.051649434021008\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1281      |\n",
            "|    iterations           | 25        |\n",
            "|    time_elapsed         | 39        |\n",
            "|    total_timesteps      | 51200     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.45e+14  |\n",
            "|    n_updates            | 240       |\n",
            "|    policy_gradient_loss | -3.05e-07 |\n",
            "|    reward               | 1546498.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.35e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2703815.7969172355\n",
            "Sharpe:  0.9611990878401284\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1279      |\n",
            "|    iterations           | 26        |\n",
            "|    time_elapsed         | 41        |\n",
            "|    total_timesteps      | 53248     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.37e+14  |\n",
            "|    n_updates            | 250       |\n",
            "|    policy_gradient_loss | -2.46e-07 |\n",
            "|    reward               | 2004917.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.53e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2901191.7695746114\n",
            "Sharpe:  1.0310665438402873\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1281      |\n",
            "|    iterations           | 27        |\n",
            "|    time_elapsed         | 43        |\n",
            "|    total_timesteps      | 55296     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.03e+14  |\n",
            "|    n_updates            | 260       |\n",
            "|    policy_gradient_loss | -1.7e-07  |\n",
            "|    reward               | 2413272.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.15e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3022529.9852783945\n",
            "Sharpe:  1.0826727606278759\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1283      |\n",
            "|    iterations           | 28        |\n",
            "|    time_elapsed         | 44        |\n",
            "|    total_timesteps      | 57344     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.53e+14  |\n",
            "|    n_updates            | 270       |\n",
            "|    policy_gradient_loss | -1.76e-07 |\n",
            "|    reward               | 3051929.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.5e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2711460.733958511\n",
            "Sharpe:  0.9694040967103944\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1284      |\n",
            "|    iterations           | 29        |\n",
            "|    time_elapsed         | 46        |\n",
            "|    total_timesteps      | 59392     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.1e+14   |\n",
            "|    n_updates            | 280       |\n",
            "|    policy_gradient_loss | -3.88e-07 |\n",
            "|    reward               | 2985941.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.56e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2946563.8432950545\n",
            "Sharpe:  1.0464066590753693\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3255846.538750506\n",
            "Sharpe:  1.142507719952693\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1282      |\n",
            "|    iterations           | 30        |\n",
            "|    time_elapsed         | 47        |\n",
            "|    total_timesteps      | 61440     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.01e+14  |\n",
            "|    n_updates            | 290       |\n",
            "|    policy_gradient_loss | -4.41e-07 |\n",
            "|    reward               | 1167326.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.53e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2722977.624528901\n",
            "Sharpe:  0.9598673044482162\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1283      |\n",
            "|    iterations           | 31        |\n",
            "|    time_elapsed         | 49        |\n",
            "|    total_timesteps      | 63488     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.93e+14  |\n",
            "|    n_updates            | 300       |\n",
            "|    policy_gradient_loss | -4.76e-07 |\n",
            "|    reward               | 1528320.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.53e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3206354.784129227\n",
            "Sharpe:  1.140903095429267\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1283      |\n",
            "|    iterations           | 32        |\n",
            "|    time_elapsed         | 51        |\n",
            "|    total_timesteps      | 65536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.56e+14  |\n",
            "|    n_updates            | 310       |\n",
            "|    policy_gradient_loss | -3.12e-07 |\n",
            "|    reward               | 1897519.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.08e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2872851.3715384956\n",
            "Sharpe:  1.0228004966523618\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1284      |\n",
            "|    iterations           | 33        |\n",
            "|    time_elapsed         | 52        |\n",
            "|    total_timesteps      | 67584     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.16e+14  |\n",
            "|    n_updates            | 320       |\n",
            "|    policy_gradient_loss | -2.06e-07 |\n",
            "|    reward               | 1782422.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.49e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2413557.319847448\n",
            "Sharpe:  0.8713660592877189\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1284      |\n",
            "|    iterations           | 34        |\n",
            "|    time_elapsed         | 54        |\n",
            "|    total_timesteps      | 69632     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.67e+14  |\n",
            "|    n_updates            | 330       |\n",
            "|    policy_gradient_loss | -2.39e-07 |\n",
            "|    reward               | 2048589.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.28e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2949595.3108087685\n",
            "Sharpe:  1.019696437579355\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1285      |\n",
            "|    iterations           | 35        |\n",
            "|    time_elapsed         | 55        |\n",
            "|    total_timesteps      | 71680     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | -2.38e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.97e+14  |\n",
            "|    n_updates            | 340       |\n",
            "|    policy_gradient_loss | -3.5e-07  |\n",
            "|    reward               | 3578157.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.23e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3316953.356659718\n",
            "Sharpe:  1.1331725707561104\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1286      |\n",
            "|    iterations           | 36        |\n",
            "|    time_elapsed         | 57        |\n",
            "|    total_timesteps      | 73728     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.76e+14  |\n",
            "|    n_updates            | 350       |\n",
            "|    policy_gradient_loss | -1.92e-07 |\n",
            "|    reward               | 2927366.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.55e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2709298.837756507\n",
            "Sharpe:  0.9612127270049082\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2973349.5510364855\n",
            "Sharpe:  1.0616230977258638\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1281      |\n",
            "|    iterations           | 37        |\n",
            "|    time_elapsed         | 59        |\n",
            "|    total_timesteps      | 75776     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 8.11e+14  |\n",
            "|    n_updates            | 360       |\n",
            "|    policy_gradient_loss | -2.42e-07 |\n",
            "|    reward               | 998651.3  |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.67e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2755274.909597306\n",
            "Sharpe:  1.0057205279449193\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1281      |\n",
            "|    iterations           | 38        |\n",
            "|    time_elapsed         | 60        |\n",
            "|    total_timesteps      | 77824     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.63e+14  |\n",
            "|    n_updates            | 370       |\n",
            "|    policy_gradient_loss | -2.37e-07 |\n",
            "|    reward               | 1184773.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.46e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3013750.7565854047\n",
            "Sharpe:  1.056871769026786\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 1281          |\n",
            "|    iterations           | 39            |\n",
            "|    time_elapsed         | 62            |\n",
            "|    total_timesteps      | 79872         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.7462298e-10 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -12.8         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 5.22e+14      |\n",
            "|    n_updates            | 380           |\n",
            "|    policy_gradient_loss | -6.91e-07     |\n",
            "|    reward               | 1853359.9     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.22e+15      |\n",
            "-------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2519123.2643700116\n",
            "Sharpe:  0.9118019432467186\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1281      |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 63        |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -12.8     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.01e+14  |\n",
            "|    n_updates            | 390       |\n",
            "|    policy_gradient_loss | -2.66e-07 |\n",
            "|    reward               | 1601861.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.33e+15  |\n",
            "---------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo,\n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=80000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "zmMmk1amUlEm",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "trained_ppo.save('trained_models/ppo.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Iuv554xYFH"
      },
      "source": [
        "### Model 3: **DDPG**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojmppgo4LPLz",
        "outputId": "2fb4d362-925b-48e5-caf1-bfdddb4d3458",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
        "\n",
        "\n",
        "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWt6BIR0LT25",
        "outputId": "797bd696-c355-41ad-a89d-44295a6fb974",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3531595.0996209425\n",
            "Sharpe:  1.0787431051948781\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 175       |\n",
            "|    time_elapsed    | 41        |\n",
            "|    total_timesteps | 7216      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -7.32e+07 |\n",
            "|    critic_loss     | 1.17e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 7115      |\n",
            "|    reward          | 3616910.2 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 174       |\n",
            "|    time_elapsed    | 82        |\n",
            "|    total_timesteps | 14432     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.29e+08 |\n",
            "|    critic_loss     | 3.84e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 14331     |\n",
            "|    reward          | 3616910.2 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 169       |\n",
            "|    time_elapsed    | 127       |\n",
            "|    total_timesteps | 21648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.78e+08 |\n",
            "|    critic_loss     | 7.35e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 21547     |\n",
            "|    reward          | 3616910.2 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 167       |\n",
            "|    time_elapsed    | 172       |\n",
            "|    total_timesteps | 28864     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.83e+08 |\n",
            "|    critic_loss     | 1.19e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 28763     |\n",
            "|    reward          | 3616910.2 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 169       |\n",
            "|    time_elapsed    | 212       |\n",
            "|    total_timesteps | 36080     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.06e+08 |\n",
            "|    critic_loss     | 6.82e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 35979     |\n",
            "|    reward          | 3616910.2 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 24        |\n",
            "|    fps             | 169       |\n",
            "|    time_elapsed    | 255       |\n",
            "|    total_timesteps | 43296     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.21e+08 |\n",
            "|    critic_loss     | 1.13e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 43195     |\n",
            "|    reward          | 3616910.2 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3616910.3251294047\n",
            "Sharpe:  1.0948682188007288\n",
            "=================================\n"
          ]
        }
      ],
      "source": [
        "trained_ddpg = agent.train_model(model=model_ddpg,\n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "x4C64xZ1UrQA",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "trained_ddpg.save('trained_models/ddpg.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPEXBcm-uBJo"
      },
      "source": [
        "### Model 4: **SAC**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaWf2QeiLqyO",
        "outputId": "8570c7e7-fe22-423a-f5c8-149c355ab236",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "SAC_PARAMS = {\n",
        "    \"batch_size\": 128,\n",
        "    \"buffer_size\": 100000,\n",
        "    \"learning_rate\": 0.0003,\n",
        "    \"learning_starts\": 100,\n",
        "    \"ent_coef\": \"auto_0.1\",\n",
        "}\n",
        "\n",
        "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgYVPqtKLvi3",
        "outputId": "83a2a60a-cf75-4eaa-8fea-b24c193f1633",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2151769.342972661\n",
            "Sharpe:  0.8361830519956183\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.0254930984\n",
            "Sharpe:  0.8187416985916498\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 117       |\n",
            "|    time_elapsed    | 61        |\n",
            "|    total_timesteps | 7216      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -4.92e+07 |\n",
            "|    critic_loss     | 7.19e+11  |\n",
            "|    ent_coef        | 0.9       |\n",
            "|    ent_coef_loss   | 11.3      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 7115      |\n",
            "|    reward          | 2107942.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 122       |\n",
            "|    time_elapsed    | 117       |\n",
            "|    total_timesteps | 14432     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -8.41e+07 |\n",
            "|    critic_loss     | 9.93e+11  |\n",
            "|    ent_coef        | 7.84      |\n",
            "|    ent_coef_loss   | -220      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 14331     |\n",
            "|    reward          | 2107942.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 124       |\n",
            "|    time_elapsed    | 174       |\n",
            "|    total_timesteps | 21648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.14e+08 |\n",
            "|    critic_loss     | 1.16e+14  |\n",
            "|    ent_coef        | 68.3      |\n",
            "|    ent_coef_loss   | -451      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 21547     |\n",
            "|    reward          | 2107942.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 124       |\n",
            "|    time_elapsed    | 231       |\n",
            "|    total_timesteps | 28864     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.22e+08 |\n",
            "|    critic_loss     | 1.51e+12  |\n",
            "|    ent_coef        | 595       |\n",
            "|    ent_coef_loss   | -683      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 28763     |\n",
            "|    reward          | 2107942.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 121       |\n",
            "|    time_elapsed    | 296       |\n",
            "|    total_timesteps | 36080     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.25e+08 |\n",
            "|    critic_loss     | 1.48e+12  |\n",
            "|    ent_coef        | 5.18e+03  |\n",
            "|    ent_coef_loss   | -917      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 35979     |\n",
            "|    reward          | 2107942.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 24        |\n",
            "|    fps             | 121       |\n",
            "|    time_elapsed    | 356       |\n",
            "|    total_timesteps | 43296     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -6.19e+07 |\n",
            "|    critic_loss     | 1.09e+12  |\n",
            "|    ent_coef        | 4.52e+04  |\n",
            "|    ent_coef_loss   | -1.15e+03 |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 43195     |\n",
            "|    reward          | 2107942.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2107942.014893869\n",
            "Sharpe:  0.8187416937099237\n",
            "=================================\n"
          ]
        }
      ],
      "source": [
        "trained_sac = agent.train_model(model=model_sac,\n",
        "                             tb_log_name='sac',\n",
        "                             total_timesteps=50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "-nUIx62dUvfF",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "trained_sac.save('trained_models/sac.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iidB5E27dfzh"
      },
      "source": [
        "### Model 5: **TD3**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtRp1mWydkvs",
        "outputId": "7ce328d8-38b1-4552-982d-12472f790b39",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "TD3_PARAMS = {\"batch_size\": 100,\n",
        "              \"buffer_size\": 1000000,\n",
        "              \"learning_rate\": 0.001}\n",
        "\n",
        "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "argM0DtodmNL",
        "outputId": "c8f9b7b4-f84f-474e-8070-df3577bc8f50",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2212910.569194974\n",
            "Sharpe:  0.9769598047984968\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 179       |\n",
            "|    time_elapsed    | 40        |\n",
            "|    total_timesteps | 7216      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -3.09e+07 |\n",
            "|    critic_loss     | 1.62e+11  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 7115      |\n",
            "|    reward          | 2114719.8 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 176       |\n",
            "|    time_elapsed    | 81        |\n",
            "|    total_timesteps | 14432     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -5.04e+07 |\n",
            "|    critic_loss     | 8.1e+11   |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 14331     |\n",
            "|    reward          | 2114719.8 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 170       |\n",
            "|    time_elapsed    | 127       |\n",
            "|    total_timesteps | 21648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -7.27e+07 |\n",
            "|    critic_loss     | 9.68e+11  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 21547     |\n",
            "|    reward          | 2114719.8 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2114719.762523916\n",
            "Sharpe:  0.9340313580555972\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 167       |\n",
            "|    time_elapsed    | 172       |\n",
            "|    total_timesteps | 28864     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -8.89e+07 |\n",
            "|    critic_loss     | 2.22e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 28763     |\n",
            "|    reward          | 2114719.8 |\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_td3 = agent.train_model(model=model_td3,\n",
        "                             tb_log_name='td3',\n",
        "                             total_timesteps=30000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "nGXdd4uEUzCk",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "trained_td3.save('trained_models/td3.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe7UMeb0nHe8"
      },
      "source": [
        "### Model 6: **DRLEnsemble**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "avN01WeWasDE"
      },
      "outputs": [],
      "source": [
        "TRAIN_START_DATE = '2016-02-02'\n",
        "TRAIN_END_DATE = '2022-12-31'\n",
        "\n",
        "TEST_START_DATE = \"2023-01-02\"\n",
        "TEST_END_DATE = \"2023-12-31\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "NQKDMb1CcvNA"
      },
      "outputs": [],
      "source": [
        "processed = train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Ma6YpTlnuZ"
      },
      "source": [
        "## Trading\n",
        "Assume that we have $1,000,000 initial capital at 2019-01-01. We use the A2C model to trade Dow jones 30 stocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "J_SeNPDwPgHZ"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
        "\n",
        "trained_a2c = A2C.load(\"trained_models/a2c\")\n",
        "trained_ddpg = DDPG.load(\"trained_models/ddpg\")\n",
        "trained_ppo = PPO.load(\"trained_models/ppo\")\n",
        "trained_td3 = TD3.load(\"trained_models/td3\")\n",
        "trained_sac = SAC.load(\"trained_models/sac\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "CmEywyFYrlGA"
      },
      "outputs": [],
      "source": [
        "trade = data_split(df, TRADE_START_DATE, TRADE_END_DATE)\n",
        "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcGYlhyal205",
        "outputId": "2c50560a-af3a-4d6c-c874-19fd1ee38520",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4536, 18)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trade.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq4W9FbSstT7",
        "outputId": "9ccaad67-a171-45cb-fa86-8054f6015a42",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1174857.3038686607\n",
            "Sharpe:  0.8866558552818465\n",
            "=================================\n",
            "hit end!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1332053.4178860674\n",
            "Sharpe:  1.157525611901432\n",
            "=================================\n",
            "hit end!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1255178.5522795934\n",
            "Sharpe:  1.061958391644664\n",
            "=================================\n",
            "hit end!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1194489.8526289463\n",
            "Sharpe:  0.8787268567968054\n",
            "=================================\n",
            "hit end!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1172273.8756343438\n",
            "Sharpe:  0.9316485931521946\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "df_daily_return_1, df_actions_1 = DRLAgent.DRL_prediction(model=trained_a2c,\n",
        "                        environment = e_trade_gym)\n",
        "df_daily_return_2, df_actions_2 = DRLAgent.DRL_prediction(model=trained_ddpg,\n",
        "                        environment = e_trade_gym)\n",
        "df_daily_return_3, df_actions_3 = DRLAgent.DRL_prediction(model=trained_ppo,\n",
        "                        environment = e_trade_gym)\n",
        "df_daily_return_4, df_actions_4 = DRLAgent.DRL_prediction(model=trained_sac,\n",
        "                        environment = e_trade_gym)\n",
        "df_daily_return_5, df_actions_5 = DRLAgent.DRL_prediction(model=trained_td3,\n",
        "                        environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "uJvj3pXt_Ukg",
        "outputId": "a48972fd-f0dc-4df0-b3d7-54f86a56b4d6",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-04-04</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-04-05</td>\n",
              "      <td>-0.002589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-04-06</td>\n",
              "      <td>0.000732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-04-10</td>\n",
              "      <td>0.004683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-04-11</td>\n",
              "      <td>0.004447</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date  daily_return\n",
              "0 2023-04-04      0.000000\n",
              "1 2023-04-05     -0.002589\n",
              "2 2023-04-06      0.000732\n",
              "3 2023-04-10      0.004683\n",
              "4 2023-04-11      0.004447"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_daily_return_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "vXMMG_9SdKTu",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "df_daily_return_1.to_csv('df_daily_return_1.csv')\n",
        "df_daily_return_2.to_csv('df_daily_return_2.csv')\n",
        "df_daily_return_3.to_csv('df_daily_return_3.csv')\n",
        "df_daily_return_4.to_csv('df_daily_return_4.csv')\n",
        "df_daily_return_5.to_csv('df_daily_return_5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "tByVcZ2L9TAJ",
        "outputId": "38f20b3b-8c36-49ea-bec2-9e630b0a2245",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>agg</th>\n",
              "      <th>bil</th>\n",
              "      <th>btcusd</th>\n",
              "      <th>gld</th>\n",
              "      <th>spy</th>\n",
              "      <th>vb</th>\n",
              "      <th>vnq</th>\n",
              "      <th>vo</th>\n",
              "      <th>vwo</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-04-04</th>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-05</th>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.070647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-06</th>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.070647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-10</th>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.070647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-11</th>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.070647</td>\n",
              "      <td>0.192039</td>\n",
              "      <td>0.070647</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 agg       bil    btcusd       gld       spy        vb  \\\n",
              "date                                                                     \n",
              "2023-04-04  0.111111  0.111111  0.111111  0.111111  0.111111  0.111111   \n",
              "2023-04-05  0.192039  0.192039  0.070647  0.070647  0.070647  0.070647   \n",
              "2023-04-06  0.192039  0.192039  0.070647  0.070647  0.070647  0.070647   \n",
              "2023-04-10  0.192039  0.192039  0.070647  0.070647  0.070647  0.070647   \n",
              "2023-04-11  0.192039  0.192039  0.070647  0.070647  0.070647  0.070647   \n",
              "\n",
              "                 vnq        vo       vwo  \n",
              "date                                      \n",
              "2023-04-04  0.111111  0.111111  0.111111  \n",
              "2023-04-05  0.070647  0.192039  0.070647  \n",
              "2023-04-06  0.070647  0.192039  0.070647  \n",
              "2023-04-10  0.070647  0.192039  0.070647  \n",
              "2023-04-11  0.070647  0.192039  0.070647  "
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_actions_1.head()\n",
        "df_actions_2.head()\n",
        "df_actions_3.head()\n",
        "df_actions_4.head()\n",
        "df_actions_5.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "xBX3Y68o1vRG",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "df_actions_1.to_csv('df_actions_1.csv')\n",
        "df_actions_2.to_csv('df_actions_2.csv')\n",
        "df_actions_3.to_csv('df_actions_3.csv')\n",
        "df_actions_4.to_csv('df_actions_4.csv')\n",
        "df_actions_5.to_csv('df_actions_5.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFO42LcomPUT"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAvxipWFmUe8"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oGu3PCa8l6L",
        "outputId": "de715ecb-182c-4fb6-b382-b9b927582fd1",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performance Stats for A2C:\n",
            "\n",
            "Annual return          0.083908\n",
            "Cumulative returns     0.174857\n",
            "Annual volatility      0.096094\n",
            "Sharpe ratio           0.886656\n",
            "Calmar ratio           0.784851\n",
            "Stability              0.911259\n",
            "Max drawdown          -0.106910\n",
            "Omega ratio            1.158499\n",
            "Sortino ratio          1.250849\n",
            "Skew                  -0.516409\n",
            "Kurtosis               2.184066\n",
            "Tail ratio             1.059590\n",
            "Daily value at risk   -0.011769\n",
            "dtype: float64\n",
            "\n",
            "Performance Stats for DDPG:\n",
            "\n",
            "Annual return          0.154146\n",
            "Cumulative returns     0.332053\n",
            "Annual volatility      0.131334\n",
            "Sharpe ratio           1.157526\n",
            "Calmar ratio           1.243251\n",
            "Stability              0.929433\n",
            "Max drawdown          -0.123986\n",
            "Omega ratio            1.210277\n",
            "Sortino ratio          1.684344\n",
            "Skew                  -0.360054\n",
            "Kurtosis               1.800750\n",
            "Tail ratio             1.137891\n",
            "Daily value at risk   -0.015943\n",
            "dtype: float64\n",
            "\n",
            "Performance Stats for PPO:\n",
            "\n",
            "Annual return          0.120348\n",
            "Cumulative returns     0.255179\n",
            "Annual volatility      0.113047\n",
            "Sharpe ratio           1.061958\n",
            "Calmar ratio           1.117957\n",
            "Stability              0.923601\n",
            "Max drawdown          -0.107650\n",
            "Omega ratio            1.191058\n",
            "Sortino ratio          1.532264\n",
            "Skew                  -0.387387\n",
            "Kurtosis               1.775783\n",
            "Tail ratio             1.145198\n",
            "Daily value at risk   -0.013766\n",
            "dtype: float64\n",
            "\n",
            "Performance Stats for SAC:\n",
            "\n",
            "Annual return          0.092927\n",
            "Cumulative returns     0.194490\n",
            "Annual volatility      0.107750\n",
            "Sharpe ratio           0.878727\n",
            "Calmar ratio           0.845737\n",
            "Stability              0.910427\n",
            "Max drawdown          -0.109877\n",
            "Omega ratio            1.158442\n",
            "Sortino ratio          1.230102\n",
            "Skew                  -0.587197\n",
            "Kurtosis               2.719476\n",
            "Tail ratio             1.046595\n",
            "Daily value at risk   -0.013199\n",
            "dtype: float64\n",
            "\n",
            "Performance Stats for TD3:\n",
            "\n",
            "Annual return          0.082716\n",
            "Cumulative returns     0.172274\n",
            "Annual volatility      0.089625\n",
            "Sharpe ratio           0.931649\n",
            "Calmar ratio           0.893256\n",
            "Stability              0.911934\n",
            "Max drawdown          -0.092601\n",
            "Omega ratio            1.166059\n",
            "Sortino ratio          1.326406\n",
            "Skew                  -0.451320\n",
            "Kurtosis               1.975599\n",
            "Tail ratio             1.080529\n",
            "Daily value at risk   -0.010960\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from pyfolio import timeseries\n",
        "\n",
        "return_dfs = [df_daily_return_1, df_daily_return_2, df_daily_return_3, df_daily_return_4, df_daily_return_5]\n",
        "agent_names = ['A2C', 'DDPG', 'PPO', 'SAC', 'TD3']\n",
        "\n",
        "for i, df_return in enumerate(return_dfs):\n",
        "    strat = convert_daily_return_to_pyfolio_ts(df_return)\n",
        "    stats = timeseries.perf_stats(strat)\n",
        "    print(f\"\\nPerformance Stats for {agent_names[i]}:\\n\")\n",
        "    print(stats)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
